---
title: "RDDs and key-value pairs"
---

Spark supports also RDDs of key-value pairs. Key-value pairs in python are represented by means of python tuples:

- The first value is the key part of the pair
- The second value is the value part of the pair

RDDs of key-value pairs are sometimes called "pair RDDs".

RDDs of key-value pairs are characterized by 

- specific operations (e.g., `reduceByKey()`, `join()`), which analyze the content of one group (key) at a time;
- operations available for the standard RDDs (e.g., `filter()`, `map()`, `reduce()`).

Many applications are based on RDDs of key-value pairs: the operations available for RDDs of key-value pairs allow grouping data by key and performing computation by key (i.e., by group). The basic idea is similar to the one of the MapReduce-based programs in Hadoop, but there are more operations already available.

# Creating RDDs of key-value pairs
RDDs of key-value pairs can be built

- From other RDDs by applying the `map()` or the `flatMap()` transformation on other RDDs;
- From a Python in-memory collection of tuple (key-value pairs) by using the `parallelize()` method of the `SparkContext` class.

Key-value pairs are represented as standard built-in Python tuples composed of two elements

- Key
- Value

# RDDs of key-value pairs by using the Map transformation
The goal is to define an RDD of key-value pairs by using the map transformation: apply a function `f` on each element of the input RDD that returns one tuple for each input element. The new RDD of key-value pairs contains one tuple `y` for each element `x` of the input RDD.

The standard `map(f)` transformation is used, and the new RDD of key-value pairs contains one tuple `y` for each input element `x` of the input RDD ($y=f(x)$).

:::{.callout-note collapse="true"}
## Example
- Create an RDD from a textual file containing the first names of a list of users; each line of the file contains one first name;
- Create an RDD of key-value pairs containing a list of pairs `(first name, 1)`.

```python
# Read the content of the input textual file
namesRDD = sc.textFile("first_names.txt")

# Create an RDD of key-value pairs
nameOnePairRDD = namesRDD.map(lambda name: (name, 1))
```

|||
|-|----|
| `nameOnePairRDD` | It contains key-value pairs (i.e., tuples) of type (string, integer) |

:::

# RDDs of key-value pairs by using the flatMap transformation
Define an RDD of key-value pairs by using the flatMap transformation: apply a function `f` on each element of the input RDD that returns a list of tuples for each input element. The new PairRDD contains all the pairs obtained by applying `f` on each element `x` of the input RDD.

The standard `flatMap(f)` transformation is used, and the new RDD of key-value pairs contains the tuples returned by the execution of `f` on each element `x` of the input RDD.

$$
[y]= f(x)
$$

- Given a element $x$ of the input RDD, $f$ applied on $x$ returns a list of pairs $[y]$;
- The new RDD is a list of pairs contains all the pairs of the returned list of pairs. It is not an RDD of lists.

$[y]$ can be the empty list.

:::{.callout-note collapse="true"}
## Example
1. Create an RDD from a textual file; each line of the file contains a set of words;
2. Create a `PairRDD` containing a list of pairs `(word, 1)`: one pair for each word occurring in the input document (with repetitions).

**Version 1**

```python
# Define the function associated with the flatMap transformation
def wordsOnes(line):
    pairs = []
    for word in line.split(' '):
        pairs.append( (word, 1))
    return pairs

# Read the content of the input textual file
linesRDD = sc.textFile("document.txt")

# Create an RDD of key-value pairs based on the input document
# One pair (word,1) for each input word
wordOnePairRDD = linesRDD.flatMap(wordsOnes)
```

**Version 1**
```python
# Read the content of the input textual file
linesRDD = sc.textFile("document.txt")

# Create an RDD of key-value pairs based on the input document
# One pair (word,1) for each input word
wordOnePairRDD = linesRDD.flatMap(
    lambda line: map(lambda w: (w, 1), line.split(' '))
)
```

|||
|-|----|
| `map(lambda w: (w, 1), line.split(' '))` | This is the map of python. It is not the Spark’s map transformation. |

:::

# RDDs of key-value pairs by using parallelize
Use the parallelize method to create an RDD of key-value pairs from a local python in-memory collection of tuples.

It is based on the standard `parallelize(c)` method of the `SparkContext` class: each element (tuple) of the local python collection becomes a key-vaue pair of the returned RDD.

:::{.callout-note collapse="true"}
## Example
Create an RDD from a local python list containing the following key-value pairs

- `("Paolo", 40)`
- `("Giorgio", 22)`
- `("Paolo", 35)`

```python
# Create the local python list
nameAge = [ ("Paolo", 40), ("Giorgio", 22), ("Paolo", 35)]

# Create the RDD of pairs from the local collection
nameAgePairRDD = sc.parallelize(nameAge)
```

|||
|-|----|
| `nameAge` | This is a local in-memory python list of key-value pairs (tuples), that is stored in the main memory of the Driver. |
| `nameAgePairRDD` | This is an RDD or key-value pairs based on the content of the local in-memory python list. The RDD is stored in the “distributed” main memory of the cluster servers |

:::

# Transformations on RDDs of key-value pairs
All the standard transformations can be applied, where the specified functions operate on tuples, but also specific transformations are available (e.g., `reduceByKey()`, `groupyKey()`, `mapValues()`, `join()`).

## ReduceByKey transformation
Create a new RDD of key-value pairs where there is one pair for each distinct key `k` of the input RDD of key-value pairs: 

- The value associated with key `k` in the new RDD of key-value pairs is computed by applying a function `f` on the values associated with `k` in the input RDD of key-value pairs; the function `f` must be associative and commutative, otherwise the result depends on how data are partitioned and analyzed;
- The data type of the new RDD of key-value pairs is the same of the input RDD of key-value pairs.

The reduceByKey transformation is based on the `reduceByKey(f)` method of the `RDD` class. A function `f` is passed to the reduceByKey method

- Given the values of two input pairs, `f` is used to combine them in one single value;
- `f` is recursively invoked over the values of the pairs associated with one key at a time until the input values associated with one key are reduced to one single value.

The retuned RDD contains a number of key-value pairs equal to the number of distinct keys in the input key-value pair RDD.

Similarly to the `reduce()` action, the `reduceByKey()` transformation aggregate values, however `reduceByKey()` is executed on RDDs of key-value pairs and returns a set of key-value pairs, while `reduce()` is executed on an RDD and returns one single value (stored in a local python variable). Moreover, `reduceByKey()` is a transformation, and so it is executed lazily and its result is stored in another RDD, whereas `reduce()` is an action.

A shuffle operation is executed for computing the result of the `reduceByKey()` transformation. The result/value for each group/key is computed from data stored in different input partitions.

:::{.callout-note collapse="true"}
## Example
1. Create an RDD from a local python list containing the pairs, where the key is the first name of a user and the value is his/her age
    - `("Paolo", 40)`
    - `("Giorgio", 22)`
    - `("Paolo", 35)`
2. Create a new RDD of key-value pairs containing one pair for each name. In the returned RDD, associate each name with the age of the youngest user with that name.

```python
# Create the local python list
nameAge = [ ("Paolo", 40), ("Giorgio", 22), ("Paolo", 35)]

# Create the RDD of pairs from the local collection
nameAgePairRDD = sc.parallelize(nameAge)

# Select for each name the lowest age value
youngestPairRDD= nameAgePairRDD.reduceByKey(lambda age1, age2: min(age1, age2))
```

|||
|-|----|
| `youngestPairRDD` | The returned RDD of key-value pairs contains one pair for each distinct input key (i.e., for each distinct name in this example) |

:::

## FoldByKey transformation
The `foldByKey()` has the same goal of the `reduceBykey()` transformation, however

- It is characterized also by a "zero" value
- Functions must be associative but are not required to be commutative

The foldByKey transformation is based on the `foldByKey(zeroValue, op)` method of the `RDD` class. A function `op` is passed to the fold method:

- Given values of two input pairs, `op` is used to combine them in one single value
- `op` is also used to combine input values with the "zero" value
- `op` is recursively invoked over the values of the pairs associated with one key at a time until the input values are reduced to one single value

The "zero" value is the neutral value for the used function `op` (i.e., "zero" combined with any value $v$ by using `op` is equal to $v$).

A shuffle operation is executed for computing the result of the `foldByKey()` transformation. The result/value for each group/key is computed from data stored in different input partitions.

:::{.callout-note collapse="true"}
## Example
1. Create an RDD from a local python list containing the pairs, where the key is the first name of a user and the value is a message published by him/her
    - `("Paolo", "Message1")`
    - `("Giorgio", "Message2")`
    - `("Paolo", "Message3")`
2. Create a new RDD of key-value pairs containing one pair for each name. In the returned RDD, associate each name the concatenation of its messages (preserving the order of the messages in the input RDD).

```python
# Create the local python list
nameMess = [("Paolo", "Message1"), ("Giorgio", "Message2"), ("Paolo", "Message3")]

# Create the RDD of pairs from the local collection
nameMessPairRDD = sc.parallelize(nameMess)

# Concatenate the messages of each user
concatPairRDD= nameMessPairRDD.foldByKey('', lambda m1, m2: m1+m2)
```

:::

## CombineByKey transformation
Create a new RDD of key-value pairs where there is one pair for each distinct key $k$ of the input RDD of key-value pairs. The value associated with the key $k$ in the new RDD of key-value pairs is computed by applying user-provided functions on the values associated with $k$ in the input RDD of key-value pairs: the user-provided function must be associative, otherwise the result depends how data are partitioned and analyzed.

The data type of the new RDD of key-value pairs can be different with respect to the data type of the input RDD of key-value pairs.

The combineByKey transformation is based on the `combineByKey(createCombiner, mergeValue, mergeCombiner)` method of the `RDD` class

- The values of the input RDD of pairs are of type $V$
- The values of the returned RDD of pairs are of type $U$
- The type of the keys is $K$ for both RDDs of pairs

The `createCombiner` function contains the code that is used to transform a single value (type $V$) of the input RDD of key-value pairs into a value of the data type (type $U$) of the output RDD of key-value pairs. It is used to transform the first value of each key in each partition to a value of type $U$.

The `mergeValue` function contains the code that is used to combine one value of type $U$ with one value of type $V$: it is used in each partition to combine the initial values (type $V$) of each key with the intermediate ones (type $U$) of each key.

The `mergeCombiner` function contains the code that is used to combine two values of type $U$: it is used to combine intermediate values of each key returned by the analysis of different partitions.

The `combineByKey` function is more general than `reduceByKey` and `foldByKey` because the data types of the values of the input and the returned RDD of pairs can be different; for this reason, more functions must be implemented in this case.

A shuffle operation is executed for computing the result of the `combineByKey()` transformation: the result/value for each group/key is computed from data stored in different input partitions.

:::{.callout-note collapse="true"}
## Example
1. Create an RDD from a local python list containing the the following pairs: the key is the first name of a user and the value is his/her age
    - `("Paolo", 40)`
    - `("Giorgio", 22)`
    - `("Paolo", 35)`
2. Store the results in an output HDFS folder. The output contains one line for each name followed by the average age of the users with that name

```python
# Create the local python list
nameAge = [ ("Paolo", 40), ("Giorgio", 22), ("Paolo", 35)]

# Create the RDD of pairs from the local collection
nameAgePairRDD = sc.parallelize(nameAge)

# Compute the sum of ages and
# the number of input pairs for each name (key)
sumNumPerNamePairRDD = nameAgePairRDD.combineByKey(
    lambda inputElem: (inputElem, 1),
    lambda intermediateElem, inputElem: (intermediateElem[0]+inputElem, intermediateElem[1]+1),
    lambda intermediateElem1, intermediateElem2: (intermediateElem1[0]+intermediateElem2[0], intermediateElem1[1]+intermediateElem2[1])
)

# Compute the average for each name
avgPerNamePairRDD = sumNumPerNamePairRDD.map(lambda pair: (pair[0], pair[1][0]/pair[1][1]))

# Store the result in an output folder
avgPerNamePairRDD.saveAsTextFile(outputPath)
```

|||
|-|----|
| `lambda inputElem:` | Given an input value (an age), it returns a tuple containing (age,1) |
| `lambda intermediateElem, inputElem:` | Given an input value (an age) and an intermediate value (*sum ages*, *num represented values*), it combines them and returns a new updated tuple (*sum ages*, *num represented values*) |
| `lambda intermediateElem1, intermediateElem2:` | Given two intermediate result tuples (*sum ages*, *num represented values*), it combines them and returns a new updated tuple (*sum ages*, *num represented values*) |
| `lambda pair:` | Compute the average age for each key (i.e., for each name) by combining *sum ages* and *num represented values*. Each input pair is characterized by a value that is a tuple containing (*sum ages*, *num represented values*). |

:::

## GroupByKey transformation
Create a new RDD of key-value pairs where there is one pair for each distinct key $k$ of the input RDD of key-value pairs: the value associated with key $k$ in the new RDD of key-value pairs is the list of values associated with $k$ in the input RDD of key-value pairs.

The groupByKey transformation is based on the `groupByKey()` method of the `RDD` class.

If grouping values per key to perform then an aggregation such as sum or average over the values of each key then groupByKey is not the right choice: `reduceByKey`, `aggregateByKey`, or `combineByKey` provide better performances for associative and commutative aggregations; `groupByKey` is useful if an aggregation or compute a function that is not associative must be applied.

A shuffle operation is executed for computing the result of the `groupByKey()` transformation: each group/key is associated with/is composed of values which are stored in different partitions of the input RDD.

:::{.callout-note collapse="true"}
## Example
1. Create an RDD from a local python list containing the following pairs: the key is the first name of a user and the value is his/her age.
    - `("Paolo", 40)`
    - `("Giorgio", 22)`
    - `("Paolo", 35)`
2. Store the results in an output HDFS folder. The output contains one line for each name followed by the ages of all the users with that name.

```python
# Create the local python list
nameAge = [ ("Paolo", 40), ("Giorgio", 22), ("Paolo", 35)]

# Create the RDD of pairs from the local collection
nameAgePairRDD = sc.parallelize(nameAge)

# Create one group for each name with the list of associated ages
agesPerNamePairRDD = nameAgePairRDD.groupByKey()

# Store the result in an output folder
agesPerNamePairRDD.mapValues(lambda listValues: list(listValues)).saveAsTextFile(outputPath)
```

|||
|-|----|
| `agesPerNamePairRDD` | In this RDD of key-value pairs each tuple is composed of a string (key of the pair) and a collection of integers (the value of the pair - a `ResultIterable` object) |
| `.mapValues(lambda listValues: list(listValues))` | This part is used to format the content of the value part of each pair before storing the result in the output folder: this transforms a `ResultIterable` object to a Python list. Without this map the output will contain the pointers to `ResultIterable` objects instead of a readable list of integer values |
:::

## MapValues transformation
Apply a function $f$ over the value of each pair of an input RDD or key-value pairs and return a new RDD of key-value pairs: one pair is created in the returned RDD for each input pair

- The key of the created pair is equal to the key of the input pair
- The value of the created pair is obtained by applying the function $f$ on the value of the input pair

The data type of the values of the new RDD of key-value pairs can be different from the data type of the values of the input RDD of key-value pairs. The data type of the key is the same.

The mapValues transformation is based on the `mapValues(f)` method of the `RDD` class: a function `f` is passed to the mapValues method, where `f` contains the code that is applied to transform each input value into the a new value that is stored in the RDD of key-value pairs. The retuned RDD of pairs contains a number of key-value pairs equal to the number of key-value pairs of the input RDD of pairs (the key part is not changed).

:::{.callout-note collapse="true"}
1. Create an RDD from a local python list containing the following pairs: the key is the first name of a user and the value is his/her age.
    - `("Paolo", 40)`
    - `("Giorgio", 22)`
    - `("Paolo", 35)`
2. Increase the age of each user (+1 year) and store the result in the HDFS file system, one output line per user.

```python
# Create the local python list
nameAge = [ ("Paolo", 40), ("Giorgio", 22), ("Paolo", 35)]

# Create the RDD of pairs from the local collection
nameAgePairRDD = sc.parallelize(nameAge)

# Increment age of all users
plusOnePairRDD = nameAgePairRDD.mapValues(lambda age: age+1)

# Save the result on disk
plusOnePairRDD.saveAsTextFile(outputPath)
```
:::

## FlatMapValues transformation