<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Distributed architectures for big data processing and analytics - 18&nbsp; Spark SQL and DataFrames</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./18a_spark_mllib.html" rel="next">
<link href="./15b_pagerank.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./16_sparksql_dataframes.html"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Spark SQL and DataFrames</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Distributed architectures for big data processing and analytics</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">About this Book</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_01_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to Big data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_architectures.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Big data architectures</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03b_HDFS_clc.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">HDFS and Hadoop: command line commands</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_intro_hadoop.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Hadoop and MapReduce</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_hadoop_implementation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">How to write MapReduce programs in Hadoop</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_mapreduce_patterns_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">MapReduce patterns - 1</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_mapreduce_advanced_topics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">MapReduce and Hadoop Advanced Topics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_mapreduce_patterns_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">MapReduce patterns - 2</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_sql_operators_mapreduce.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Relational Algebra Operations and MapReduce</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10b_spark_submit_execute.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">How to submit/execute a Spark application</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_intro_spark.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Introduction to Spark</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_rdd_based_programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">RDD based programming</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_rdd_keyvalue_pairs.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">RDDs and key-value pairs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_rdd_numbers.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">RDD of numbers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_cache_accumulators_broadcast.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Cache, Accumulators, Broadcast Variables</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15b_pagerank.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Introduction to PageRank</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_sparksql_dataframes.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Spark SQL and DataFrames</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18a_spark_mllib.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Spark MLlib</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18b_classification.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Classification algorithms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18c_clustering.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Clustering algorithms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18d_regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Regression algorithms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18e_mining.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Itemset and Association rule mining</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19_graph_analytics_1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Graph analytics in Spark</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20_graph_analytics_2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Graph Analytics in Spark</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21_streaming_analytics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Streaming data analytics frameworks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22_structured_streaming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Spark structured streaming</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23_streaming_frameworks.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Streaming data analytics frameworks</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#spark-sql" id="toc-spark-sql" class="nav-link active" data-scroll-target="#spark-sql">Spark SQL</a></li>
  <li><a href="#dataframes-1" id="toc-dataframes-1" class="nav-link" data-scroll-target="#dataframes-1">DataFrames</a></li>
  <li><a href="#operations-on-dataframes" id="toc-operations-on-dataframes" class="nav-link" data-scroll-target="#operations-on-dataframes">Operations on DataFrames</a></li>
  <li><a href="#dataframes-and-the-sql-language" id="toc-dataframes-and-the-sql-language" class="nav-link" data-scroll-target="#dataframes-and-the-sql-language">DataFrames and the SQL language</a></li>
  <li><a href="#save-dataframes" id="toc-save-dataframes" class="nav-link" data-scroll-target="#save-dataframes">Save DataFrames</a></li>
  <li><a href="#udfs-user-defines-functions" id="toc-udfs-user-defines-functions" class="nav-link" data-scroll-target="#udfs-user-defines-functions">UDFs: User Defines Functions</a></li>
  <li><a href="#other-notes" id="toc-other-notes" class="nav-link" data-scroll-target="#other-notes">Other notes</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Spark SQL and DataFrames</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="spark-sql" class="level3">
<h3 class="anchored" data-anchor-id="spark-sql">Spark SQL</h3>
<p>Spark SQL is the Spark component for structured data processing. It provides a programming abstraction called <em>Dataframe</em> and can act as a distributed SQL query engine: the input data can be queried by using</p>
<ul>
<li>Ad-hoc methods</li>
<li>Or an SQL-like language</li>
</ul>
<section id="spark-sql-vs-spark-rdd-apis" class="level4">
<h4 class="anchored" data-anchor-id="spark-sql-vs-spark-rdd-apis">Spark SQL vs Spark RDD APIs</h4>
<p>The interfaces provided by Spark SQL provide more information about the structure of both the data and the computation being performed. Spark SQL uses this extra information to perform extra optimizations based on a “SQL-like” optimizer called <strong>Catalyst</strong>, and so programs based on Dataframe are usually faster than standard RDD-based programs.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<figcaption class="figure-caption">Spark SQL vs Spark RDD APIs</figcaption>
<p><img src="images/16_sparksql_dataframes/sql_vs_rdd.png" class="img-fluid figure-img" style="width:80.0%"></p>
</figure>
</div>
</section>
<section id="dataframes" class="level4">
<h4 class="anchored" data-anchor-id="dataframes">DataFrames</h4>
<p>A DataFrame is a distributed collection of structured data. It is conceptually equivalent to a table in a relational database, and it can be created reading data from different types of external sources (CSV files, JSON files, RDBMs,…). A DataFrame benefits from Spark SQL optimized execution engine exploiting the information about the data structure.</p>
<p>All the Spark SQL functionalities are based on an instance of the <code>pyspark.sql.SparkSession</code> class</p>
<p>To import it in a standalone application use</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To instance a <code>SparkSession</code> object use</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>To close a <code>SparkSession</code> use the <code>SparkSession.stop()</code> method</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>spark.stop()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="dataframes-1" class="level3">
<h3 class="anchored" data-anchor-id="dataframes-1">DataFrames</h3>
<p>A DataFrame is a distributed collection of data organized into named columns, equivalent to a relational table: DataFrames are lists of <strong>Row objects</strong>.</p>
<p>The classes used to define DataFrames are</p>
<ul>
<li><code>pyspark.sql.DataFrame</code></li>
<li><code>pyspark.sql.Row</code></li>
</ul>
<p>DataFrames can be created from different sources</p>
<ul>
<li>Structured (textual) data files (e.g., csv files, json files);</li>
<li>Existing RDDs;</li>
<li>Hive tables;</li>
<li>External relational databases.</li>
</ul>
<section id="creating-dataframes-from-csv-files" class="level4">
<h4 class="anchored" data-anchor-id="creating-dataframes-from-csv-files">Creating DataFrames from csv files</h4>
<p>Spark SQL provides an API that allows creating DataFrames directly from CSV files. The creation of a DataFrame from a csv file is based the <code>load(path)</code> method of the <code>pyspark.sql.DataFrameReader</code> class, where <code>path</code> is the path of the input file. To get a <code>DataFrameReader</code> using the the <code>read()</code> method of the <code>SparkSession</code> class.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>df <span class="op">=</span> spark.read.load(path, options)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Create a DataFrame from a csv file (“people.csv”) containing the profiles of a set of people. Each line of the file contains name and age of a person, and age can assume the null value (i.e., it can be missing). The first line contains the header (i.e., the names of the attributes/columns).</p>
<p>Example of csv file</p>
<pre><code>name,age
Andy,30
Michael,
Justin,19</code></pre>
<p>Notice that the age of the second person is unknown.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb6-2"><a href="#cb6-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb6-3"><a href="#cb6-3"></a></span>
<span id="cb6-4"><a href="#cb6-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb6-5"><a href="#cb6-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb6-6"><a href="#cb6-6"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb6-7"><a href="#cb6-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb6-8"><a href="#cb6-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb6-9"><a href="#cb6-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb6-10"><a href="#cb6-10"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 75%">
</colgroup>
<tbody>
<tr class="odd">
<td><code>format="csv"</code></td>
<td>This is used to specify the format of the input file</td>
</tr>
<tr class="even">
<td><code>header=True</code></td>
<td>This is used to specify that the first line of the file contains the name of the attributes/columns</td>
</tr>
<tr class="odd">
<td><code>inferSchema=True</code></td>
<td>This method is used to specify that the system must infer the data types of each column. Without this option all columns are considered strings</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="creating-dataframes-from-json-files" class="level4">
<h4 class="anchored" data-anchor-id="creating-dataframes-from-json-files">Creating DataFrames from JSON files</h4>
<p>Spark SQL provides an API that allows creating a DataFrame directly from a textual file where each line contains a JSON object. Hence, the input file is not a standard JSON file: it must be properly formatted in order to have one JSON object (tuple) for each line. So, the format of the input file must be compliant with the <strong>JSON Lines text format</strong>, also called newline-delimited JSON.</p>
<p>The creation of a DataFrame from JSON files is based on the same method used for reading csv files, that is the <code>load(path)</code> method of the <code>pyspark.sql.DataFrameReader</code> class, where <code>path</code> is the path of the input file. To get a DataFrameReader use the <code>read()</code> method of the <code>SparkSession</code> class.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>df <span class="op">=</span> spark.read.load(path, <span class="bu">format</span><span class="op">=</span><span class="st">"json"</span>, options)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>or</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a>df <span class="op">=</span> spark.read.json(path, options)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The same API allows also reading standard multiline JSON files by setting the multiline option to true by setting the argument <code>multiLine=True</code> on the defined <code>DataFrameReader</code> for reading standard JSON files (this feature is available since Spark 2.2.0).</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pay attention that reading a set of small JSON files from HDFS is very slow.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Create a DataFrame from a JSON Lines text formatted file (“people.json”) containing the profiles of a set of people: each line of the file contains a JSON object containing name and age of a person. Age can assume the null value.</p>
<p>Example of JSON file</p>
<pre><code>{"name":"Michael"}
{"name":"Andy", "age":30}
{"name":"Justin", "age":19}</code></pre>
<p>Notice that the age of the first person is unknown.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb10-2"><a href="#cb10-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb10-3"><a href="#cb10-3"></a></span>
<span id="cb10-4"><a href="#cb10-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb10-5"><a href="#cb10-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb10-6"><a href="#cb10-6"></a>    <span class="st">"people.json"</span>,</span>
<span id="cb10-7"><a href="#cb10-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"json"</span></span>
<span id="cb10-8"><a href="#cb10-8"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 75%">
</colgroup>
<tbody>
<tr class="odd">
<td><code>format="json"</code></td>
<td>This method is used to specify the format of the input file.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Create a DataFrame from a folder containing a set of standard multiline JSON files: each input JSON file contains the profile of one person, in particular each file contains name and age of a person. Age can assume the null value.</p>
<p>Example of JSON file</p>
<pre><code>{"name":"Andy", "age":30}</code></pre>
<div class="sourceCode" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb12-2"><a href="#cb12-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb12-3"><a href="#cb12-3"></a></span>
<span id="cb12-4"><a href="#cb12-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb12-5"><a href="#cb12-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb12-6"><a href="#cb12-6"></a>    <span class="st">"folder_JSONFiles/"</span>,</span>
<span id="cb12-7"><a href="#cb12-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"json"</span>,</span>
<span id="cb12-8"><a href="#cb12-8"></a>    multiLine<span class="op">=</span><span class="va">True</span></span>
<span id="cb12-9"><a href="#cb12-9"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 75%">
</colgroup>
<tbody>
<tr class="odd">
<td><code>multiLine=True</code></td>
<td>This multiline option is set to true to specify that the input files are standard multiline JSON files.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="creating-dataframes-from-other-data-sources" class="level4">
<h4 class="anchored" data-anchor-id="creating-dataframes-from-other-data-sources">Creating DataFrames from other data sources</h4>
<p>The <code>DataFrameReader</code> class (the same we used for reading a json file and store it in a DataFrame) provides other methods to read many standard (textual) formats and read data from external databases:</p>
<ul>
<li>Apache parquet files</li>
<li>external relational database, through a JDBC connection</li>
<li>Hive tables</li>
<li>…</li>
</ul>
</section>
<section id="creating-dataframes-from-rdds-or-python-lists" class="level4">
<h4 class="anchored" data-anchor-id="creating-dataframes-from-rdds-or-python-lists">Creating DataFrames from RDDs or Python lists</h4>
<p>The content of an RDD of tuples or the content of a Python list of tuples can be stored in a DataFrame by using the <code>spark.createDataFrame(data,schema)</code> method, where <code>data</code> is a RDD of tuples or Rows, Python list of tuples or Rows, or pandas DataFrame, and <code>schema</code> is a list of string with the names of the columns/attributes. <code>schema</code> is optional, and if not specified the column names are set to <code>_1</code>, <code>_2</code>, …, <code>_n</code> for input RDDs/lists of tuples.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Create a DataFrame from the following Python list</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a>[</span>
<span id="cb13-2"><a href="#cb13-2"></a>    (<span class="dv">19</span>,<span class="st">"Justin"</span>),</span>
<span id="cb13-3"><a href="#cb13-3"></a>    (<span class="dv">30</span>,<span class="st">"Andy"</span>),</span>
<span id="cb13-4"><a href="#cb13-4"></a>    (<span class="va">None</span>,<span class="st">"Michael"</span>)</span>
<span id="cb13-5"><a href="#cb13-5"></a>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The column names must be set to “age” and “name”.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb14-2"><a href="#cb14-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb14-3"><a href="#cb14-3"></a></span>
<span id="cb14-4"><a href="#cb14-4"></a><span class="co">## Create a Python list of tuples</span></span>
<span id="cb14-5"><a href="#cb14-5"></a>profilesList <span class="op">=</span> [</span>
<span id="cb14-6"><a href="#cb14-6"></a>    (<span class="dv">19</span>,<span class="st">"Justin"</span>),</span>
<span id="cb14-7"><a href="#cb14-7"></a>    (<span class="dv">30</span>,<span class="st">"Andy"</span>),</span>
<span id="cb14-8"><a href="#cb14-8"></a>    (<span class="va">None</span>,<span class="st">"Michael"</span>)</span>
<span id="cb14-9"><a href="#cb14-9"></a>]</span>
<span id="cb14-10"><a href="#cb14-10"></a></span>
<span id="cb14-11"><a href="#cb14-11"></a><span class="co">## Create a DataFrame from the profilesList</span></span>
<span id="cb14-12"><a href="#cb14-12"></a>df <span class="op">=</span> spark.createDataFrame(profilesList,[<span class="st">"age"</span>,<span class="st">"name"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="from-dataframe-to-rdd" class="level4">
<h4 class="anchored" data-anchor-id="from-dataframe-to-rdd">From DataFrame to RDD</h4>
<p>The <code>rdd</code> method of the <code>DataFrame</code> class returns an RDD of Row objects containing the content of the DataFrame which it is invoked on. Each <code>Row</code> object is like a dictionary containing the values of a record: it contains column names in the keys and column values in the values.</p>
<section id="usage-of-the-row-class" class="level5">
<h5 class="anchored" data-anchor-id="usage-of-the-row-class">Usage of the Row class</h5>
<p>The fields in it can be accessed:</p>
<ul>
<li>like attributes: <code>row.key</code>, where <code>key</code> is a column name;</li>
<li>like dictionary values: <code>row["key"]</code>;</li>
<li>using <code>for key in row</code> will search through row keys.</li>
</ul>
<p>Also the <code>asDict()</code> method returns the Row content as a Python dictionary.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from a csv file containing the profiles of a set of people: each line of the file contains name and age of a person, but the first line contains the header (i.e., the name of the attributes/columns);</li>
<li>Transform the input DataFrame into an RDD, select only the name field/column and store the result in the output folder.</li>
</ol>
<div class="sourceCode" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb15-2"><a href="#cb15-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb15-3"><a href="#cb15-3"></a></span>
<span id="cb15-4"><a href="#cb15-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb15-5"><a href="#cb15-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb15-6"><a href="#cb15-6"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb15-7"><a href="#cb15-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb15-8"><a href="#cb15-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb15-9"><a href="#cb15-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb15-10"><a href="#cb15-10"></a>)</span>
<span id="cb15-11"><a href="#cb15-11"></a></span>
<span id="cb15-12"><a href="#cb15-12"></a><span class="co">## Define an RDD based on the content of</span></span>
<span id="cb15-13"><a href="#cb15-13"></a><span class="co">## the DataFrame</span></span>
<span id="cb15-14"><a href="#cb15-14"></a>rddRows <span class="op">=</span> df.rdd</span>
<span id="cb15-15"><a href="#cb15-15"></a></span>
<span id="cb15-16"><a href="#cb15-16"></a><span class="co">## Use the map transformation to extract</span></span>
<span id="cb15-17"><a href="#cb15-17"></a><span class="co">## the name field/column</span></span>
<span id="cb15-18"><a href="#cb15-18"></a>rddNames <span class="op">=</span> rddRows.<span class="bu">map</span>(<span class="kw">lambda</span> row: row.name)</span>
<span id="cb15-19"><a href="#cb15-19"></a></span>
<span id="cb15-20"><a href="#cb15-20"></a><span class="co">## Store the result</span></span>
<span id="cb15-21"><a href="#cb15-21"></a>rddNames.saveAsTextFile(outputPath)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="operations-on-dataframes" class="level3">
<h3 class="anchored" data-anchor-id="operations-on-dataframes">Operations on DataFrames</h3>
<p>A set of specific methods are available for the <code>DataFrame</code> class (e.g., <code>show()</code>, <code>printSchema()</code>, <code>count()</code>, <code>distinct()</code>, <code>select()</code>, <code>filter()</code>), also the standard <code>collect()</code> and <code>count()</code> actions are available.</p>
<section id="show-method" class="level4">
<h4 class="anchored" data-anchor-id="show-method">Show method</h4>
<p>The <code>show(n)</code> method of the <code>DataFrame</code> class prints on the standard output the first <code>n</code> of the input DataFrame. Default value of <code>n</code> is 20.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from a csv file containing the profiles of a set of people;</li>
<li>Print the content of the first 2 people (i.e., the first 2 rows of the DataFrame).</li>
</ol>
<p>The content of people.csv is</p>
<pre><code>name,age
Andy,30
Michael,
Justin,19</code></pre>
<div class="sourceCode" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb17-2"><a href="#cb17-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb17-3"><a href="#cb17-3"></a></span>
<span id="cb17-4"><a href="#cb17-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb17-5"><a href="#cb17-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb17-6"><a href="#cb17-6"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb17-7"><a href="#cb17-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb17-8"><a href="#cb17-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb17-9"><a href="#cb17-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb17-10"><a href="#cb17-10"></a>)</span>
<span id="cb17-11"><a href="#cb17-11"></a></span>
<span id="cb17-12"><a href="#cb17-12"></a>df.show(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="printschema-method" class="level4">
<h4 class="anchored" data-anchor-id="printschema-method">PrintSchema method</h4>
<p>The <code>printSchema()</code> method of the <code>DataFrame</code> class prints on the standard output the schema of the DataFrame (i.e., the name of the attributes of the data stored in the DataFrame).</p>
</section>
<section id="count-method" class="level4">
<h4 class="anchored" data-anchor-id="count-method">Count method</h4>
<p>The <code>count()</code> method of the <code>DataFrame</code> class returns the number of rows in the input DataFrame.</p>
</section>
<section id="distinct-method" class="level4">
<h4 class="anchored" data-anchor-id="distinct-method">Distinct method</h4>
<p>The <code>distinct()</code> method of the <code>DataFrame</code> class returns a new DataFrame that contains only the unique rows of the input DataFrame. A shuffle phase is needed.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pay attention that the distinct operation is always an heavy operation in terms of data sent on the network.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from a csv file containing the names of a set of people. The first line is the header.</li>
<li>Create a new DataFrame without duplicates.</li>
</ol>
<p>The content of “names.csv” is</p>
<pre><code>name
Andy
Michael
Justin
Michael</code></pre>
<div class="sourceCode" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb19-2"><a href="#cb19-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb19-3"><a href="#cb19-3"></a></span>
<span id="cb19-4"><a href="#cb19-4"></a><span class="co">## Create a DataFrame from names.csv</span></span>
<span id="cb19-5"><a href="#cb19-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb19-6"><a href="#cb19-6"></a>    <span class="st">"names.csv"</span>,</span>
<span id="cb19-7"><a href="#cb19-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb19-8"><a href="#cb19-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb19-9"><a href="#cb19-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb19-10"><a href="#cb19-10"></a>)</span>
<span id="cb19-11"><a href="#cb19-11"></a></span>
<span id="cb19-12"><a href="#cb19-12"></a>df_distinct <span class="op">=</span> df.distinct()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="select-method" class="level4">
<h4 class="anchored" data-anchor-id="select-method">Select method</h4>
<p>The <code>select(col1, ..., coln)</code> method of the <code>DataFrame</code> class returns a new DataFrame that contains only the specified columns of the input DataFrame. Use <code>*</code> as special column to select all columns</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pay attention that the select method can generate errors at runtime if there are mistakes in the names of the columns.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from the “people2.csv” file that scontains the profiles of a set of people
<ul>
<li>The first line contains the header;</li>
<li>The others lines contain the users’ profiles: one line per person, and each line contains name, age, and gender of a person.</li>
</ul></li>
<li>Create a new DataFrame containing only name and age of the people.</li>
</ol>
<p>The “people2.csv” has the following structure</p>
<pre><code>name,age,gender
Paul,40,male
John,40,male</code></pre>
<div class="sourceCode" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb21-2"><a href="#cb21-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb21-3"><a href="#cb21-3"></a></span>
<span id="cb21-4"><a href="#cb21-4"></a><span class="co">## Create a DataFrame from people2.csv</span></span>
<span id="cb21-5"><a href="#cb21-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb21-6"><a href="#cb21-6"></a>    <span class="st">"people2.csv"</span>,</span>
<span id="cb21-7"><a href="#cb21-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb21-8"><a href="#cb21-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb21-9"><a href="#cb21-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb21-10"><a href="#cb21-10"></a>)</span>
<span id="cb21-11"><a href="#cb21-11"></a></span>
<span id="cb21-12"><a href="#cb21-12"></a>dfNamesAges <span class="op">=</span> df.select(<span class="st">"name"</span>,<span class="st">"age"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="selectexpr-method" class="level4">
<h4 class="anchored" data-anchor-id="selectexpr-method">SelectExpr method</h4>
<p>The <code>selectExpr(expression1,...,expressionN)</code> method of the <code>DataFrame</code> class is a variant of the select method, where <code>expr</code> can be a SQL expression.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from the “people2.csv” file that scontains the profiles of a set of people
<ul>
<li>The first line contains the header;</li>
<li>The others lines contain the users’ profiles: one line per person, and each line contains name, age, and gender of a person.</li>
</ul></li>
<li>Create a new DataFrame containing only name and age of the people.</li>
<li>Create a new DataFrame containing only the name of the people and their age plus one. Call the age column as “new_age”.</li>
</ol>
<p>The “people2.csv” has the following structure</p>
<pre><code>name,age,gender
Paul,40,male
John,40,male</code></pre>
<div class="sourceCode" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb23-2"><a href="#cb23-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb23-3"><a href="#cb23-3"></a></span>
<span id="cb23-4"><a href="#cb23-4"></a><span class="co">## Create a DataFrame from people2.csv</span></span>
<span id="cb23-5"><a href="#cb23-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb23-6"><a href="#cb23-6"></a>    <span class="st">"people2.csv"</span>,</span>
<span id="cb23-7"><a href="#cb23-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb23-8"><a href="#cb23-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb23-9"><a href="#cb23-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb23-10"><a href="#cb23-10"></a>)</span>
<span id="cb23-11"><a href="#cb23-11"></a></span>
<span id="cb23-12"><a href="#cb23-12"></a>dfNamesAges <span class="op">=</span> df.selectExpr(<span class="st">"name"</span>,<span class="st">"age"</span>)</span>
<span id="cb23-13"><a href="#cb23-13"></a></span>
<span id="cb23-14"><a href="#cb23-14"></a>dfNamesAgesMod <span class="op">=</span> df.selectExpr(<span class="st">"name"</span>, <span class="st">"age + 1 AS new_age"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from the “people2.csv” file that contains the profiles of a set of people</li>
</ol>
<ul>
<li>The first line contains the header;</li>
<li>The others lines contain the users’ profiles: each line contains name, age, and gender of a person.</li>
</ul>
<ol start="2" type="1">
<li>Create a new DataFrame containing the same columns of the initial dataset plus an additional column called “newAge” containing the value of age incremented by one.</li>
</ol>
<p>The “people2.csv” has the following structure</p>
<pre><code>name,age,gender
Paul,40,male
John,40,male</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb25-2"><a href="#cb25-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb25-3"><a href="#cb25-3"></a></span>
<span id="cb25-4"><a href="#cb25-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb25-5"><a href="#cb25-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb25-6"><a href="#cb25-6"></a>    <span class="st">"people2.csv"</span>,</span>
<span id="cb25-7"><a href="#cb25-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb25-8"><a href="#cb25-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb25-9"><a href="#cb25-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb25-10"><a href="#cb25-10"></a>)</span>
<span id="cb25-11"><a href="#cb25-11"></a></span>
<span id="cb25-12"><a href="#cb25-12"></a><span class="co">## Create a new DataFrame with four columns:</span></span>
<span id="cb25-13"><a href="#cb25-13"></a><span class="co">## name, age, gender, newAge = age +1</span></span>
<span id="cb25-14"><a href="#cb25-14"></a>dfNewAge <span class="op">=</span> df.selectExpr(</span>
<span id="cb25-15"><a href="#cb25-15"></a>    <span class="st">"name"</span>,</span>
<span id="cb25-16"><a href="#cb25-16"></a>    <span class="st">"age"</span>,</span>
<span id="cb25-17"><a href="#cb25-17"></a>    <span class="st">"gender"</span>,</span>
<span id="cb25-18"><a href="#cb25-18"></a>    <span class="st">"age+1 as newAge"</span></span>
<span id="cb25-19"><a href="#cb25-19"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 66%">
</colgroup>
<tbody>
<tr class="odd">
<td><code>"... as newAge"</code></td>
<td>This part of the expression is used to specify the name of the column associated with the result of the first part of the expression in the returned DataFrame. Without this part of the expression, the name of the returned column would be “age+1”.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="filter-method" class="level4">
<h4 class="anchored" data-anchor-id="filter-method">Filter method</h4>
<p>The <code>filter(conditionExpr)</code> method of the <code>DataFrame</code> class returns a new DataFrame that contains only the rows satisfying the specified condition. The condition is expressed as a Boolean SQL expression.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pay attention that this version of the filter method can generate errors at runtime if there are errors in the filter expression: the parameter is a string and the system cannot check the correctness of the expression at compile time.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from the “people.csv” file that contains the profiles of a set of people
<ul>
<li>The first line contains the header;</li>
<li>The others lines contain the users’ profiles: each line contains name and age of a person.</li>
</ul></li>
<li>Create a new DataFrame containing only the people with age between 20 and 31.</li>
</ol>
<div class="sourceCode" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb26-2"><a href="#cb26-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb26-3"><a href="#cb26-3"></a></span>
<span id="cb26-4"><a href="#cb26-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb26-5"><a href="#cb26-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb26-6"><a href="#cb26-6"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb26-7"><a href="#cb26-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb26-8"><a href="#cb26-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb26-9"><a href="#cb26-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb26-10"><a href="#cb26-10"></a>)</span>
<span id="cb26-11"><a href="#cb26-11"></a></span>
<span id="cb26-12"><a href="#cb26-12"></a>df_filtered <span class="op">=</span> df.<span class="bu">filter</span>(<span class="st">"age&gt;=20 and age&lt;=31"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="where-method" class="level4">
<h4 class="anchored" data-anchor-id="where-method">Where method</h4>
<p>The <code>where(expression)</code> method of the <code>DataFrame</code> class is an alias of the <code>filter(conditionExpr)</code> method.</p>
</section>
<section id="join" class="level4">
<h4 class="anchored" data-anchor-id="join">Join</h4>
<p>The <code>join(right, on, how)</code> method of the <code>DataFrame</code> class is used to join two DataFrames. It returns a DataFrame that contains the join of the tuples of the two input DataFrames based on the <code>on</code> join condition.</p>
<p><code>on</code> specifies the join condition. It can be:</p>
<ul>
<li>a string: the column to join</li>
<li>a list of strings: multiple columns to join</li>
<li>a condition/an expression on the columns (e.g., <code>joined_df = df.join(df2, df.name == df2.name)</code>)</li>
</ul>
<p><code>how</code> specifies the type of join</p>
<ul>
<li><code>inner</code> (default type of join)</li>
<li><code>cross</code></li>
<li><code>outer</code></li>
<li><code>full</code></li>
<li><code>full_outer</code></li>
<li><code>left</code></li>
<li><code>left_outer</code></li>
<li><code>right</code></li>
<li><code>right_outer</code></li>
<li><code>left_semi</code></li>
<li><code>left_anti</code></li>
</ul>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pay attention that this method: can generate errors at runtime if there are errors in the join expression.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create two DataFrames
<ul>
<li>One based on the “people_id.csv” file that contains the profiles of a set of people, the schema is: uid, name, age;</li>
<li>One based on the liked_sports.csv file that contains the liked sports for each person, the schema is: uid, sportname. 2.Join the content of the two DataFrames (uid is the join column) and show it on the standard output.</li>
</ul></li>
</ol>
<div class="sourceCode" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb27-2"><a href="#cb27-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb27-3"><a href="#cb27-3"></a></span>
<span id="cb27-4"><a href="#cb27-4"></a><span class="co">## Read people_id.csv and store it in a DataFrame</span></span>
<span id="cb27-5"><a href="#cb27-5"></a>dfPeople <span class="op">=</span> spark.read.load(</span>
<span id="cb27-6"><a href="#cb27-6"></a>    <span class="st">"people_id.csv"</span>,</span>
<span id="cb27-7"><a href="#cb27-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb27-8"><a href="#cb27-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb27-9"><a href="#cb27-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb27-10"><a href="#cb27-10"></a>)</span>
<span id="cb27-11"><a href="#cb27-11"></a></span>
<span id="cb27-12"><a href="#cb27-12"></a><span class="co">## Read liked_sports.csv and store it in a DataFrame</span></span>
<span id="cb27-13"><a href="#cb27-13"></a>dfUidSports <span class="op">=</span> spark.read.load(</span>
<span id="cb27-14"><a href="#cb27-14"></a>    <span class="st">"liked_sports.csv"</span>,</span>
<span id="cb27-15"><a href="#cb27-15"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb27-16"><a href="#cb27-16"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb27-17"><a href="#cb27-17"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb27-18"><a href="#cb27-18"></a>)</span>
<span id="cb27-19"><a href="#cb27-19"></a></span>
<span id="cb27-20"><a href="#cb27-20"></a><span class="co">## Join the two input DataFrames</span></span>
<span id="cb27-21"><a href="#cb27-21"></a>dfPersonLikes <span class="op">=</span> dfPeople.join(</span>
<span id="cb27-22"><a href="#cb27-22"></a>    dfUidSports,</span>
<span id="cb27-23"><a href="#cb27-23"></a>    dfPeople.uid <span class="op">==</span> dfUidSports.uid</span>
<span id="cb27-24"><a href="#cb27-24"></a>)</span>
<span id="cb27-25"><a href="#cb27-25"></a></span>
<span id="cb27-26"><a href="#cb27-26"></a><span class="co">## Print the result on the standard output</span></span>
<span id="cb27-27"><a href="#cb27-27"></a>dfPersonLikes.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<tbody>
<tr class="odd">
<td><code>dfPeople.uid == dfUidSports.uid</code></td>
<td>Specify the join condition on the uid columns.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create two DataFrames
<ul>
<li>One based on the “people_id.csv” file that contains the profiles of a set of people, the schema is: uid, name, age;</li>
<li>One based on the banned.csv file that contains the banned users, the schema is: uid, bannedmotivation.</li>
</ul></li>
<li>Select the profiles of the non-banned users and show them on the standard output.</li>
</ol>
<div class="sourceCode" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb28-2"><a href="#cb28-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb28-3"><a href="#cb28-3"></a></span>
<span id="cb28-4"><a href="#cb28-4"></a><span class="co">## Read people_id.csv and store it in a DataFrame</span></span>
<span id="cb28-5"><a href="#cb28-5"></a>dfPeople <span class="op">=</span> spark.read.load(</span>
<span id="cb28-6"><a href="#cb28-6"></a>    <span class="st">"people_id.csv"</span>,</span>
<span id="cb28-7"><a href="#cb28-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb28-8"><a href="#cb28-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb28-9"><a href="#cb28-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb28-10"><a href="#cb28-10"></a>)</span>
<span id="cb28-11"><a href="#cb28-11"></a></span>
<span id="cb28-12"><a href="#cb28-12"></a><span class="co">## Read banned.csv and store it in a DataFrame</span></span>
<span id="cb28-13"><a href="#cb28-13"></a>dfBannedUsers <span class="op">=</span> spark.read.load(</span>
<span id="cb28-14"><a href="#cb28-14"></a>    <span class="st">"banned.csv"</span>,</span>
<span id="cb28-15"><a href="#cb28-15"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb28-16"><a href="#cb28-16"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb28-17"><a href="#cb28-17"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb28-18"><a href="#cb28-18"></a>)</span>
<span id="cb28-19"><a href="#cb28-19"></a></span>
<span id="cb28-20"><a href="#cb28-20"></a><span class="co">## Apply the Left Anti Join on the two input DataFrames</span></span>
<span id="cb28-21"><a href="#cb28-21"></a>dfSelectedProfiles <span class="op">=</span> dfPeople.join(</span>
<span id="cb28-22"><a href="#cb28-22"></a>    dfBannedUsers,</span>
<span id="cb28-23"><a href="#cb28-23"></a>    dfPeople.uid <span class="op">==</span> dfBannedUsers.uid,</span>
<span id="cb28-24"><a href="#cb28-24"></a>    <span class="st">"left_anti"</span></span>
<span id="cb28-25"><a href="#cb28-25"></a>)</span>
<span id="cb28-26"><a href="#cb28-26"></a></span>
<span id="cb28-27"><a href="#cb28-27"></a><span class="co">## Print the result on the standard output</span></span>
<span id="cb28-28"><a href="#cb28-28"></a>dfSelectedProfiles.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 50%">
<col style="width: 50%">
</colgroup>
<tbody>
<tr class="odd">
<td><code>dfPeople.uid == dfUidSports.uid</code></td>
<td>Specify the (anti) join condition on the uid columns.</td>
</tr>
<tr class="even">
<td><code>"left_anti"</code></td>
<td>Use Left Anti Join.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="aggregate-functions" class="level4">
<h4 class="anchored" data-anchor-id="aggregate-functions">Aggregate functions</h4>
<p>Aggregate functions are provided to compute aggregates over the set of values of columns. Some of the provided aggregate functions/methods are</p>
<ul>
<li><code>avg(column)</code></li>
<li><code>count(column)</code></li>
<li><code>sum(column)</code></li>
<li><code>abs(column)</code></li>
<li>…</li>
</ul>
<p>Each aggregate function returns one value computed by considering all the values of the input column.</p>
<p>The <code>agg(expr)</code> method of the <code>DataFrame</code> class is used to specify which aggregate function we want to apply on one input column. The result is a DataFrame containing one single row and one single column, and the name of the return column is “function_name(column)”.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pay attention that this methods can generate errors at runtime (e.g., wrong attribute name, wrong data type).</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from the “people.csv” file that contains the profiles of a set of people (each line contains name and age of a person)
<ul>
<li>The first line contains the header;</li>
<li>The others lines contain the users’ profiles.</li>
</ul></li>
<li>Create a Dataset containing the average value of age.</li>
</ol>
<p>Input file example</p>
<pre><code>name,age
Andy,30
Michael,15
Justin,19
Andy,40</code></pre>
<p>Expected output example</p>
<pre><code>avg(age)
26.0</code></pre>
<div class="sourceCode" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb31-2"><a href="#cb31-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb31-3"><a href="#cb31-3"></a></span>
<span id="cb31-4"><a href="#cb31-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb31-5"><a href="#cb31-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb31-6"><a href="#cb31-6"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb31-7"><a href="#cb31-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb31-8"><a href="#cb31-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb31-9"><a href="#cb31-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb31-10"><a href="#cb31-10"></a>)</span>
<span id="cb31-11"><a href="#cb31-11"></a></span>
<span id="cb31-12"><a href="#cb31-12"></a><span class="co">## Compute the average of age</span></span>
<span id="cb31-13"><a href="#cb31-13"></a>averageAge <span class="op">=</span> df.agg({<span class="st">"age"</span>: <span class="st">"avg"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="groupby-and-aggregate-functions" class="level4">
<h4 class="anchored" data-anchor-id="groupby-and-aggregate-functions">groupBy and aggregate functions</h4>
<p>The method <code>groupBy(col1, ..., coln)</code> method of the <code>DataFrame</code> class combined with a set of aggregate methods can be used to split the input data in groups and compute aggregate function over each group.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Caution
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pay attention that this methods can generate errors at runtime if there are semantic errors (e.g., wrong attribute names, wrong data types).</p>
</div>
</div>
<p>It is possible to specify which attributes are used to split the input data in groups by using the <code>groupBy(col1, ..., coln)</code> method, and then, apply the aggregate functions to compute by final result (the result is a DataFrame).</p>
<p>Some of the provided aggregate functions/methods are</p>
<ul>
<li><code>avg(column)</code></li>
<li><code>count(column)</code></li>
<li><code>sum(column)</code></li>
<li><code>abs(column)</code></li>
<li>…</li>
</ul>
<p>Otherwise, the <code>agg()</code> method can be used to apply multiple aggregate functions at the same time over each group.</p>
<p>See the static methods of the <code>pyspark.sql.GroupedData</code> class for a complete list.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-22-contents" aria-controls="callout-22" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-22" class="callout-22-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from the “people.csv” file that contains the profiles of a set of people</li>
</ol>
<ul>
<li>The first line contains the header;</li>
<li>The others lines contain the users’ profiles: each line contains name and age of a person.</li>
</ul>
<ol start="2" type="1">
<li>Create a DataFrame containing the for each name the average value of age.</li>
</ol>
<p>Input file example</p>
<pre><code>name,age
Andy,30
Michael,15
Justin,19
Andy,40</code></pre>
<p>Expected output example</p>
<pre><code>name,avg(age)
Andy,35
Michael,15
Justin,19</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb34-2"><a href="#cb34-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb34-3"><a href="#cb34-3"></a></span>
<span id="cb34-4"><a href="#cb34-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb34-5"><a href="#cb34-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb34-6"><a href="#cb34-6"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb34-7"><a href="#cb34-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb34-8"><a href="#cb34-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb34-9"><a href="#cb34-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb34-10"><a href="#cb34-10"></a>)</span>
<span id="cb34-11"><a href="#cb34-11"></a></span>
<span id="cb34-12"><a href="#cb34-12"></a>grouped <span class="op">=</span> df.groupBy(<span class="st">"name"</span>).avg(<span class="st">"age"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-23-contents" aria-controls="callout-23" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-23" class="callout-23-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from the “people.csv” file that contains the profiles of a set of people
<ul>
<li>The first line contains the header</li>
<li>The others lines contain the users’ profiles: each line contains name and age of a person</li>
</ul></li>
<li>Create a DataFrame containing the for each name the average value of age and the number of person with that name</li>
</ol>
<p>Input file example</p>
<pre><code>name,age
Andy,30
Michael,15
Justin,19
Andy,40</code></pre>
<p>Expected output example</p>
<pre><code>name,avg(age),count(name)
Andy,35,2
Michael,15,1
Justin,19,1</code></pre>
<div class="sourceCode" id="cb37"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb37-2"><a href="#cb37-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb37-3"><a href="#cb37-3"></a></span>
<span id="cb37-4"><a href="#cb37-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb37-5"><a href="#cb37-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb37-6"><a href="#cb37-6"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb37-7"><a href="#cb37-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb37-8"><a href="#cb37-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb37-9"><a href="#cb37-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb37-10"><a href="#cb37-10"></a>)</span>
<span id="cb37-11"><a href="#cb37-11"></a></span>
<span id="cb37-12"><a href="#cb37-12"></a>grouped <span class="op">=</span> df.groupBy(<span class="st">"name"</span>) <span class="op">\</span></span>
<span id="cb37-13"><a href="#cb37-13"></a>    .agg({<span class="st">"age"</span>: <span class="st">"avg"</span>, <span class="st">"name"</span>: <span class="st">"count"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="sort-method" class="level4">
<h4 class="anchored" data-anchor-id="sort-method">Sort method</h4>
<p>The <code>sort(col1, ..., coln, ascending=True)</code> method of the DataFrame class returns a new DataFrame that contains the same data of the input one, but whose content is sorted by <code>col1, ..., coln</code>. <code>ascending</code> determines if the sort should be ascending (<code>True</code>) or descending (<code>False</code>).</p>
</section>
</section>
<section id="dataframes-and-the-sql-language" class="level3">
<h3 class="anchored" data-anchor-id="dataframes-and-the-sql-language">DataFrames and the SQL language</h3>
<p>Sparks allows querying the content of a DataFrame also by using the SQL language, but in order to do this a table name must be assigned to a DataFrame. The <code>createOrReplaceTempView(tableName)</code> method of the <code>DataFrame</code> class can be used to assign a <code>tableName</code> as table name to the DataFrame which it is invoked on.</p>
<p>Once the DataFrame has been mapped to table names, SQL-like queries can be executed (the executed queries return DataFrame objects). The <code>sql(query)</code> method of the <code>SparkSession</code> class can be used to execute a SQL-like query, where <code>query</code> is a SQL-like query. Currently some SQL features are not supported (e.g., nested subqueries in the “WHERE” clause are not allowed).</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-24-contents" aria-controls="callout-24" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-24" class="callout-24-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from a JSON file containing the profiles of a set of people: each line of the file contains a JSON object containing name, age, and gender of a person;</li>
<li>Create a new DataFrame containing only the people with age between 20 and 31 and print them on the standard output (use the SQL language to perform this operation).</li>
</ol>
<div class="sourceCode" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb38-2"><a href="#cb38-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb38-3"><a href="#cb38-3"></a></span>
<span id="cb38-4"><a href="#cb38-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb38-5"><a href="#cb38-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb38-6"><a href="#cb38-6"></a>    <span class="st">"people.json"</span>,</span>
<span id="cb38-7"><a href="#cb38-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"json"</span></span>
<span id="cb38-8"><a href="#cb38-8"></a>)</span>
<span id="cb38-9"><a href="#cb38-9"></a></span>
<span id="cb38-10"><a href="#cb38-10"></a><span class="co">## Assign the “table name” people to the df DataFrame</span></span>
<span id="cb38-11"><a href="#cb38-11"></a>df.createOrReplaceTempView(<span class="st">"people"</span>)</span>
<span id="cb38-12"><a href="#cb38-12"></a></span>
<span id="cb38-13"><a href="#cb38-13"></a><span class="co">## Select the people with age between 20 and 31</span></span>
<span id="cb38-14"><a href="#cb38-14"></a><span class="co">## by querying the people table</span></span>
<span id="cb38-15"><a href="#cb38-15"></a>selectedPeople <span class="op">=</span> spark.sql(</span>
<span id="cb38-16"><a href="#cb38-16"></a>    <span class="st">"SELECT * FROM people WHERE age&gt;=20 and age&lt;=31"</span></span>
<span id="cb38-17"><a href="#cb38-17"></a>)</span>
<span id="cb38-18"><a href="#cb38-18"></a></span>
<span id="cb38-19"><a href="#cb38-19"></a><span class="co">## Print the result on the standard output</span></span>
<span id="cb38-20"><a href="#cb38-20"></a>selectedPeople.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-25-contents" aria-controls="callout-25" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-25" class="callout-25-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create two DataFrames
<ul>
<li>One based on the “people_id.csv” file that contains the profiles of a set of people, the schema is: uid, name, age;</li>
<li>One based on the “liked_sports.csv” file that contains the liked sports for each person, the schema is: uid, sportname.</li>
</ul></li>
<li>Join the content of the two DataFrames and show it on the standard output.</li>
</ol>
<div class="sourceCode" id="cb39"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb39-2"><a href="#cb39-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb39-3"><a href="#cb39-3"></a></span>
<span id="cb39-4"><a href="#cb39-4"></a><span class="co">## Read people_id.csv and store it in a DataFrame</span></span>
<span id="cb39-5"><a href="#cb39-5"></a>dfPeople <span class="op">=</span> spark.read.load(</span>
<span id="cb39-6"><a href="#cb39-6"></a>    <span class="st">"people_id.csv"</span>,</span>
<span id="cb39-7"><a href="#cb39-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb39-8"><a href="#cb39-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb39-9"><a href="#cb39-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb39-10"><a href="#cb39-10"></a>)</span>
<span id="cb39-11"><a href="#cb39-11"></a></span>
<span id="cb39-12"><a href="#cb39-12"></a><span class="co">## Assign the “table name” people to the dfPerson</span></span>
<span id="cb39-13"><a href="#cb39-13"></a>dfPeople.createOrReplaceTempView(<span class="st">"people"</span>)</span>
<span id="cb39-14"><a href="#cb39-14"></a></span>
<span id="cb39-15"><a href="#cb39-15"></a><span class="co">## Read liked_sports.csv and store it in a DataFrame</span></span>
<span id="cb39-16"><a href="#cb39-16"></a>dfUidSports <span class="op">=</span> spark.read.load(</span>
<span id="cb39-17"><a href="#cb39-17"></a>    <span class="st">"liked_sports.csv"</span>,</span>
<span id="cb39-18"><a href="#cb39-18"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb39-19"><a href="#cb39-19"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb39-20"><a href="#cb39-20"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb39-21"><a href="#cb39-21"></a>)</span>
<span id="cb39-22"><a href="#cb39-22"></a></span>
<span id="cb39-23"><a href="#cb39-23"></a><span class="co">## Assign the “table name” liked to dfUidSports</span></span>
<span id="cb39-24"><a href="#cb39-24"></a>dfUidSports.createOrReplaceTempView(<span class="st">"liked"</span>)</span>
<span id="cb39-25"><a href="#cb39-25"></a></span>
<span id="cb39-26"><a href="#cb39-26"></a><span class="co">## Join the two input tables by using the</span></span>
<span id="cb39-27"><a href="#cb39-27"></a><span class="co">#SQL-like syntax</span></span>
<span id="cb39-28"><a href="#cb39-28"></a>dfPersonLikes <span class="op">=</span> spark.sql(</span>
<span id="cb39-29"><a href="#cb39-29"></a>    <span class="st">"SELECT * from people, liked where people.uid=liked.uid"</span></span>
<span id="cb39-30"><a href="#cb39-30"></a>)</span>
<span id="cb39-31"><a href="#cb39-31"></a></span>
<span id="cb39-32"><a href="#cb39-32"></a><span class="co">## Print the result on the standard output</span></span>
<span id="cb39-33"><a href="#cb39-33"></a>dfPersonLikes.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-26-contents" aria-controls="callout-26" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 3
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-26" class="callout-26-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from the “people.csv” file that contains the profiles of a set of people
<ul>
<li>The first line contains the header;</li>
<li>The others lines contain the users’ profiles: each line contains name and age of a person.</li>
</ul></li>
<li>Create a DataFrame containing for each name the average value of age and the number of person with that name. Print its content on the standard output.</li>
</ol>
<p>Input file example</p>
<pre><code>name,age
Andy,30
Michael,15
Justin,19
Andy,40</code></pre>
<p>Expected output example</p>
<pre><code>name,avg(age),count(name)
Andy,35,2
Michael,15,1
Justin,19,1</code></pre>
<div class="sourceCode" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb42-2"><a href="#cb42-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb42-3"><a href="#cb42-3"></a></span>
<span id="cb42-4"><a href="#cb42-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb42-5"><a href="#cb42-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb42-6"><a href="#cb42-6"></a>    <span class="st">"people.json"</span>,</span>
<span id="cb42-7"><a href="#cb42-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"json"</span></span>
<span id="cb42-8"><a href="#cb42-8"></a>)</span>
<span id="cb42-9"><a href="#cb42-9"></a></span>
<span id="cb42-10"><a href="#cb42-10"></a><span class="co">## Assign the “table name” people to the df DataFrame</span></span>
<span id="cb42-11"><a href="#cb42-11"></a>df.createOrReplaceTempView(<span class="st">"people"</span>)</span>
<span id="cb42-12"><a href="#cb42-12"></a></span>
<span id="cb42-13"><a href="#cb42-13"></a><span class="co">## Define groups based on the value of name and</span></span>
<span id="cb42-14"><a href="#cb42-14"></a><span class="co">## compute average and number of records for each group</span></span>
<span id="cb42-15"><a href="#cb42-15"></a>nameAvgAgeCount <span class="op">=</span> spark.sql(</span>
<span id="cb42-16"><a href="#cb42-16"></a>    <span class="st">"SELECT name, avg(age), count(name) FROM people GROUP BY name"</span></span>
<span id="cb42-17"><a href="#cb42-17"></a>)</span>
<span id="cb42-18"><a href="#cb42-18"></a></span>
<span id="cb42-19"><a href="#cb42-19"></a><span class="co">## Print the result on the standard output</span></span>
<span id="cb42-20"><a href="#cb42-20"></a>nameAvgAgeCount.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="save-dataframes" class="level3">
<h3 class="anchored" data-anchor-id="save-dataframes">Save DataFrames</h3>
<p>The content of DataFrames can be stored on disk by using two approches</p>
<ul>
<li>Convert DataFrames to traditional RDDs by using the rdd method of the DataFrame, and then use <code>saveAsTextFile(outputFolder)</code>;</li>
<li>Use the <code>write()</code> method of DataFrames, that returns a <code>DatFrameWriter</code> class instance.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-27-contents" aria-controls="callout-27" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 1
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-27" class="callout-27-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from the “people.csv” file that contains the profiles of a set of people
<ul>
<li>The first line contains the header;</li>
<li>The others lines contain the users’ profiles: each line contains name, age, and gender of a person.</li>
</ul></li>
<li>Store the DataFrame in the output folder by using the <code>saveAsTextFile()</code> method.</li>
</ol>
<div class="sourceCode" id="cb43"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb43-2"><a href="#cb43-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb43-3"><a href="#cb43-3"></a></span>
<span id="cb43-4"><a href="#cb43-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb43-5"><a href="#cb43-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb43-6"><a href="#cb43-6"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb43-7"><a href="#cb43-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb43-8"><a href="#cb43-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb43-9"><a href="#cb43-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb43-10"><a href="#cb43-10"></a>)</span>
<span id="cb43-11"><a href="#cb43-11"></a></span>
<span id="cb43-12"><a href="#cb43-12"></a><span class="co">## Save it</span></span>
<span id="cb43-13"><a href="#cb43-13"></a>df.rdd.saveAsTextFile(outputPath)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-28-contents" aria-controls="callout-28" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example 2
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-28" class="callout-28-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from the “people.csv” file that contains the profiles of a set of people
<ul>
<li>The first line contains the header;</li>
<li>The others lines contain the users’ profiles: each line contains name, age, and gender of a person.</li>
</ul></li>
<li>Store the DataFrame in the output folder by using the <code>write()</code> method, with the CSV format.</li>
</ol>
<div class="sourceCode" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb44-2"><a href="#cb44-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb44-3"><a href="#cb44-3"></a></span>
<span id="cb44-4"><a href="#cb44-4"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb44-5"><a href="#cb44-5"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb44-6"><a href="#cb44-6"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb44-7"><a href="#cb44-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb44-8"><a href="#cb44-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb44-9"><a href="#cb44-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb44-10"><a href="#cb44-10"></a>)</span>
<span id="cb44-11"><a href="#cb44-11"></a></span>
<span id="cb44-12"><a href="#cb44-12"></a><span class="co">## Save it</span></span>
<span id="cb44-13"><a href="#cb44-13"></a>df.write.csv(outputPath, header<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="udfs-user-defines-functions" class="level3">
<h3 class="anchored" data-anchor-id="udfs-user-defines-functions">UDFs: User Defines Functions</h3>
<p>Spark SQL provides a set of system predefined functions, which can be used in some transformations (e.g., <code>selectExpr()</code>, <code>sort()</code>) but also in the SQL queries. Some examples are</p>
<ul>
<li><code>hour(Timestamp)</code></li>
<li><code>abs(Integer)</code></li>
<li>…</li>
</ul>
<p>However, users can also define custom functions, which are called <strong>User Defined Functions</strong> (<strong>UDFs</strong>).</p>
<p>UDFs are defined/registered by invoking the <code>udf().register(name, function, datatype)</code> on the <code>SparkSession</code>, where</p>
<ul>
<li><code>name</code> is the name of the defined UDF</li>
<li><code>function</code> is a lambda function used to specify how the parameters of the function are used to generate the returned value
<ul>
<li>One of more input parameters are accepted</li>
<li>One single returned value is accepted</li>
</ul></li>
<li><code>datatype</code> is the SQL data type of the returned value</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-29-contents" aria-controls="callout-29" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-29" class="callout-29-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Define a UDFs that, given a string, returns the length of the string.</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb45-2"><a href="#cb45-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb45-3"><a href="#cb45-3"></a></span>
<span id="cb45-4"><a href="#cb45-4"></a><span class="co">## Define the UDF</span></span>
<span id="cb45-5"><a href="#cb45-5"></a><span class="co">## name: length</span></span>
<span id="cb45-6"><a href="#cb45-6"></a><span class="co">## output: integer value</span></span>
<span id="cb45-7"><a href="#cb45-7"></a>spark.udf.register(<span class="st">"length"</span>, <span class="kw">lambda</span> x: <span class="bu">len</span>(x))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Use of the defined UDF in a selectExpr transformation.</p>
<div class="sourceCode" id="cb46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a>result <span class="op">=</span> inputDF.selectExpr(<span class="st">"length(name) as size"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Use of the defined UDF in a SQL query.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1"></a>result <span class="op">=</span> spark.sql(<span class="st">"SELECT length(name) FROM profiles"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="other-notes" class="level3">
<h3 class="anchored" data-anchor-id="other-notes">Other notes</h3>
<section id="data-warehouse-methods-cube-and-rollup" class="level4">
<h4 class="anchored" data-anchor-id="data-warehouse-methods-cube-and-rollup">Data warehouse methods: cube and rollup</h4>
<p>The method <code>cube(col1, ..., coln)</code> of the <code>DataFrame</code> class can be used to create a multi-dimensional cube for the input DataFrame, on top of which aggregate functions can be computed for each group.</p>
<p>The method <code>rollup(col1, ..., coln)</code> of the <code>DataFrame</code> class can be used to create a multi-dimensional rollup for the input DataFrame, on top of which aggregate functions can be computed for each group.</p>
<p>Specify which attributes are used to split the input data in groups by using <code>cube(col1, ..., coln)</code> or <code>rollup(col1, ..., coln)</code>, respectively, then, apply the aggregate functions to compute for each group of the cube/rollup. The result is a DataFrame. The same aggregate functions/methods already discussed for groupBy can be used also for cube and rollup.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-30-contents" aria-controls="callout-30" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-30" class="callout-30-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a DataFrame from the “purchases.csv” file
<ul>
<li>The first line contains the header;</li>
<li>The others lines contain the quantities of purchased products by users: each line contains userid, productid, quantity.</li>
</ul></li>
<li>Create a first DataFrame containing the result of the cube method. Define one group for each pair userid, productid and compute the sum of quantity in each group; 3.Create a second DataFrame containing the result of the rollup method. Define one group for each pair userid, productid and compute the sum of quantity in each group.</li>
</ol>
<p>Input file</p>
<pre><code>userid,productid,quantity
u1,p1,10
u1,p1,20
u1,p2,20
u1,p3,10
u2,p1,20
u2,p3,40
u2,p3,30</code></pre>
<p>Expected output - cube</p>
<pre><code>userid,productid,sum(quantity)
null    null    150
null    p1      50
null    p2      20
null    p3      80
u1      null    60
u1      p1      30
u1      p2      20
u1      p3      10
u2      null    90
u2      p1      20
u2      p3      70</code></pre>
<p>Expected output - rollup</p>
<pre><code>userid,productid,sum(quantity)
null    null    150
u1      null    60
u1      p1      30
u1      p2      20
u1      p3      10
u2      null    90
u2      p1      20
u2      p3      70</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb51-2"><a href="#cb51-2"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb51-3"><a href="#cb51-3"></a></span>
<span id="cb51-4"><a href="#cb51-4"></a><span class="co">## Read purchases.csv and store it in a DataFrame</span></span>
<span id="cb51-5"><a href="#cb51-5"></a>dfPurchases <span class="op">=</span> spark.read.load(</span>
<span id="cb51-6"><a href="#cb51-6"></a>    <span class="st">"purchases.csv"</span>,</span>
<span id="cb51-7"><a href="#cb51-7"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb51-8"><a href="#cb51-8"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb51-9"><a href="#cb51-9"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb51-10"><a href="#cb51-10"></a>)</span>
<span id="cb51-11"><a href="#cb51-11"></a></span>
<span id="cb51-12"><a href="#cb51-12"></a>dfCube<span class="op">=</span>dfPurchases <span class="op">\</span></span>
<span id="cb51-13"><a href="#cb51-13"></a>    .cube(<span class="st">"userid"</span>,<span class="st">"productid"</span>) <span class="op">\</span></span>
<span id="cb51-14"><a href="#cb51-14"></a>    .agg({<span class="st">"quantity"</span>: <span class="st">"sum"</span>})</span>
<span id="cb51-15"><a href="#cb51-15"></a></span>
<span id="cb51-16"><a href="#cb51-16"></a>dfRollup<span class="op">=</span>dfPurchases <span class="op">\</span></span>
<span id="cb51-17"><a href="#cb51-17"></a>    .rollup(<span class="st">"userid"</span>,<span class="st">"productid"</span>)<span class="op">\</span></span>
<span id="cb51-18"><a href="#cb51-18"></a>    .agg({<span class="st">"quantity"</span>: <span class="st">"sum"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>
</section>
<section id="set-methods" class="level4">
<h4 class="anchored" data-anchor-id="set-methods">Set methods</h4>
<p>Similarly to RDDs also DataFrames can be combined by using set transformations</p>
<ul>
<li><code>df1.union(df2)</code></li>
<li><code>df1.intersect(df2)</code></li>
<li><code>df1.subtract(df2)</code></li>
</ul>
</section>
<section id="broadcast-join" class="level4">
<h4 class="anchored" data-anchor-id="broadcast-join">Broadcast join</h4>
<p>Spark SQL automatically implements a broadcast version of the join operation if one of the two input DataFrames is small enough to be stored in the main memory of each executor.</p>
<p>It is possible to suggest/force it by creating a broadcast version of a DataFrame.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-31-contents" aria-controls="callout-31" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-31" class="callout-31-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div class="sourceCode" id="cb52"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1"></a>dfPersonLikesBroadcast <span class="op">=</span> dfUidSports<span class="op">\</span></span>
<span id="cb52-2"><a href="#cb52-2"></a>    .join(</span>
<span id="cb52-3"><a href="#cb52-3"></a>        broadcast(dfPersons),</span>
<span id="cb52-4"><a href="#cb52-4"></a>        dfPersons.uid <span class="op">==</span> dfUidSports.uid</span>
<span id="cb52-5"><a href="#cb52-5"></a>    )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 66%">
</colgroup>
<tbody>
<tr class="odd">
<td><code>broadcast(dfPersons)</code></td>
<td>In this case we specify that <code>dfPersons</code> must be broadcasted and hence Spark will execute the join operation by using a broadcast join.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="execution-plan" class="level4">
<h4 class="anchored" data-anchor-id="execution-plan">Execution plan</h4>
<p>The method <code>explain()</code> can be invoked on a DataFrame to print on the standard output the execution plan of the part of the code that is used to compute the content of the DataFrame on which <code>explain()</code> is invoked.</p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Handle positioning of the toggle
      window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./15b_pagerank.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Introduction to PageRank</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./18a_spark_mllib.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Spark MLlib</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb53" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb53-1"><a href="#cb53-1"></a><span class="fu"># Spark SQL and DataFrames</span></span>
<span id="cb53-2"><a href="#cb53-2"></a><span class="fu">## Spark SQL</span></span>
<span id="cb53-3"><a href="#cb53-3"></a>Spark SQL is the Spark component for structured data processing. It provides a programming abstraction called *Dataframe* and can act as a distributed SQL query engine: the input data can be queried by using</span>
<span id="cb53-4"><a href="#cb53-4"></a></span>
<span id="cb53-5"><a href="#cb53-5"></a><span class="ss">- </span>Ad-hoc methods</span>
<span id="cb53-6"><a href="#cb53-6"></a><span class="ss">- </span>Or an SQL-like language</span>
<span id="cb53-7"><a href="#cb53-7"></a></span>
<span id="cb53-8"><a href="#cb53-8"></a><span class="fu">### Spark SQL vs Spark RDD APIs</span></span>
<span id="cb53-9"><a href="#cb53-9"></a>The interfaces provided by Spark SQL provide more information about the structure of both the data and the computation being performed. Spark SQL uses this extra information to perform extra optimizations based on a "SQL-like" optimizer called **Catalyst**, and so programs based on Dataframe are usually faster than standard RDD-based programs.</span>
<span id="cb53-10"><a href="#cb53-10"></a></span>
<span id="cb53-11"><a href="#cb53-11"></a><span class="al">![Spark SQL vs Spark RDD APIs](images/16_sparksql_dataframes/sql_vs_rdd.png)</span>{width=80%}</span>
<span id="cb53-12"><a href="#cb53-12"></a></span>
<span id="cb53-13"><a href="#cb53-13"></a><span class="fu">### DataFrames</span></span>
<span id="cb53-14"><a href="#cb53-14"></a>A DataFrame is a distributed collection of structured data. It is conceptually equivalent to a table in a relational database, and it can be created reading data from different types of external sources (CSV files, JSON files, RDBMs,...). A DataFrame benefits from Spark SQL optimized execution engine exploiting the information about the data structure.</span>
<span id="cb53-15"><a href="#cb53-15"></a></span>
<span id="cb53-16"><a href="#cb53-16"></a>All the Spark SQL functionalities are based on an instance of the <span class="in">`pyspark.sql.SparkSession`</span> class</span>
<span id="cb53-17"><a href="#cb53-17"></a></span>
<span id="cb53-18"><a href="#cb53-18"></a>To import it in a standalone application use</span>
<span id="cb53-19"><a href="#cb53-19"></a></span>
<span id="cb53-20"><a href="#cb53-20"></a><span class="in">```python</span></span>
<span id="cb53-21"><a href="#cb53-21"></a><span class="im">from</span> pyspark.sql <span class="im">import</span> SparkSession</span>
<span id="cb53-22"><a href="#cb53-22"></a><span class="in">```</span></span>
<span id="cb53-23"><a href="#cb53-23"></a></span>
<span id="cb53-24"><a href="#cb53-24"></a>To instance a <span class="in">`SparkSession`</span> object use </span>
<span id="cb53-25"><a href="#cb53-25"></a></span>
<span id="cb53-26"><a href="#cb53-26"></a><span class="in">```python</span></span>
<span id="cb53-27"><a href="#cb53-27"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-28"><a href="#cb53-28"></a><span class="in">```</span></span>
<span id="cb53-29"><a href="#cb53-29"></a></span>
<span id="cb53-30"><a href="#cb53-30"></a>To close a <span class="in">`SparkSession`</span> use the <span class="in">`SparkSession.stop()`</span> method</span>
<span id="cb53-31"><a href="#cb53-31"></a></span>
<span id="cb53-32"><a href="#cb53-32"></a><span class="in">```python</span></span>
<span id="cb53-33"><a href="#cb53-33"></a>spark.stop()</span>
<span id="cb53-34"><a href="#cb53-34"></a><span class="in">```</span></span>
<span id="cb53-35"><a href="#cb53-35"></a></span>
<span id="cb53-36"><a href="#cb53-36"></a><span class="fu">## DataFrames</span></span>
<span id="cb53-37"><a href="#cb53-37"></a>A DataFrame is a distributed collection of data organized into named columns, equivalent to a relational table: DataFrames are lists of **Row objects**.</span>
<span id="cb53-38"><a href="#cb53-38"></a></span>
<span id="cb53-39"><a href="#cb53-39"></a>The classes used to define DataFrames are</span>
<span id="cb53-40"><a href="#cb53-40"></a></span>
<span id="cb53-41"><a href="#cb53-41"></a><span class="ss">- </span><span class="in">`pyspark.sql.DataFrame`</span></span>
<span id="cb53-42"><a href="#cb53-42"></a><span class="ss">- </span><span class="in">`pyspark.sql.Row`</span></span>
<span id="cb53-43"><a href="#cb53-43"></a></span>
<span id="cb53-44"><a href="#cb53-44"></a>DataFrames can be created from different sources</span>
<span id="cb53-45"><a href="#cb53-45"></a></span>
<span id="cb53-46"><a href="#cb53-46"></a><span class="ss">- </span>Structured (textual) data files (e.g., csv files, json files);</span>
<span id="cb53-47"><a href="#cb53-47"></a><span class="ss">- </span>Existing RDDs;</span>
<span id="cb53-48"><a href="#cb53-48"></a><span class="ss">- </span>Hive tables;</span>
<span id="cb53-49"><a href="#cb53-49"></a><span class="ss">- </span>External relational databases.</span>
<span id="cb53-50"><a href="#cb53-50"></a></span>
<span id="cb53-51"><a href="#cb53-51"></a><span class="fu">### Creating DataFrames from csv files</span></span>
<span id="cb53-52"><a href="#cb53-52"></a>Spark SQL provides an API that allows creating DataFrames directly from CSV files. The creation of a DataFrame from a csv file is based the <span class="in">`load(path)`</span> method of the <span class="in">`pyspark.sql.DataFrameReader`</span> class, where <span class="in">`path`</span> is the path of the input file. To get a <span class="in">`DataFrameReader`</span> using the the <span class="in">`read()`</span> method of the <span class="in">`SparkSession`</span> class.</span>
<span id="cb53-53"><a href="#cb53-53"></a></span>
<span id="cb53-54"><a href="#cb53-54"></a><span class="in">```python</span></span>
<span id="cb53-55"><a href="#cb53-55"></a>df <span class="op">=</span> spark.read.load(path, options)</span>
<span id="cb53-56"><a href="#cb53-56"></a><span class="in">```</span></span>
<span id="cb53-57"><a href="#cb53-57"></a></span>
<span id="cb53-58"><a href="#cb53-58"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-59"><a href="#cb53-59"></a><span class="fu">### Example</span></span>
<span id="cb53-60"><a href="#cb53-60"></a>Create a DataFrame from a csv file ("people.csv") containing the profiles of a set of people. Each line of the file contains name and age of a person, and age can assume the null value (i.e., it can be missing). The first line contains the header (i.e., the names of the attributes/columns).</span>
<span id="cb53-61"><a href="#cb53-61"></a></span>
<span id="cb53-62"><a href="#cb53-62"></a>Example of csv file</span>
<span id="cb53-63"><a href="#cb53-63"></a></span>
<span id="cb53-64"><a href="#cb53-64"></a><span class="in">```</span></span>
<span id="cb53-65"><a href="#cb53-65"></a><span class="in">name,age</span></span>
<span id="cb53-66"><a href="#cb53-66"></a><span class="in">Andy,30</span></span>
<span id="cb53-67"><a href="#cb53-67"></a><span class="in">Michael,</span></span>
<span id="cb53-68"><a href="#cb53-68"></a><span class="in">Justin,19</span></span>
<span id="cb53-69"><a href="#cb53-69"></a><span class="in">```</span></span>
<span id="cb53-70"><a href="#cb53-70"></a></span>
<span id="cb53-71"><a href="#cb53-71"></a>Notice that the age of the second person is unknown.</span>
<span id="cb53-72"><a href="#cb53-72"></a></span>
<span id="cb53-73"><a href="#cb53-73"></a><span class="in">```python</span></span>
<span id="cb53-74"><a href="#cb53-74"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-75"><a href="#cb53-75"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-76"><a href="#cb53-76"></a></span>
<span id="cb53-77"><a href="#cb53-77"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-78"><a href="#cb53-78"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-79"><a href="#cb53-79"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb53-80"><a href="#cb53-80"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-81"><a href="#cb53-81"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-82"><a href="#cb53-82"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-83"><a href="#cb53-83"></a>)</span>
<span id="cb53-84"><a href="#cb53-84"></a><span class="in">```</span></span>
<span id="cb53-85"><a href="#cb53-85"></a></span>
<span id="cb53-86"><a href="#cb53-86"></a>|||</span>
<span id="cb53-87"><a href="#cb53-87"></a>|-|---|</span>
<span id="cb53-88"><a href="#cb53-88"></a>| <span class="in">`format="csv"`</span> | This is used to specify the format of the input file |</span>
<span id="cb53-89"><a href="#cb53-89"></a>| <span class="in">`header=True`</span> | This is used to specify that the first line of the file contains the name of the attributes/columns |</span>
<span id="cb53-90"><a href="#cb53-90"></a>| <span class="in">`inferSchema=True`</span> | This method is used to specify that the system must infer the data types of each column. Without this option all columns are considered strings |</span>
<span id="cb53-91"><a href="#cb53-91"></a></span>
<span id="cb53-92"><a href="#cb53-92"></a>:::</span>
<span id="cb53-93"><a href="#cb53-93"></a></span>
<span id="cb53-94"><a href="#cb53-94"></a><span class="fu">### Creating DataFrames from JSON files</span></span>
<span id="cb53-95"><a href="#cb53-95"></a>Spark SQL provides an API that allows creating a DataFrame directly from a textual file where each line contains a JSON object. Hence, the input file is not a standard JSON file: it must be properly formatted in order to have one JSON object (tuple) for each line. So, the format of the input file must be compliant with the **JSON Lines text format**, also called newline-delimited JSON.</span>
<span id="cb53-96"><a href="#cb53-96"></a></span>
<span id="cb53-97"><a href="#cb53-97"></a>The creation of a DataFrame from JSON files is based on the same method used for reading csv files, that is the <span class="in">`load(path)`</span> method of the <span class="in">`pyspark.sql.DataFrameReader`</span> class, where <span class="in">`path`</span> is the path of the input file. To get a DataFrameReader use the <span class="in">`read()`</span> method of the <span class="in">`SparkSession`</span> class.</span>
<span id="cb53-98"><a href="#cb53-98"></a></span>
<span id="cb53-99"><a href="#cb53-99"></a><span class="in">```python</span></span>
<span id="cb53-100"><a href="#cb53-100"></a>df <span class="op">=</span> spark.read.load(path, <span class="bu">format</span><span class="op">=</span><span class="st">"json"</span>, options)</span>
<span id="cb53-101"><a href="#cb53-101"></a><span class="in">```</span></span>
<span id="cb53-102"><a href="#cb53-102"></a></span>
<span id="cb53-103"><a href="#cb53-103"></a>or</span>
<span id="cb53-104"><a href="#cb53-104"></a></span>
<span id="cb53-105"><a href="#cb53-105"></a><span class="in">```python</span></span>
<span id="cb53-106"><a href="#cb53-106"></a>df <span class="op">=</span> spark.read.json(path, options)</span>
<span id="cb53-107"><a href="#cb53-107"></a><span class="in">```</span></span>
<span id="cb53-108"><a href="#cb53-108"></a></span>
<span id="cb53-109"><a href="#cb53-109"></a>The same API allows also reading standard multiline JSON files by setting the multiline option to true by setting the argument <span class="in">`multiLine=True`</span> on the defined</span>
<span id="cb53-110"><a href="#cb53-110"></a><span class="in">`DataFrameReader`</span> for reading standard JSON files (this feature is available since Spark 2.2.0). </span>
<span id="cb53-111"><a href="#cb53-111"></a></span>
<span id="cb53-112"><a href="#cb53-112"></a>:::{.callout-caution}</span>
<span id="cb53-113"><a href="#cb53-113"></a>Pay attention that reading a set of small JSON files from HDFS is very slow.</span>
<span id="cb53-114"><a href="#cb53-114"></a>:::</span>
<span id="cb53-115"><a href="#cb53-115"></a></span>
<span id="cb53-116"><a href="#cb53-116"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-117"><a href="#cb53-117"></a><span class="fu">### Example 1</span></span>
<span id="cb53-118"><a href="#cb53-118"></a>Create a DataFrame from a JSON Lines text formatted file ("people.json") containing the profiles of a set of people: each line of the file contains a JSON object containing name and age of a person. Age can assume the null value.</span>
<span id="cb53-119"><a href="#cb53-119"></a></span>
<span id="cb53-120"><a href="#cb53-120"></a>Example of JSON file</span>
<span id="cb53-121"><a href="#cb53-121"></a></span>
<span id="cb53-122"><a href="#cb53-122"></a><span class="in">```</span></span>
<span id="cb53-123"><a href="#cb53-123"></a><span class="in">{"name":"Michael"}</span></span>
<span id="cb53-124"><a href="#cb53-124"></a><span class="in">{"name":"Andy", "age":30}</span></span>
<span id="cb53-125"><a href="#cb53-125"></a><span class="in">{"name":"Justin", "age":19}</span></span>
<span id="cb53-126"><a href="#cb53-126"></a><span class="in">```</span></span>
<span id="cb53-127"><a href="#cb53-127"></a></span>
<span id="cb53-128"><a href="#cb53-128"></a>Notice that the age of the first person is unknown.</span>
<span id="cb53-129"><a href="#cb53-129"></a></span>
<span id="cb53-130"><a href="#cb53-130"></a><span class="in">```python</span></span>
<span id="cb53-131"><a href="#cb53-131"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-132"><a href="#cb53-132"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-133"><a href="#cb53-133"></a></span>
<span id="cb53-134"><a href="#cb53-134"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-135"><a href="#cb53-135"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-136"><a href="#cb53-136"></a>    <span class="st">"people.json"</span>,</span>
<span id="cb53-137"><a href="#cb53-137"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"json"</span></span>
<span id="cb53-138"><a href="#cb53-138"></a>)</span>
<span id="cb53-139"><a href="#cb53-139"></a><span class="in">```</span></span>
<span id="cb53-140"><a href="#cb53-140"></a></span>
<span id="cb53-141"><a href="#cb53-141"></a>|||</span>
<span id="cb53-142"><a href="#cb53-142"></a>|-|---|</span>
<span id="cb53-143"><a href="#cb53-143"></a>| <span class="in">`format="json"`</span> | This method is used to specify the format of the input file. |</span>
<span id="cb53-144"><a href="#cb53-144"></a></span>
<span id="cb53-145"><a href="#cb53-145"></a>:::</span>
<span id="cb53-146"><a href="#cb53-146"></a></span>
<span id="cb53-147"><a href="#cb53-147"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-148"><a href="#cb53-148"></a><span class="fu">### Example 2</span></span>
<span id="cb53-149"><a href="#cb53-149"></a>Create a DataFrame from a folder containing a set of standard multiline JSON files: each input JSON file contains the profile of one person, in particular each file contains name and age of a person. Age can assume the null value.</span>
<span id="cb53-150"><a href="#cb53-150"></a></span>
<span id="cb53-151"><a href="#cb53-151"></a>Example of JSON file</span>
<span id="cb53-152"><a href="#cb53-152"></a></span>
<span id="cb53-153"><a href="#cb53-153"></a><span class="in">```</span></span>
<span id="cb53-154"><a href="#cb53-154"></a><span class="in">{"name":"Andy", "age":30}</span></span>
<span id="cb53-155"><a href="#cb53-155"></a><span class="in">```</span></span>
<span id="cb53-156"><a href="#cb53-156"></a></span>
<span id="cb53-157"><a href="#cb53-157"></a><span class="in">```python</span></span>
<span id="cb53-158"><a href="#cb53-158"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-159"><a href="#cb53-159"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-160"><a href="#cb53-160"></a></span>
<span id="cb53-161"><a href="#cb53-161"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-162"><a href="#cb53-162"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-163"><a href="#cb53-163"></a>    <span class="st">"folder_JSONFiles/"</span>,</span>
<span id="cb53-164"><a href="#cb53-164"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"json"</span>,</span>
<span id="cb53-165"><a href="#cb53-165"></a>    multiLine<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-166"><a href="#cb53-166"></a>)</span>
<span id="cb53-167"><a href="#cb53-167"></a><span class="in">```</span></span>
<span id="cb53-168"><a href="#cb53-168"></a></span>
<span id="cb53-169"><a href="#cb53-169"></a>|||</span>
<span id="cb53-170"><a href="#cb53-170"></a>|-|---|</span>
<span id="cb53-171"><a href="#cb53-171"></a>| <span class="in">`multiLine=True`</span> | This multiline option is set to true to specify that the input files are standard multiline JSON files. |</span>
<span id="cb53-172"><a href="#cb53-172"></a></span>
<span id="cb53-173"><a href="#cb53-173"></a>:::</span>
<span id="cb53-174"><a href="#cb53-174"></a></span>
<span id="cb53-175"><a href="#cb53-175"></a><span class="fu">### Creating DataFrames from other data sources</span></span>
<span id="cb53-176"><a href="#cb53-176"></a>The <span class="in">`DataFrameReader`</span> class (the same we used for reading a json file and store it in a DataFrame) provides other methods to read many standard (textual) formats and read data from external databases:</span>
<span id="cb53-177"><a href="#cb53-177"></a></span>
<span id="cb53-178"><a href="#cb53-178"></a><span class="ss">- </span>Apache parquet files</span>
<span id="cb53-179"><a href="#cb53-179"></a><span class="ss">- </span>external relational database, through a JDBC connection</span>
<span id="cb53-180"><a href="#cb53-180"></a><span class="ss">- </span>Hive tables</span>
<span id="cb53-181"><a href="#cb53-181"></a><span class="ss">- </span>...</span>
<span id="cb53-182"><a href="#cb53-182"></a></span>
<span id="cb53-183"><a href="#cb53-183"></a><span class="fu">### Creating DataFrames from RDDs or Python lists</span></span>
<span id="cb53-184"><a href="#cb53-184"></a>The content of an RDD of tuples or the content of a Python list of tuples can be stored in a DataFrame by using the <span class="in">`spark.createDataFrame(data,schema)`</span> method, where <span class="in">`data`</span> is a RDD of tuples or Rows, Python list of tuples or Rows, or pandas DataFrame, and <span class="in">`schema`</span> is a list of string with the names of the columns/attributes. <span class="in">`schema`</span> is optional, and if not specified the column names are set to <span class="in">`_1`</span>, <span class="in">`_2`</span>, ..., <span class="in">`_n`</span> for input RDDs/lists of tuples.</span>
<span id="cb53-185"><a href="#cb53-185"></a></span>
<span id="cb53-186"><a href="#cb53-186"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-187"><a href="#cb53-187"></a><span class="fu">### Example</span></span>
<span id="cb53-188"><a href="#cb53-188"></a>Create a DataFrame from the following Python list</span>
<span id="cb53-189"><a href="#cb53-189"></a></span>
<span id="cb53-190"><a href="#cb53-190"></a><span class="in">```python</span></span>
<span id="cb53-191"><a href="#cb53-191"></a>[</span>
<span id="cb53-192"><a href="#cb53-192"></a>    (<span class="dv">19</span>,<span class="st">"Justin"</span>),</span>
<span id="cb53-193"><a href="#cb53-193"></a>    (<span class="dv">30</span>,<span class="st">"Andy"</span>),</span>
<span id="cb53-194"><a href="#cb53-194"></a>    (<span class="va">None</span>,<span class="st">"Michael"</span>)</span>
<span id="cb53-195"><a href="#cb53-195"></a>]</span>
<span id="cb53-196"><a href="#cb53-196"></a><span class="in">```</span></span>
<span id="cb53-197"><a href="#cb53-197"></a></span>
<span id="cb53-198"><a href="#cb53-198"></a>The column names must be set to "age" and "name".</span>
<span id="cb53-199"><a href="#cb53-199"></a></span>
<span id="cb53-200"><a href="#cb53-200"></a><span class="in">```python</span></span>
<span id="cb53-201"><a href="#cb53-201"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-202"><a href="#cb53-202"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-203"><a href="#cb53-203"></a></span>
<span id="cb53-204"><a href="#cb53-204"></a><span class="co">## Create a Python list of tuples</span></span>
<span id="cb53-205"><a href="#cb53-205"></a>profilesList <span class="op">=</span> [</span>
<span id="cb53-206"><a href="#cb53-206"></a>    (<span class="dv">19</span>,<span class="st">"Justin"</span>),</span>
<span id="cb53-207"><a href="#cb53-207"></a>    (<span class="dv">30</span>,<span class="st">"Andy"</span>),</span>
<span id="cb53-208"><a href="#cb53-208"></a>    (<span class="va">None</span>,<span class="st">"Michael"</span>)</span>
<span id="cb53-209"><a href="#cb53-209"></a>]</span>
<span id="cb53-210"><a href="#cb53-210"></a></span>
<span id="cb53-211"><a href="#cb53-211"></a><span class="co">## Create a DataFrame from the profilesList</span></span>
<span id="cb53-212"><a href="#cb53-212"></a>df <span class="op">=</span> spark.createDataFrame(profilesList,[<span class="st">"age"</span>,<span class="st">"name"</span>])</span>
<span id="cb53-213"><a href="#cb53-213"></a><span class="in">```</span></span>
<span id="cb53-214"><a href="#cb53-214"></a></span>
<span id="cb53-215"><a href="#cb53-215"></a>:::</span>
<span id="cb53-216"><a href="#cb53-216"></a></span>
<span id="cb53-217"><a href="#cb53-217"></a><span class="fu">### From DataFrame to RDD</span></span>
<span id="cb53-218"><a href="#cb53-218"></a>The <span class="in">`rdd`</span> method of the <span class="in">`DataFrame`</span> class returns an RDD of Row objects containing the content of the DataFrame which it is invoked on. Each <span class="in">`Row`</span> object is like a dictionary containing the values of a record: it contains column names in the keys and column values in the values.</span>
<span id="cb53-219"><a href="#cb53-219"></a></span>
<span id="cb53-220"><a href="#cb53-220"></a><span class="fu">#### Usage of the Row class</span></span>
<span id="cb53-221"><a href="#cb53-221"></a>The fields in it can be accessed:</span>
<span id="cb53-222"><a href="#cb53-222"></a></span>
<span id="cb53-223"><a href="#cb53-223"></a><span class="ss">- </span>like attributes: <span class="in">`row.key`</span>, where <span class="in">`key`</span> is a column name;</span>
<span id="cb53-224"><a href="#cb53-224"></a><span class="ss">- </span>like dictionary values: <span class="in">`row["key"]`</span>;</span>
<span id="cb53-225"><a href="#cb53-225"></a><span class="ss">- </span>using <span class="in">`for key in row`</span> will search through row keys.</span>
<span id="cb53-226"><a href="#cb53-226"></a></span>
<span id="cb53-227"><a href="#cb53-227"></a>Also the <span class="in">`asDict()`</span> method returns the Row content as a Python dictionary.</span>
<span id="cb53-228"><a href="#cb53-228"></a></span>
<span id="cb53-229"><a href="#cb53-229"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-230"><a href="#cb53-230"></a><span class="fu">### Example</span></span>
<span id="cb53-231"><a href="#cb53-231"></a><span class="ss">1. </span>Create a DataFrame from a csv file containing the profiles of a set of people: each line of the file contains name and age of a person, but the first line contains the header (i.e., the name of the attributes/columns);</span>
<span id="cb53-232"><a href="#cb53-232"></a><span class="ss">2. </span>Transform the input DataFrame into an RDD, select only the name field/column and store the result in the output folder.</span>
<span id="cb53-233"><a href="#cb53-233"></a></span>
<span id="cb53-234"><a href="#cb53-234"></a><span class="in">```python</span></span>
<span id="cb53-235"><a href="#cb53-235"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-236"><a href="#cb53-236"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-237"><a href="#cb53-237"></a></span>
<span id="cb53-238"><a href="#cb53-238"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-239"><a href="#cb53-239"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-240"><a href="#cb53-240"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb53-241"><a href="#cb53-241"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-242"><a href="#cb53-242"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-243"><a href="#cb53-243"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-244"><a href="#cb53-244"></a>)</span>
<span id="cb53-245"><a href="#cb53-245"></a></span>
<span id="cb53-246"><a href="#cb53-246"></a><span class="co">## Define an RDD based on the content of</span></span>
<span id="cb53-247"><a href="#cb53-247"></a><span class="co">## the DataFrame</span></span>
<span id="cb53-248"><a href="#cb53-248"></a>rddRows <span class="op">=</span> df.rdd</span>
<span id="cb53-249"><a href="#cb53-249"></a></span>
<span id="cb53-250"><a href="#cb53-250"></a><span class="co">## Use the map transformation to extract</span></span>
<span id="cb53-251"><a href="#cb53-251"></a><span class="co">## the name field/column</span></span>
<span id="cb53-252"><a href="#cb53-252"></a>rddNames <span class="op">=</span> rddRows.<span class="bu">map</span>(<span class="kw">lambda</span> row: row.name)</span>
<span id="cb53-253"><a href="#cb53-253"></a></span>
<span id="cb53-254"><a href="#cb53-254"></a><span class="co">## Store the result</span></span>
<span id="cb53-255"><a href="#cb53-255"></a>rddNames.saveAsTextFile(outputPath)</span>
<span id="cb53-256"><a href="#cb53-256"></a><span class="in">```</span></span>
<span id="cb53-257"><a href="#cb53-257"></a>:::</span>
<span id="cb53-258"><a href="#cb53-258"></a></span>
<span id="cb53-259"><a href="#cb53-259"></a><span class="fu">## Operations on DataFrames</span></span>
<span id="cb53-260"><a href="#cb53-260"></a>A set of specific methods are available for the <span class="in">`DataFrame`</span> class (e.g., <span class="in">`show()`</span>, <span class="in">`printSchema()`</span>, <span class="in">`count()`</span>, <span class="in">`distinct()`</span>, <span class="in">`select()`</span>, <span class="in">`filter()`</span>), also the standard <span class="in">`collect()`</span> and <span class="in">`count()`</span> actions are available.</span>
<span id="cb53-261"><a href="#cb53-261"></a></span>
<span id="cb53-262"><a href="#cb53-262"></a><span class="fu">### Show method</span></span>
<span id="cb53-263"><a href="#cb53-263"></a>The <span class="in">`show(n)`</span> method of the <span class="in">`DataFrame`</span> class prints on the standard output the first <span class="in">`n`</span> of the input DataFrame. Default value of <span class="in">`n`</span> is 20.</span>
<span id="cb53-264"><a href="#cb53-264"></a></span>
<span id="cb53-265"><a href="#cb53-265"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-266"><a href="#cb53-266"></a><span class="fu">### Example</span></span>
<span id="cb53-267"><a href="#cb53-267"></a><span class="ss">1. </span>Create a DataFrame from a csv file containing the profiles of a set of people;</span>
<span id="cb53-268"><a href="#cb53-268"></a><span class="ss">2. </span>Print the content of the first 2 people (i.e., the first 2 rows of the DataFrame).</span>
<span id="cb53-269"><a href="#cb53-269"></a></span>
<span id="cb53-270"><a href="#cb53-270"></a>The content of people.csv is</span>
<span id="cb53-271"><a href="#cb53-271"></a></span>
<span id="cb53-272"><a href="#cb53-272"></a><span class="in">```</span></span>
<span id="cb53-273"><a href="#cb53-273"></a><span class="in">name,age</span></span>
<span id="cb53-274"><a href="#cb53-274"></a><span class="in">Andy,30</span></span>
<span id="cb53-275"><a href="#cb53-275"></a><span class="in">Michael,</span></span>
<span id="cb53-276"><a href="#cb53-276"></a><span class="in">Justin,19</span></span>
<span id="cb53-277"><a href="#cb53-277"></a><span class="in">```</span></span>
<span id="cb53-278"><a href="#cb53-278"></a></span>
<span id="cb53-279"><a href="#cb53-279"></a><span class="in">```python</span></span>
<span id="cb53-280"><a href="#cb53-280"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-281"><a href="#cb53-281"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-282"><a href="#cb53-282"></a></span>
<span id="cb53-283"><a href="#cb53-283"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-284"><a href="#cb53-284"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-285"><a href="#cb53-285"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb53-286"><a href="#cb53-286"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-287"><a href="#cb53-287"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-288"><a href="#cb53-288"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-289"><a href="#cb53-289"></a>)</span>
<span id="cb53-290"><a href="#cb53-290"></a></span>
<span id="cb53-291"><a href="#cb53-291"></a>df.show(<span class="dv">2</span>)</span>
<span id="cb53-292"><a href="#cb53-292"></a><span class="in">```</span></span>
<span id="cb53-293"><a href="#cb53-293"></a></span>
<span id="cb53-294"><a href="#cb53-294"></a>:::</span>
<span id="cb53-295"><a href="#cb53-295"></a></span>
<span id="cb53-296"><a href="#cb53-296"></a><span class="fu">### PrintSchema method</span></span>
<span id="cb53-297"><a href="#cb53-297"></a>The <span class="in">`printSchema()`</span> method of the <span class="in">`DataFrame`</span> class prints on the standard output the schema of the DataFrame (i.e., the name of the attributes of the data stored in the DataFrame).</span>
<span id="cb53-298"><a href="#cb53-298"></a></span>
<span id="cb53-299"><a href="#cb53-299"></a><span class="fu">### Count method</span></span>
<span id="cb53-300"><a href="#cb53-300"></a>The <span class="in">`count()`</span> method of the <span class="in">`DataFrame`</span> class returns the number of rows in the input DataFrame.</span>
<span id="cb53-301"><a href="#cb53-301"></a></span>
<span id="cb53-302"><a href="#cb53-302"></a><span class="fu">### Distinct method</span></span>
<span id="cb53-303"><a href="#cb53-303"></a>The <span class="in">`distinct()`</span> method of the <span class="in">`DataFrame`</span> class returns a new DataFrame that contains only the unique rows of the input DataFrame. A shuffle phase is needed.</span>
<span id="cb53-304"><a href="#cb53-304"></a></span>
<span id="cb53-305"><a href="#cb53-305"></a>:::{.callout-caution}</span>
<span id="cb53-306"><a href="#cb53-306"></a>Pay attention that the distinct operation is always an heavy operation in terms of data sent on the network.</span>
<span id="cb53-307"><a href="#cb53-307"></a>:::</span>
<span id="cb53-308"><a href="#cb53-308"></a></span>
<span id="cb53-309"><a href="#cb53-309"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-310"><a href="#cb53-310"></a><span class="fu">### Example</span></span>
<span id="cb53-311"><a href="#cb53-311"></a><span class="ss">1. </span>Create a DataFrame from a csv file containing the names of a set of people. The first line is the header.</span>
<span id="cb53-312"><a href="#cb53-312"></a><span class="ss">2. </span>Create a new DataFrame without duplicates.</span>
<span id="cb53-313"><a href="#cb53-313"></a></span>
<span id="cb53-314"><a href="#cb53-314"></a>The content of "names.csv" is</span>
<span id="cb53-315"><a href="#cb53-315"></a></span>
<span id="cb53-316"><a href="#cb53-316"></a><span class="in">```</span></span>
<span id="cb53-317"><a href="#cb53-317"></a><span class="in">name</span></span>
<span id="cb53-318"><a href="#cb53-318"></a><span class="in">Andy</span></span>
<span id="cb53-319"><a href="#cb53-319"></a><span class="in">Michael</span></span>
<span id="cb53-320"><a href="#cb53-320"></a><span class="in">Justin</span></span>
<span id="cb53-321"><a href="#cb53-321"></a><span class="in">Michael</span></span>
<span id="cb53-322"><a href="#cb53-322"></a><span class="in">```</span></span>
<span id="cb53-323"><a href="#cb53-323"></a></span>
<span id="cb53-324"><a href="#cb53-324"></a><span class="in">```python</span></span>
<span id="cb53-325"><a href="#cb53-325"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-326"><a href="#cb53-326"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-327"><a href="#cb53-327"></a></span>
<span id="cb53-328"><a href="#cb53-328"></a><span class="co">## Create a DataFrame from names.csv</span></span>
<span id="cb53-329"><a href="#cb53-329"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-330"><a href="#cb53-330"></a>    <span class="st">"names.csv"</span>,</span>
<span id="cb53-331"><a href="#cb53-331"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-332"><a href="#cb53-332"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-333"><a href="#cb53-333"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-334"><a href="#cb53-334"></a>)</span>
<span id="cb53-335"><a href="#cb53-335"></a></span>
<span id="cb53-336"><a href="#cb53-336"></a>df_distinct <span class="op">=</span> df.distinct()</span>
<span id="cb53-337"><a href="#cb53-337"></a><span class="in">```</span></span>
<span id="cb53-338"><a href="#cb53-338"></a></span>
<span id="cb53-339"><a href="#cb53-339"></a>:::</span>
<span id="cb53-340"><a href="#cb53-340"></a></span>
<span id="cb53-341"><a href="#cb53-341"></a><span class="fu">### Select method</span></span>
<span id="cb53-342"><a href="#cb53-342"></a>The <span class="in">`select(col1, ..., coln)`</span> method of the <span class="in">`DataFrame`</span> class returns a new DataFrame that contains only the specified columns of the input DataFrame. Use <span class="in">`*`</span> as special column to select all columns</span>
<span id="cb53-343"><a href="#cb53-343"></a></span>
<span id="cb53-344"><a href="#cb53-344"></a>:::{.callout-caution}</span>
<span id="cb53-345"><a href="#cb53-345"></a>Pay attention that the select method can generate errors at runtime if there are mistakes in the names of the columns.</span>
<span id="cb53-346"><a href="#cb53-346"></a>:::</span>
<span id="cb53-347"><a href="#cb53-347"></a></span>
<span id="cb53-348"><a href="#cb53-348"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-349"><a href="#cb53-349"></a><span class="fu">### Example</span></span>
<span id="cb53-350"><a href="#cb53-350"></a><span class="ss">1. </span>Create a DataFrame from the "people2.csv" file that scontains the profiles of a set of people</span>
<span id="cb53-351"><a href="#cb53-351"></a><span class="ss">    - </span>The first line contains the header;</span>
<span id="cb53-352"><a href="#cb53-352"></a><span class="ss">    - </span>The others lines contain the users' profiles: one line per person, and each line contains name, age, and gender of a person.</span>
<span id="cb53-353"><a href="#cb53-353"></a><span class="ss">2. </span>Create a new DataFrame containing only name and age of the people.</span>
<span id="cb53-354"><a href="#cb53-354"></a></span>
<span id="cb53-355"><a href="#cb53-355"></a>The "people2.csv" has the following structure</span>
<span id="cb53-356"><a href="#cb53-356"></a></span>
<span id="cb53-357"><a href="#cb53-357"></a><span class="in">```</span></span>
<span id="cb53-358"><a href="#cb53-358"></a><span class="in">name,age,gender</span></span>
<span id="cb53-359"><a href="#cb53-359"></a><span class="in">Paul,40,male</span></span>
<span id="cb53-360"><a href="#cb53-360"></a><span class="in">John,40,male</span></span>
<span id="cb53-361"><a href="#cb53-361"></a><span class="in">```</span></span>
<span id="cb53-362"><a href="#cb53-362"></a></span>
<span id="cb53-363"><a href="#cb53-363"></a><span class="in">```python</span></span>
<span id="cb53-364"><a href="#cb53-364"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-365"><a href="#cb53-365"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-366"><a href="#cb53-366"></a></span>
<span id="cb53-367"><a href="#cb53-367"></a><span class="co">## Create a DataFrame from people2.csv</span></span>
<span id="cb53-368"><a href="#cb53-368"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-369"><a href="#cb53-369"></a>    <span class="st">"people2.csv"</span>,</span>
<span id="cb53-370"><a href="#cb53-370"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-371"><a href="#cb53-371"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-372"><a href="#cb53-372"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-373"><a href="#cb53-373"></a>)</span>
<span id="cb53-374"><a href="#cb53-374"></a></span>
<span id="cb53-375"><a href="#cb53-375"></a>dfNamesAges <span class="op">=</span> df.select(<span class="st">"name"</span>,<span class="st">"age"</span>)</span>
<span id="cb53-376"><a href="#cb53-376"></a><span class="in">```</span></span>
<span id="cb53-377"><a href="#cb53-377"></a></span>
<span id="cb53-378"><a href="#cb53-378"></a>:::</span>
<span id="cb53-379"><a href="#cb53-379"></a></span>
<span id="cb53-380"><a href="#cb53-380"></a><span class="fu">### SelectExpr method</span></span>
<span id="cb53-381"><a href="#cb53-381"></a>The <span class="in">`selectExpr(expression1,...,expressionN)`</span> method of the <span class="in">`DataFrame`</span> class is a variant of the select method, where <span class="in">`expr`</span> can be a SQL expression.</span>
<span id="cb53-382"><a href="#cb53-382"></a></span>
<span id="cb53-383"><a href="#cb53-383"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-384"><a href="#cb53-384"></a><span class="fu">### Example 1</span></span>
<span id="cb53-385"><a href="#cb53-385"></a><span class="ss">1. </span>Create a DataFrame from the "people2.csv" file that scontains the profiles of a set of people</span>
<span id="cb53-386"><a href="#cb53-386"></a><span class="ss">    - </span>The first line contains the header;</span>
<span id="cb53-387"><a href="#cb53-387"></a><span class="ss">    - </span>The others lines contain the users' profiles: one line per person, and each line contains name, age, and gender of a person.</span>
<span id="cb53-388"><a href="#cb53-388"></a><span class="ss">2. </span>Create a new DataFrame containing only name and age of the people.</span>
<span id="cb53-389"><a href="#cb53-389"></a><span class="ss">3. </span>Create a new DataFrame containing only the name of the people and their age plus one. Call the age column as "new_age".</span>
<span id="cb53-390"><a href="#cb53-390"></a></span>
<span id="cb53-391"><a href="#cb53-391"></a>The "people2.csv" has the following structure</span>
<span id="cb53-392"><a href="#cb53-392"></a></span>
<span id="cb53-393"><a href="#cb53-393"></a><span class="in">```</span></span>
<span id="cb53-394"><a href="#cb53-394"></a><span class="in">name,age,gender</span></span>
<span id="cb53-395"><a href="#cb53-395"></a><span class="in">Paul,40,male</span></span>
<span id="cb53-396"><a href="#cb53-396"></a><span class="in">John,40,male</span></span>
<span id="cb53-397"><a href="#cb53-397"></a><span class="in">```</span></span>
<span id="cb53-398"><a href="#cb53-398"></a></span>
<span id="cb53-399"><a href="#cb53-399"></a><span class="in">```python</span></span>
<span id="cb53-400"><a href="#cb53-400"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-401"><a href="#cb53-401"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-402"><a href="#cb53-402"></a></span>
<span id="cb53-403"><a href="#cb53-403"></a><span class="co">## Create a DataFrame from people2.csv</span></span>
<span id="cb53-404"><a href="#cb53-404"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-405"><a href="#cb53-405"></a>    <span class="st">"people2.csv"</span>,</span>
<span id="cb53-406"><a href="#cb53-406"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-407"><a href="#cb53-407"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-408"><a href="#cb53-408"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-409"><a href="#cb53-409"></a>)</span>
<span id="cb53-410"><a href="#cb53-410"></a></span>
<span id="cb53-411"><a href="#cb53-411"></a>dfNamesAges <span class="op">=</span> df.selectExpr(<span class="st">"name"</span>,<span class="st">"age"</span>)</span>
<span id="cb53-412"><a href="#cb53-412"></a></span>
<span id="cb53-413"><a href="#cb53-413"></a>dfNamesAgesMod <span class="op">=</span> df.selectExpr(<span class="st">"name"</span>, <span class="st">"age + 1 AS new_age"</span>)</span>
<span id="cb53-414"><a href="#cb53-414"></a><span class="in">```</span></span>
<span id="cb53-415"><a href="#cb53-415"></a></span>
<span id="cb53-416"><a href="#cb53-416"></a>:::</span>
<span id="cb53-417"><a href="#cb53-417"></a></span>
<span id="cb53-418"><a href="#cb53-418"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-419"><a href="#cb53-419"></a><span class="fu">### Example 2</span></span>
<span id="cb53-420"><a href="#cb53-420"></a><span class="ss">1. </span>Create a DataFrame from the "people2.csv" file that contains the profiles of a set of people</span>
<span id="cb53-421"><a href="#cb53-421"></a><span class="ss">- </span>The first line contains the header;</span>
<span id="cb53-422"><a href="#cb53-422"></a><span class="ss">- </span>The others lines contain the users' profiles: each line contains name, age, and gender of a person.</span>
<span id="cb53-423"><a href="#cb53-423"></a><span class="ss">2. </span>Create a new DataFrame containing the same columns of the initial dataset plus an additional column called "newAge" containing the value of age incremented by one.</span>
<span id="cb53-424"><a href="#cb53-424"></a></span>
<span id="cb53-425"><a href="#cb53-425"></a>The "people2.csv" has the following structure</span>
<span id="cb53-426"><a href="#cb53-426"></a></span>
<span id="cb53-427"><a href="#cb53-427"></a><span class="in">```</span></span>
<span id="cb53-428"><a href="#cb53-428"></a><span class="in">name,age,gender</span></span>
<span id="cb53-429"><a href="#cb53-429"></a><span class="in">Paul,40,male</span></span>
<span id="cb53-430"><a href="#cb53-430"></a><span class="in">John,40,male</span></span>
<span id="cb53-431"><a href="#cb53-431"></a><span class="in">```</span></span>
<span id="cb53-432"><a href="#cb53-432"></a></span>
<span id="cb53-433"><a href="#cb53-433"></a><span class="in">```python</span></span>
<span id="cb53-434"><a href="#cb53-434"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-435"><a href="#cb53-435"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-436"><a href="#cb53-436"></a></span>
<span id="cb53-437"><a href="#cb53-437"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-438"><a href="#cb53-438"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-439"><a href="#cb53-439"></a>    <span class="st">"people2.csv"</span>,</span>
<span id="cb53-440"><a href="#cb53-440"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-441"><a href="#cb53-441"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-442"><a href="#cb53-442"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-443"><a href="#cb53-443"></a>)</span>
<span id="cb53-444"><a href="#cb53-444"></a></span>
<span id="cb53-445"><a href="#cb53-445"></a><span class="co">## Create a new DataFrame with four columns:</span></span>
<span id="cb53-446"><a href="#cb53-446"></a><span class="co">## name, age, gender, newAge = age +1</span></span>
<span id="cb53-447"><a href="#cb53-447"></a>dfNewAge <span class="op">=</span> df.selectExpr(</span>
<span id="cb53-448"><a href="#cb53-448"></a>    <span class="st">"name"</span>,</span>
<span id="cb53-449"><a href="#cb53-449"></a>    <span class="st">"age"</span>,</span>
<span id="cb53-450"><a href="#cb53-450"></a>    <span class="st">"gender"</span>,</span>
<span id="cb53-451"><a href="#cb53-451"></a>    <span class="st">"age+1 as newAge"</span></span>
<span id="cb53-452"><a href="#cb53-452"></a>)</span>
<span id="cb53-453"><a href="#cb53-453"></a><span class="in">```</span></span>
<span id="cb53-454"><a href="#cb53-454"></a></span>
<span id="cb53-455"><a href="#cb53-455"></a>|||</span>
<span id="cb53-456"><a href="#cb53-456"></a>|-|--|</span>
<span id="cb53-457"><a href="#cb53-457"></a>| <span class="in">`"... as newAge"`</span> | This part of the expression is used to specify the name of the column associated with the result of the first part of the expression in the returned DataFrame. Without this part of the expression, the name of the returned column would be "age+1". |</span>
<span id="cb53-458"><a href="#cb53-458"></a></span>
<span id="cb53-459"><a href="#cb53-459"></a>:::</span>
<span id="cb53-460"><a href="#cb53-460"></a></span>
<span id="cb53-461"><a href="#cb53-461"></a><span class="fu">### Filter method</span></span>
<span id="cb53-462"><a href="#cb53-462"></a>The <span class="in">`filter(conditionExpr)`</span> method of the <span class="in">`DataFrame`</span> class returns a new DataFrame that contains only the rows satisfying the specified condition. The condition is expressed as a Boolean SQL expression.</span>
<span id="cb53-463"><a href="#cb53-463"></a></span>
<span id="cb53-464"><a href="#cb53-464"></a>:::{.callout-caution}</span>
<span id="cb53-465"><a href="#cb53-465"></a>Pay attention that this version of the filter method can generate errors at runtime if there are errors in the filter expression: the parameter is a string and the system cannot check the correctness of the expression at compile time.</span>
<span id="cb53-466"><a href="#cb53-466"></a>:::</span>
<span id="cb53-467"><a href="#cb53-467"></a></span>
<span id="cb53-468"><a href="#cb53-468"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-469"><a href="#cb53-469"></a><span class="fu">### Example</span></span>
<span id="cb53-470"><a href="#cb53-470"></a><span class="ss">1. </span>Create a DataFrame from the "people.csv" file that contains the profiles of a set of people</span>
<span id="cb53-471"><a href="#cb53-471"></a><span class="ss">    - </span>The first line contains the header;</span>
<span id="cb53-472"><a href="#cb53-472"></a><span class="ss">    - </span>The others lines contain the users' profiles: each line contains name and age of a person.</span>
<span id="cb53-473"><a href="#cb53-473"></a><span class="ss">2. </span>Create a new DataFrame containing only the people with age between 20 and 31.</span>
<span id="cb53-474"><a href="#cb53-474"></a></span>
<span id="cb53-475"><a href="#cb53-475"></a><span class="in">```python</span></span>
<span id="cb53-476"><a href="#cb53-476"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-477"><a href="#cb53-477"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-478"><a href="#cb53-478"></a></span>
<span id="cb53-479"><a href="#cb53-479"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-480"><a href="#cb53-480"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-481"><a href="#cb53-481"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb53-482"><a href="#cb53-482"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-483"><a href="#cb53-483"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-484"><a href="#cb53-484"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-485"><a href="#cb53-485"></a>)</span>
<span id="cb53-486"><a href="#cb53-486"></a></span>
<span id="cb53-487"><a href="#cb53-487"></a>df_filtered <span class="op">=</span> df.<span class="bu">filter</span>(<span class="st">"age&gt;=20 and age&lt;=31"</span>)</span>
<span id="cb53-488"><a href="#cb53-488"></a><span class="in">```</span></span>
<span id="cb53-489"><a href="#cb53-489"></a></span>
<span id="cb53-490"><a href="#cb53-490"></a>:::</span>
<span id="cb53-491"><a href="#cb53-491"></a></span>
<span id="cb53-492"><a href="#cb53-492"></a><span class="fu">### Where method</span></span>
<span id="cb53-493"><a href="#cb53-493"></a>The <span class="in">`where(expression)`</span> method of the <span class="in">`DataFrame`</span> class is an alias of the <span class="in">`filter(conditionExpr)`</span> method.</span>
<span id="cb53-494"><a href="#cb53-494"></a></span>
<span id="cb53-495"><a href="#cb53-495"></a><span class="fu">### Join</span></span>
<span id="cb53-496"><a href="#cb53-496"></a>The <span class="in">`join(right, on, how)`</span> method of the <span class="in">`DataFrame`</span> class is used to join two DataFrames. It returns a DataFrame that contains the join of the tuples of the two input DataFrames based on the <span class="in">`on`</span> join condition.</span>
<span id="cb53-497"><a href="#cb53-497"></a></span>
<span id="cb53-498"><a href="#cb53-498"></a><span class="in">`on`</span> specifies the join condition. It can be:</span>
<span id="cb53-499"><a href="#cb53-499"></a>    </span>
<span id="cb53-500"><a href="#cb53-500"></a><span class="ss">- </span>a string: the column to join</span>
<span id="cb53-501"><a href="#cb53-501"></a><span class="ss">- </span>a list of strings: multiple columns to join</span>
<span id="cb53-502"><a href="#cb53-502"></a><span class="ss">- </span>a condition/an expression on the columns (e.g., <span class="in">`joined_df = df.join(df2, df.name == df2.name)`</span>)</span>
<span id="cb53-503"><a href="#cb53-503"></a></span>
<span id="cb53-504"><a href="#cb53-504"></a><span class="in">`how`</span> specifies the type of join</span>
<span id="cb53-505"><a href="#cb53-505"></a></span>
<span id="cb53-506"><a href="#cb53-506"></a><span class="ss">- </span><span class="in">`inner`</span> (default type of join)</span>
<span id="cb53-507"><a href="#cb53-507"></a><span class="ss">- </span><span class="in">`cross`</span></span>
<span id="cb53-508"><a href="#cb53-508"></a><span class="ss">- </span><span class="in">`outer`</span></span>
<span id="cb53-509"><a href="#cb53-509"></a><span class="ss">- </span><span class="in">`full`</span></span>
<span id="cb53-510"><a href="#cb53-510"></a><span class="ss">- </span><span class="in">`full_outer`</span></span>
<span id="cb53-511"><a href="#cb53-511"></a><span class="ss">- </span><span class="in">`left`</span></span>
<span id="cb53-512"><a href="#cb53-512"></a><span class="ss">- </span><span class="in">`left_outer`</span></span>
<span id="cb53-513"><a href="#cb53-513"></a><span class="ss">- </span><span class="in">`right`</span></span>
<span id="cb53-514"><a href="#cb53-514"></a><span class="ss">- </span><span class="in">`right_outer`</span></span>
<span id="cb53-515"><a href="#cb53-515"></a><span class="ss">- </span><span class="in">`left_semi`</span></span>
<span id="cb53-516"><a href="#cb53-516"></a><span class="ss">- </span><span class="in">`left_anti`</span></span>
<span id="cb53-517"><a href="#cb53-517"></a></span>
<span id="cb53-518"><a href="#cb53-518"></a>:::{.callout-caution}</span>
<span id="cb53-519"><a href="#cb53-519"></a>Pay attention that this method: can generate errors at runtime if there are errors in the join expression.</span>
<span id="cb53-520"><a href="#cb53-520"></a>:::</span>
<span id="cb53-521"><a href="#cb53-521"></a></span>
<span id="cb53-522"><a href="#cb53-522"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-523"><a href="#cb53-523"></a><span class="fu">### Example 1</span></span>
<span id="cb53-524"><a href="#cb53-524"></a><span class="ss">1. </span>Create two DataFrames</span>
<span id="cb53-525"><a href="#cb53-525"></a><span class="ss">    - </span>One based on the "people_id.csv" file that contains the profiles of a set of people, the schema is: uid, name, age;</span>
<span id="cb53-526"><a href="#cb53-526"></a><span class="ss">    - </span>One based on the liked_sports.csv file that contains the liked sports for each person, the schema is: uid, sportname.</span>
<span id="cb53-527"><a href="#cb53-527"></a>2.Join the content of the two DataFrames (uid is the join column) and show it on the standard output.</span>
<span id="cb53-528"><a href="#cb53-528"></a></span>
<span id="cb53-529"><a href="#cb53-529"></a><span class="in">```python</span></span>
<span id="cb53-530"><a href="#cb53-530"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-531"><a href="#cb53-531"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-532"><a href="#cb53-532"></a></span>
<span id="cb53-533"><a href="#cb53-533"></a><span class="co">## Read people_id.csv and store it in a DataFrame</span></span>
<span id="cb53-534"><a href="#cb53-534"></a>dfPeople <span class="op">=</span> spark.read.load(</span>
<span id="cb53-535"><a href="#cb53-535"></a>    <span class="st">"people_id.csv"</span>,</span>
<span id="cb53-536"><a href="#cb53-536"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-537"><a href="#cb53-537"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-538"><a href="#cb53-538"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-539"><a href="#cb53-539"></a>)</span>
<span id="cb53-540"><a href="#cb53-540"></a></span>
<span id="cb53-541"><a href="#cb53-541"></a><span class="co">## Read liked_sports.csv and store it in a DataFrame</span></span>
<span id="cb53-542"><a href="#cb53-542"></a>dfUidSports <span class="op">=</span> spark.read.load(</span>
<span id="cb53-543"><a href="#cb53-543"></a>    <span class="st">"liked_sports.csv"</span>,</span>
<span id="cb53-544"><a href="#cb53-544"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-545"><a href="#cb53-545"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-546"><a href="#cb53-546"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-547"><a href="#cb53-547"></a>)</span>
<span id="cb53-548"><a href="#cb53-548"></a></span>
<span id="cb53-549"><a href="#cb53-549"></a><span class="co">## Join the two input DataFrames</span></span>
<span id="cb53-550"><a href="#cb53-550"></a>dfPersonLikes <span class="op">=</span> dfPeople.join(</span>
<span id="cb53-551"><a href="#cb53-551"></a>    dfUidSports,</span>
<span id="cb53-552"><a href="#cb53-552"></a>    dfPeople.uid <span class="op">==</span> dfUidSports.uid</span>
<span id="cb53-553"><a href="#cb53-553"></a>)</span>
<span id="cb53-554"><a href="#cb53-554"></a></span>
<span id="cb53-555"><a href="#cb53-555"></a><span class="co">## Print the result on the standard output</span></span>
<span id="cb53-556"><a href="#cb53-556"></a>dfPersonLikes.show()</span>
<span id="cb53-557"><a href="#cb53-557"></a><span class="in">```</span></span>
<span id="cb53-558"><a href="#cb53-558"></a></span>
<span id="cb53-559"><a href="#cb53-559"></a>|||</span>
<span id="cb53-560"><a href="#cb53-560"></a>|-|-|</span>
<span id="cb53-561"><a href="#cb53-561"></a>| <span class="in">`dfPeople.uid == dfUidSports.uid`</span> | Specify the join condition on the uid columns. |</span>
<span id="cb53-562"><a href="#cb53-562"></a></span>
<span id="cb53-563"><a href="#cb53-563"></a>:::</span>
<span id="cb53-564"><a href="#cb53-564"></a></span>
<span id="cb53-565"><a href="#cb53-565"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-566"><a href="#cb53-566"></a><span class="fu">### Example 2</span></span>
<span id="cb53-567"><a href="#cb53-567"></a><span class="ss">1. </span>Create two DataFrames</span>
<span id="cb53-568"><a href="#cb53-568"></a><span class="ss">    - </span>One based on the "people_id.csv" file that contains the profiles of a set of people, the schema is: uid, name, age;</span>
<span id="cb53-569"><a href="#cb53-569"></a><span class="ss">    - </span>One based on the banned.csv file that contains the banned users, the schema is: uid, bannedmotivation.</span>
<span id="cb53-570"><a href="#cb53-570"></a><span class="ss">2. </span>Select the profiles of the non-banned users and show them on the standard output.</span>
<span id="cb53-571"><a href="#cb53-571"></a></span>
<span id="cb53-572"><a href="#cb53-572"></a><span class="in">```python</span></span>
<span id="cb53-573"><a href="#cb53-573"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-574"><a href="#cb53-574"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-575"><a href="#cb53-575"></a></span>
<span id="cb53-576"><a href="#cb53-576"></a><span class="co">## Read people_id.csv and store it in a DataFrame</span></span>
<span id="cb53-577"><a href="#cb53-577"></a>dfPeople <span class="op">=</span> spark.read.load(</span>
<span id="cb53-578"><a href="#cb53-578"></a>    <span class="st">"people_id.csv"</span>,</span>
<span id="cb53-579"><a href="#cb53-579"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-580"><a href="#cb53-580"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-581"><a href="#cb53-581"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-582"><a href="#cb53-582"></a>)</span>
<span id="cb53-583"><a href="#cb53-583"></a></span>
<span id="cb53-584"><a href="#cb53-584"></a><span class="co">## Read banned.csv and store it in a DataFrame</span></span>
<span id="cb53-585"><a href="#cb53-585"></a>dfBannedUsers <span class="op">=</span> spark.read.load(</span>
<span id="cb53-586"><a href="#cb53-586"></a>    <span class="st">"banned.csv"</span>,</span>
<span id="cb53-587"><a href="#cb53-587"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-588"><a href="#cb53-588"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-589"><a href="#cb53-589"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-590"><a href="#cb53-590"></a>)</span>
<span id="cb53-591"><a href="#cb53-591"></a></span>
<span id="cb53-592"><a href="#cb53-592"></a><span class="co">## Apply the Left Anti Join on the two input DataFrames</span></span>
<span id="cb53-593"><a href="#cb53-593"></a>dfSelectedProfiles <span class="op">=</span> dfPeople.join(</span>
<span id="cb53-594"><a href="#cb53-594"></a>    dfBannedUsers,</span>
<span id="cb53-595"><a href="#cb53-595"></a>    dfPeople.uid <span class="op">==</span> dfBannedUsers.uid,</span>
<span id="cb53-596"><a href="#cb53-596"></a>    <span class="st">"left_anti"</span></span>
<span id="cb53-597"><a href="#cb53-597"></a>)</span>
<span id="cb53-598"><a href="#cb53-598"></a></span>
<span id="cb53-599"><a href="#cb53-599"></a><span class="co">## Print the result on the standard output</span></span>
<span id="cb53-600"><a href="#cb53-600"></a>dfSelectedProfiles.show()</span>
<span id="cb53-601"><a href="#cb53-601"></a><span class="in">```</span></span>
<span id="cb53-602"><a href="#cb53-602"></a></span>
<span id="cb53-603"><a href="#cb53-603"></a>|||</span>
<span id="cb53-604"><a href="#cb53-604"></a>|-|-|</span>
<span id="cb53-605"><a href="#cb53-605"></a>| <span class="in">`dfPeople.uid == dfUidSports.uid`</span> | Specify the (anti) join condition on the uid columns. |</span>
<span id="cb53-606"><a href="#cb53-606"></a>| <span class="in">`"left_anti"`</span> | Use Left Anti Join. |</span>
<span id="cb53-607"><a href="#cb53-607"></a></span>
<span id="cb53-608"><a href="#cb53-608"></a>:::</span>
<span id="cb53-609"><a href="#cb53-609"></a></span>
<span id="cb53-610"><a href="#cb53-610"></a><span class="fu">### Aggregate functions</span></span>
<span id="cb53-611"><a href="#cb53-611"></a>Aggregate functions are provided to compute aggregates over the set of values of columns. Some of the provided aggregate functions/methods are</span>
<span id="cb53-612"><a href="#cb53-612"></a></span>
<span id="cb53-613"><a href="#cb53-613"></a><span class="ss">- </span><span class="in">`avg(column)`</span></span>
<span id="cb53-614"><a href="#cb53-614"></a><span class="ss">- </span><span class="in">`count(column)`</span></span>
<span id="cb53-615"><a href="#cb53-615"></a><span class="ss">- </span><span class="in">`sum(column)`</span></span>
<span id="cb53-616"><a href="#cb53-616"></a><span class="ss">- </span><span class="in">`abs(column)`</span></span>
<span id="cb53-617"><a href="#cb53-617"></a><span class="ss">- </span>...</span>
<span id="cb53-618"><a href="#cb53-618"></a></span>
<span id="cb53-619"><a href="#cb53-619"></a>Each aggregate function returns one value computed by considering all the values of the input column.</span>
<span id="cb53-620"><a href="#cb53-620"></a></span>
<span id="cb53-621"><a href="#cb53-621"></a>The <span class="in">`agg(expr)`</span> method of the <span class="in">`DataFrame`</span> class is used to specify which aggregate function we want to apply on one input column. The result is a DataFrame containing one single row and one single column, and the name of the return column is "function_name(column)".</span>
<span id="cb53-622"><a href="#cb53-622"></a></span>
<span id="cb53-623"><a href="#cb53-623"></a>:::{.callout-caution}</span>
<span id="cb53-624"><a href="#cb53-624"></a>Pay attention that this methods can generate errors at runtime (e.g., wrong attribute name, wrong data type).</span>
<span id="cb53-625"><a href="#cb53-625"></a>:::</span>
<span id="cb53-626"><a href="#cb53-626"></a></span>
<span id="cb53-627"><a href="#cb53-627"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-628"><a href="#cb53-628"></a><span class="fu">### Example</span></span>
<span id="cb53-629"><a href="#cb53-629"></a><span class="ss">1. </span>Create a DataFrame from the "people.csv" file that contains the profiles of a set of people (each line contains name and age of a person)</span>
<span id="cb53-630"><a href="#cb53-630"></a><span class="ss">    - </span>The first line contains the header;</span>
<span id="cb53-631"><a href="#cb53-631"></a><span class="ss">    - </span>The others lines contain the users' profiles.</span>
<span id="cb53-632"><a href="#cb53-632"></a><span class="ss">2. </span>Create a Dataset containing the average value of age.</span>
<span id="cb53-633"><a href="#cb53-633"></a></span>
<span id="cb53-634"><a href="#cb53-634"></a>Input file example</span>
<span id="cb53-635"><a href="#cb53-635"></a></span>
<span id="cb53-636"><a href="#cb53-636"></a><span class="in">```</span></span>
<span id="cb53-637"><a href="#cb53-637"></a><span class="in">name,age</span></span>
<span id="cb53-638"><a href="#cb53-638"></a><span class="in">Andy,30</span></span>
<span id="cb53-639"><a href="#cb53-639"></a><span class="in">Michael,15</span></span>
<span id="cb53-640"><a href="#cb53-640"></a><span class="in">Justin,19</span></span>
<span id="cb53-641"><a href="#cb53-641"></a><span class="in">Andy,40</span></span>
<span id="cb53-642"><a href="#cb53-642"></a><span class="in">```</span></span>
<span id="cb53-643"><a href="#cb53-643"></a></span>
<span id="cb53-644"><a href="#cb53-644"></a>Expected output example</span>
<span id="cb53-645"><a href="#cb53-645"></a></span>
<span id="cb53-646"><a href="#cb53-646"></a><span class="in">```</span></span>
<span id="cb53-647"><a href="#cb53-647"></a><span class="in">avg(age)</span></span>
<span id="cb53-648"><a href="#cb53-648"></a><span class="in">26.0</span></span>
<span id="cb53-649"><a href="#cb53-649"></a><span class="in">```</span></span>
<span id="cb53-650"><a href="#cb53-650"></a></span>
<span id="cb53-651"><a href="#cb53-651"></a><span class="in">```python</span></span>
<span id="cb53-652"><a href="#cb53-652"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-653"><a href="#cb53-653"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-654"><a href="#cb53-654"></a></span>
<span id="cb53-655"><a href="#cb53-655"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-656"><a href="#cb53-656"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-657"><a href="#cb53-657"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb53-658"><a href="#cb53-658"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-659"><a href="#cb53-659"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-660"><a href="#cb53-660"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-661"><a href="#cb53-661"></a>)</span>
<span id="cb53-662"><a href="#cb53-662"></a></span>
<span id="cb53-663"><a href="#cb53-663"></a><span class="co">## Compute the average of age</span></span>
<span id="cb53-664"><a href="#cb53-664"></a>averageAge <span class="op">=</span> df.agg({<span class="st">"age"</span>: <span class="st">"avg"</span>})</span>
<span id="cb53-665"><a href="#cb53-665"></a><span class="in">```</span></span>
<span id="cb53-666"><a href="#cb53-666"></a></span>
<span id="cb53-667"><a href="#cb53-667"></a>:::</span>
<span id="cb53-668"><a href="#cb53-668"></a></span>
<span id="cb53-669"><a href="#cb53-669"></a><span class="fu">### groupBy and aggregate functions</span></span>
<span id="cb53-670"><a href="#cb53-670"></a>The method <span class="in">`groupBy(col1, ..., coln)`</span> method of the <span class="in">`DataFrame`</span> class combined with a set of aggregate methods can be used to split the input data in groups and compute aggregate function over each group.</span>
<span id="cb53-671"><a href="#cb53-671"></a></span>
<span id="cb53-672"><a href="#cb53-672"></a>:::{.callout-caution}</span>
<span id="cb53-673"><a href="#cb53-673"></a>Pay attention that this methods can generate errors at runtime if there are semantic errors (e.g., wrong attribute names, wrong data types).</span>
<span id="cb53-674"><a href="#cb53-674"></a>:::</span>
<span id="cb53-675"><a href="#cb53-675"></a></span>
<span id="cb53-676"><a href="#cb53-676"></a>It is possible to specify which attributes are used to split the input data in groups by using the <span class="in">`groupBy(col1, ..., coln)`</span> method, and then, apply the aggregate functions to compute by final result (the result is a DataFrame).</span>
<span id="cb53-677"><a href="#cb53-677"></a></span>
<span id="cb53-678"><a href="#cb53-678"></a>Some of the provided aggregate functions/methods are</span>
<span id="cb53-679"><a href="#cb53-679"></a></span>
<span id="cb53-680"><a href="#cb53-680"></a><span class="ss">- </span><span class="in">`avg(column)`</span></span>
<span id="cb53-681"><a href="#cb53-681"></a><span class="ss">- </span><span class="in">`count(column)`</span></span>
<span id="cb53-682"><a href="#cb53-682"></a><span class="ss">- </span><span class="in">`sum(column)`</span></span>
<span id="cb53-683"><a href="#cb53-683"></a><span class="ss">- </span><span class="in">`abs(column)`</span></span>
<span id="cb53-684"><a href="#cb53-684"></a><span class="ss">- </span>...</span>
<span id="cb53-685"><a href="#cb53-685"></a></span>
<span id="cb53-686"><a href="#cb53-686"></a>Otherwise, the <span class="in">`agg()`</span> method can be used to apply multiple aggregate functions at the same time over each group.</span>
<span id="cb53-687"><a href="#cb53-687"></a></span>
<span id="cb53-688"><a href="#cb53-688"></a>See the static methods of the <span class="in">`pyspark.sql.GroupedData`</span> class for a complete list.</span>
<span id="cb53-689"><a href="#cb53-689"></a></span>
<span id="cb53-690"><a href="#cb53-690"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-691"><a href="#cb53-691"></a><span class="fu">### Example 1</span></span>
<span id="cb53-692"><a href="#cb53-692"></a><span class="ss">1. </span>Create a DataFrame from the "people.csv" file that contains the profiles of a set of people</span>
<span id="cb53-693"><a href="#cb53-693"></a><span class="ss">- </span>The first line contains the header;</span>
<span id="cb53-694"><a href="#cb53-694"></a><span class="ss">- </span>The others lines contain the users' profiles: each line contains name and age of a person.</span>
<span id="cb53-695"><a href="#cb53-695"></a><span class="ss">2. </span>Create a DataFrame containing the for each name the average value of age.</span>
<span id="cb53-696"><a href="#cb53-696"></a></span>
<span id="cb53-697"><a href="#cb53-697"></a>Input file example</span>
<span id="cb53-698"><a href="#cb53-698"></a></span>
<span id="cb53-699"><a href="#cb53-699"></a><span class="in">```</span></span>
<span id="cb53-700"><a href="#cb53-700"></a><span class="in">name,age</span></span>
<span id="cb53-701"><a href="#cb53-701"></a><span class="in">Andy,30</span></span>
<span id="cb53-702"><a href="#cb53-702"></a><span class="in">Michael,15</span></span>
<span id="cb53-703"><a href="#cb53-703"></a><span class="in">Justin,19</span></span>
<span id="cb53-704"><a href="#cb53-704"></a><span class="in">Andy,40</span></span>
<span id="cb53-705"><a href="#cb53-705"></a><span class="in">```</span></span>
<span id="cb53-706"><a href="#cb53-706"></a></span>
<span id="cb53-707"><a href="#cb53-707"></a>Expected output example</span>
<span id="cb53-708"><a href="#cb53-708"></a></span>
<span id="cb53-709"><a href="#cb53-709"></a><span class="in">```</span></span>
<span id="cb53-710"><a href="#cb53-710"></a><span class="in">name,avg(age)</span></span>
<span id="cb53-711"><a href="#cb53-711"></a><span class="in">Andy,35</span></span>
<span id="cb53-712"><a href="#cb53-712"></a><span class="in">Michael,15</span></span>
<span id="cb53-713"><a href="#cb53-713"></a><span class="in">Justin,19</span></span>
<span id="cb53-714"><a href="#cb53-714"></a><span class="in">```</span></span>
<span id="cb53-715"><a href="#cb53-715"></a></span>
<span id="cb53-716"><a href="#cb53-716"></a><span class="in">```python</span></span>
<span id="cb53-717"><a href="#cb53-717"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-718"><a href="#cb53-718"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-719"><a href="#cb53-719"></a></span>
<span id="cb53-720"><a href="#cb53-720"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-721"><a href="#cb53-721"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-722"><a href="#cb53-722"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb53-723"><a href="#cb53-723"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-724"><a href="#cb53-724"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-725"><a href="#cb53-725"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-726"><a href="#cb53-726"></a>)</span>
<span id="cb53-727"><a href="#cb53-727"></a></span>
<span id="cb53-728"><a href="#cb53-728"></a>grouped <span class="op">=</span> df.groupBy(<span class="st">"name"</span>).avg(<span class="st">"age"</span>)</span>
<span id="cb53-729"><a href="#cb53-729"></a><span class="in">```</span></span>
<span id="cb53-730"><a href="#cb53-730"></a></span>
<span id="cb53-731"><a href="#cb53-731"></a>:::</span>
<span id="cb53-732"><a href="#cb53-732"></a></span>
<span id="cb53-733"><a href="#cb53-733"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-734"><a href="#cb53-734"></a><span class="fu">### Example 2</span></span>
<span id="cb53-735"><a href="#cb53-735"></a><span class="ss">1. </span>Create a DataFrame from the "people.csv" file that contains the profiles of a set of people</span>
<span id="cb53-736"><a href="#cb53-736"></a><span class="ss">    - </span>The first line contains the header</span>
<span id="cb53-737"><a href="#cb53-737"></a><span class="ss">    - </span>The others lines contain the users' profiles: each line contains name and age of a person</span>
<span id="cb53-738"><a href="#cb53-738"></a><span class="ss">2. </span>Create a DataFrame containing the for each name the average value of age and the number of person with that name</span>
<span id="cb53-739"><a href="#cb53-739"></a></span>
<span id="cb53-740"><a href="#cb53-740"></a>Input file example</span>
<span id="cb53-741"><a href="#cb53-741"></a></span>
<span id="cb53-742"><a href="#cb53-742"></a><span class="in">```</span></span>
<span id="cb53-743"><a href="#cb53-743"></a><span class="in">name,age</span></span>
<span id="cb53-744"><a href="#cb53-744"></a><span class="in">Andy,30</span></span>
<span id="cb53-745"><a href="#cb53-745"></a><span class="in">Michael,15</span></span>
<span id="cb53-746"><a href="#cb53-746"></a><span class="in">Justin,19</span></span>
<span id="cb53-747"><a href="#cb53-747"></a><span class="in">Andy,40</span></span>
<span id="cb53-748"><a href="#cb53-748"></a><span class="in">```</span></span>
<span id="cb53-749"><a href="#cb53-749"></a></span>
<span id="cb53-750"><a href="#cb53-750"></a>Expected output example</span>
<span id="cb53-751"><a href="#cb53-751"></a></span>
<span id="cb53-752"><a href="#cb53-752"></a><span class="in">```</span></span>
<span id="cb53-753"><a href="#cb53-753"></a><span class="in">name,avg(age),count(name)</span></span>
<span id="cb53-754"><a href="#cb53-754"></a><span class="in">Andy,35,2</span></span>
<span id="cb53-755"><a href="#cb53-755"></a><span class="in">Michael,15,1</span></span>
<span id="cb53-756"><a href="#cb53-756"></a><span class="in">Justin,19,1</span></span>
<span id="cb53-757"><a href="#cb53-757"></a><span class="in">```</span></span>
<span id="cb53-758"><a href="#cb53-758"></a></span>
<span id="cb53-759"><a href="#cb53-759"></a><span class="in">```python</span></span>
<span id="cb53-760"><a href="#cb53-760"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-761"><a href="#cb53-761"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-762"><a href="#cb53-762"></a></span>
<span id="cb53-763"><a href="#cb53-763"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-764"><a href="#cb53-764"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-765"><a href="#cb53-765"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb53-766"><a href="#cb53-766"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-767"><a href="#cb53-767"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-768"><a href="#cb53-768"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-769"><a href="#cb53-769"></a>)</span>
<span id="cb53-770"><a href="#cb53-770"></a></span>
<span id="cb53-771"><a href="#cb53-771"></a>grouped <span class="op">=</span> df.groupBy(<span class="st">"name"</span>) <span class="op">\</span></span>
<span id="cb53-772"><a href="#cb53-772"></a>    .agg({<span class="st">"age"</span>: <span class="st">"avg"</span>, <span class="st">"name"</span>: <span class="st">"count"</span>})</span>
<span id="cb53-773"><a href="#cb53-773"></a><span class="in">```</span></span>
<span id="cb53-774"><a href="#cb53-774"></a></span>
<span id="cb53-775"><a href="#cb53-775"></a>:::</span>
<span id="cb53-776"><a href="#cb53-776"></a></span>
<span id="cb53-777"><a href="#cb53-777"></a><span class="fu">### Sort method</span></span>
<span id="cb53-778"><a href="#cb53-778"></a>The <span class="in">`sort(col1, ..., coln, ascending=True)`</span> method of the DataFrame class returns a new DataFrame that contains the same data of the input one, but whose content is sorted by <span class="in">`col1, ..., coln`</span>. <span class="in">`ascending`</span> determines if the sort should be ascending (<span class="in">`True`</span>) or descending (<span class="in">`False`</span>).</span>
<span id="cb53-779"><a href="#cb53-779"></a></span>
<span id="cb53-780"><a href="#cb53-780"></a><span class="fu">## DataFrames and the SQL language</span></span>
<span id="cb53-781"><a href="#cb53-781"></a>Sparks allows querying the content of a DataFrame also by using the SQL language, but in order to do this a table name must be assigned to a DataFrame. The <span class="in">`createOrReplaceTempView(tableName)`</span> method of the <span class="in">`DataFrame`</span> class can be used to assign a <span class="in">`tableName`</span> as table name to the DataFrame which it is invoked on.</span>
<span id="cb53-782"><a href="#cb53-782"></a></span>
<span id="cb53-783"><a href="#cb53-783"></a>Once the DataFrame has been mapped to table names, SQL-like queries can be executed (the executed queries return DataFrame objects). The <span class="in">`sql(query)`</span> method of the <span class="in">`SparkSession`</span> class can be used to execute a SQL-like query, where <span class="in">`query`</span> is a SQL-like query. Currently some SQL features are not supported (e.g., nested subqueries in the "WHERE" clause are not allowed).</span>
<span id="cb53-784"><a href="#cb53-784"></a></span>
<span id="cb53-785"><a href="#cb53-785"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-786"><a href="#cb53-786"></a><span class="fu">### Example 1</span></span>
<span id="cb53-787"><a href="#cb53-787"></a><span class="ss">1. </span>Create a DataFrame from a JSON file containing the profiles of a set of people: each line of the file contains a JSON object containing name, age, and gender of a person;</span>
<span id="cb53-788"><a href="#cb53-788"></a><span class="ss">2. </span>Create a new DataFrame containing only the people with age between 20 and 31 and print them on the standard output (use the SQL language to perform this operation).</span>
<span id="cb53-789"><a href="#cb53-789"></a></span>
<span id="cb53-790"><a href="#cb53-790"></a><span class="in">```python</span></span>
<span id="cb53-791"><a href="#cb53-791"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-792"><a href="#cb53-792"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-793"><a href="#cb53-793"></a></span>
<span id="cb53-794"><a href="#cb53-794"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-795"><a href="#cb53-795"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-796"><a href="#cb53-796"></a>    <span class="st">"people.json"</span>,</span>
<span id="cb53-797"><a href="#cb53-797"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"json"</span></span>
<span id="cb53-798"><a href="#cb53-798"></a>)</span>
<span id="cb53-799"><a href="#cb53-799"></a></span>
<span id="cb53-800"><a href="#cb53-800"></a><span class="co">## Assign the “table name” people to the df DataFrame</span></span>
<span id="cb53-801"><a href="#cb53-801"></a>df.createOrReplaceTempView(<span class="st">"people"</span>)</span>
<span id="cb53-802"><a href="#cb53-802"></a></span>
<span id="cb53-803"><a href="#cb53-803"></a><span class="co">## Select the people with age between 20 and 31</span></span>
<span id="cb53-804"><a href="#cb53-804"></a><span class="co">## by querying the people table</span></span>
<span id="cb53-805"><a href="#cb53-805"></a>selectedPeople <span class="op">=</span> spark.sql(</span>
<span id="cb53-806"><a href="#cb53-806"></a>    <span class="st">"SELECT * FROM people WHERE age&gt;=20 and age&lt;=31"</span></span>
<span id="cb53-807"><a href="#cb53-807"></a>)</span>
<span id="cb53-808"><a href="#cb53-808"></a></span>
<span id="cb53-809"><a href="#cb53-809"></a><span class="co">## Print the result on the standard output</span></span>
<span id="cb53-810"><a href="#cb53-810"></a>selectedPeople.show()</span>
<span id="cb53-811"><a href="#cb53-811"></a><span class="in">```</span></span>
<span id="cb53-812"><a href="#cb53-812"></a></span>
<span id="cb53-813"><a href="#cb53-813"></a>:::</span>
<span id="cb53-814"><a href="#cb53-814"></a></span>
<span id="cb53-815"><a href="#cb53-815"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-816"><a href="#cb53-816"></a><span class="fu">### Example 2</span></span>
<span id="cb53-817"><a href="#cb53-817"></a><span class="ss">1. </span>Create two DataFrames</span>
<span id="cb53-818"><a href="#cb53-818"></a><span class="ss">    - </span>One based on the "people_id.csv" file that contains the profiles of a set of people, the schema is: uid, name, age;</span>
<span id="cb53-819"><a href="#cb53-819"></a><span class="ss">    - </span>One based on the "liked_sports.csv" file that contains the liked sports for each person, the schema is: uid, sportname.</span>
<span id="cb53-820"><a href="#cb53-820"></a><span class="ss">2. </span>Join the content of the two DataFrames and show it on the standard output.</span>
<span id="cb53-821"><a href="#cb53-821"></a></span>
<span id="cb53-822"><a href="#cb53-822"></a><span class="in">```python</span></span>
<span id="cb53-823"><a href="#cb53-823"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-824"><a href="#cb53-824"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-825"><a href="#cb53-825"></a></span>
<span id="cb53-826"><a href="#cb53-826"></a><span class="co">## Read people_id.csv and store it in a DataFrame</span></span>
<span id="cb53-827"><a href="#cb53-827"></a>dfPeople <span class="op">=</span> spark.read.load(</span>
<span id="cb53-828"><a href="#cb53-828"></a>    <span class="st">"people_id.csv"</span>,</span>
<span id="cb53-829"><a href="#cb53-829"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-830"><a href="#cb53-830"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-831"><a href="#cb53-831"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-832"><a href="#cb53-832"></a>)</span>
<span id="cb53-833"><a href="#cb53-833"></a></span>
<span id="cb53-834"><a href="#cb53-834"></a><span class="co">## Assign the “table name” people to the dfPerson</span></span>
<span id="cb53-835"><a href="#cb53-835"></a>dfPeople.createOrReplaceTempView(<span class="st">"people"</span>)</span>
<span id="cb53-836"><a href="#cb53-836"></a></span>
<span id="cb53-837"><a href="#cb53-837"></a><span class="co">## Read liked_sports.csv and store it in a DataFrame</span></span>
<span id="cb53-838"><a href="#cb53-838"></a>dfUidSports <span class="op">=</span> spark.read.load(</span>
<span id="cb53-839"><a href="#cb53-839"></a>    <span class="st">"liked_sports.csv"</span>,</span>
<span id="cb53-840"><a href="#cb53-840"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-841"><a href="#cb53-841"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-842"><a href="#cb53-842"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-843"><a href="#cb53-843"></a>)</span>
<span id="cb53-844"><a href="#cb53-844"></a></span>
<span id="cb53-845"><a href="#cb53-845"></a><span class="co">## Assign the “table name” liked to dfUidSports</span></span>
<span id="cb53-846"><a href="#cb53-846"></a>dfUidSports.createOrReplaceTempView(<span class="st">"liked"</span>)</span>
<span id="cb53-847"><a href="#cb53-847"></a></span>
<span id="cb53-848"><a href="#cb53-848"></a><span class="co">## Join the two input tables by using the</span></span>
<span id="cb53-849"><a href="#cb53-849"></a><span class="co">#SQL-like syntax</span></span>
<span id="cb53-850"><a href="#cb53-850"></a>dfPersonLikes <span class="op">=</span> spark.sql(</span>
<span id="cb53-851"><a href="#cb53-851"></a>    <span class="st">"SELECT * from people, liked where people.uid=liked.uid"</span></span>
<span id="cb53-852"><a href="#cb53-852"></a>)</span>
<span id="cb53-853"><a href="#cb53-853"></a></span>
<span id="cb53-854"><a href="#cb53-854"></a><span class="co">## Print the result on the standard output</span></span>
<span id="cb53-855"><a href="#cb53-855"></a>dfPersonLikes.show()</span>
<span id="cb53-856"><a href="#cb53-856"></a><span class="in">```</span></span>
<span id="cb53-857"><a href="#cb53-857"></a></span>
<span id="cb53-858"><a href="#cb53-858"></a>:::</span>
<span id="cb53-859"><a href="#cb53-859"></a></span>
<span id="cb53-860"><a href="#cb53-860"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-861"><a href="#cb53-861"></a><span class="fu">### Example 3</span></span>
<span id="cb53-862"><a href="#cb53-862"></a><span class="ss">1. </span>Create a DataFrame from the "people.csv" file that contains the profiles of a set of people</span>
<span id="cb53-863"><a href="#cb53-863"></a><span class="ss">    - </span>The first line contains the header;</span>
<span id="cb53-864"><a href="#cb53-864"></a><span class="ss">    - </span>The others lines contain the users' profiles: each line contains name and age of a person.</span>
<span id="cb53-865"><a href="#cb53-865"></a><span class="ss">2. </span>Create a DataFrame containing for each name the average value of age and the number of person with that name. Print its content on the standard output.</span>
<span id="cb53-866"><a href="#cb53-866"></a></span>
<span id="cb53-867"><a href="#cb53-867"></a>Input file example</span>
<span id="cb53-868"><a href="#cb53-868"></a></span>
<span id="cb53-869"><a href="#cb53-869"></a><span class="in">```</span></span>
<span id="cb53-870"><a href="#cb53-870"></a><span class="in">name,age</span></span>
<span id="cb53-871"><a href="#cb53-871"></a><span class="in">Andy,30</span></span>
<span id="cb53-872"><a href="#cb53-872"></a><span class="in">Michael,15</span></span>
<span id="cb53-873"><a href="#cb53-873"></a><span class="in">Justin,19</span></span>
<span id="cb53-874"><a href="#cb53-874"></a><span class="in">Andy,40</span></span>
<span id="cb53-875"><a href="#cb53-875"></a><span class="in">```</span></span>
<span id="cb53-876"><a href="#cb53-876"></a></span>
<span id="cb53-877"><a href="#cb53-877"></a>Expected output example</span>
<span id="cb53-878"><a href="#cb53-878"></a></span>
<span id="cb53-879"><a href="#cb53-879"></a><span class="in">```</span></span>
<span id="cb53-880"><a href="#cb53-880"></a><span class="in">name,avg(age),count(name)</span></span>
<span id="cb53-881"><a href="#cb53-881"></a><span class="in">Andy,35,2</span></span>
<span id="cb53-882"><a href="#cb53-882"></a><span class="in">Michael,15,1</span></span>
<span id="cb53-883"><a href="#cb53-883"></a><span class="in">Justin,19,1</span></span>
<span id="cb53-884"><a href="#cb53-884"></a><span class="in">```</span></span>
<span id="cb53-885"><a href="#cb53-885"></a></span>
<span id="cb53-886"><a href="#cb53-886"></a><span class="in">```python</span></span>
<span id="cb53-887"><a href="#cb53-887"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-888"><a href="#cb53-888"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-889"><a href="#cb53-889"></a></span>
<span id="cb53-890"><a href="#cb53-890"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-891"><a href="#cb53-891"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-892"><a href="#cb53-892"></a>    <span class="st">"people.json"</span>,</span>
<span id="cb53-893"><a href="#cb53-893"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"json"</span></span>
<span id="cb53-894"><a href="#cb53-894"></a>)</span>
<span id="cb53-895"><a href="#cb53-895"></a></span>
<span id="cb53-896"><a href="#cb53-896"></a><span class="co">## Assign the “table name” people to the df DataFrame</span></span>
<span id="cb53-897"><a href="#cb53-897"></a>df.createOrReplaceTempView(<span class="st">"people"</span>)</span>
<span id="cb53-898"><a href="#cb53-898"></a></span>
<span id="cb53-899"><a href="#cb53-899"></a><span class="co">## Define groups based on the value of name and</span></span>
<span id="cb53-900"><a href="#cb53-900"></a><span class="co">## compute average and number of records for each group</span></span>
<span id="cb53-901"><a href="#cb53-901"></a>nameAvgAgeCount <span class="op">=</span> spark.sql(</span>
<span id="cb53-902"><a href="#cb53-902"></a>    <span class="st">"SELECT name, avg(age), count(name) FROM people GROUP BY name"</span></span>
<span id="cb53-903"><a href="#cb53-903"></a>)</span>
<span id="cb53-904"><a href="#cb53-904"></a></span>
<span id="cb53-905"><a href="#cb53-905"></a><span class="co">## Print the result on the standard output</span></span>
<span id="cb53-906"><a href="#cb53-906"></a>nameAvgAgeCount.show()</span>
<span id="cb53-907"><a href="#cb53-907"></a><span class="in">```</span></span>
<span id="cb53-908"><a href="#cb53-908"></a></span>
<span id="cb53-909"><a href="#cb53-909"></a>:::</span>
<span id="cb53-910"><a href="#cb53-910"></a></span>
<span id="cb53-911"><a href="#cb53-911"></a><span class="fu">## Save DataFrames</span></span>
<span id="cb53-912"><a href="#cb53-912"></a>The content of DataFrames can be stored on disk by using two approches</span>
<span id="cb53-913"><a href="#cb53-913"></a></span>
<span id="cb53-914"><a href="#cb53-914"></a><span class="ss">- </span>Convert DataFrames to traditional RDDs by using the rdd method of the DataFrame, and then use <span class="in">`saveAsTextFile(outputFolder)`</span>;</span>
<span id="cb53-915"><a href="#cb53-915"></a><span class="ss">- </span>Use the <span class="in">`write()`</span> method of DataFrames, that returns a <span class="in">`DatFrameWriter`</span> class instance.</span>
<span id="cb53-916"><a href="#cb53-916"></a></span>
<span id="cb53-917"><a href="#cb53-917"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-918"><a href="#cb53-918"></a><span class="fu">### Example 1</span></span>
<span id="cb53-919"><a href="#cb53-919"></a><span class="ss">1. </span>Create a DataFrame from the "people.csv" file that contains the profiles of a set of people</span>
<span id="cb53-920"><a href="#cb53-920"></a><span class="ss">    - </span>The first line contains the header;</span>
<span id="cb53-921"><a href="#cb53-921"></a><span class="ss">    - </span>The others lines contain the users' profiles: each line contains name, age, and gender of a person.</span>
<span id="cb53-922"><a href="#cb53-922"></a><span class="ss">2. </span>Store the DataFrame in the output folder by using the <span class="in">`saveAsTextFile()`</span> method.</span>
<span id="cb53-923"><a href="#cb53-923"></a></span>
<span id="cb53-924"><a href="#cb53-924"></a><span class="in">```python</span></span>
<span id="cb53-925"><a href="#cb53-925"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-926"><a href="#cb53-926"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-927"><a href="#cb53-927"></a></span>
<span id="cb53-928"><a href="#cb53-928"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-929"><a href="#cb53-929"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-930"><a href="#cb53-930"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb53-931"><a href="#cb53-931"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-932"><a href="#cb53-932"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-933"><a href="#cb53-933"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-934"><a href="#cb53-934"></a>)</span>
<span id="cb53-935"><a href="#cb53-935"></a></span>
<span id="cb53-936"><a href="#cb53-936"></a><span class="co">## Save it</span></span>
<span id="cb53-937"><a href="#cb53-937"></a>df.rdd.saveAsTextFile(outputPath)</span>
<span id="cb53-938"><a href="#cb53-938"></a><span class="in">```</span></span>
<span id="cb53-939"><a href="#cb53-939"></a></span>
<span id="cb53-940"><a href="#cb53-940"></a>:::</span>
<span id="cb53-941"><a href="#cb53-941"></a></span>
<span id="cb53-942"><a href="#cb53-942"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-943"><a href="#cb53-943"></a><span class="fu">### Example 2</span></span>
<span id="cb53-944"><a href="#cb53-944"></a><span class="ss">1. </span>Create a DataFrame from the "people.csv" file that contains the profiles of a set of people</span>
<span id="cb53-945"><a href="#cb53-945"></a><span class="ss">    - </span>The first line contains the header;</span>
<span id="cb53-946"><a href="#cb53-946"></a><span class="ss">    - </span>The others lines contain the users' profiles: each line contains name, age, and gender of a person.</span>
<span id="cb53-947"><a href="#cb53-947"></a><span class="ss">2. </span>Store the DataFrame in the output folder by using the <span class="in">`write()`</span> method, with the CSV format.</span>
<span id="cb53-948"><a href="#cb53-948"></a></span>
<span id="cb53-949"><a href="#cb53-949"></a><span class="in">```python</span></span>
<span id="cb53-950"><a href="#cb53-950"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-951"><a href="#cb53-951"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-952"><a href="#cb53-952"></a></span>
<span id="cb53-953"><a href="#cb53-953"></a><span class="co">## Create a DataFrame from people.csv</span></span>
<span id="cb53-954"><a href="#cb53-954"></a>df <span class="op">=</span> spark.read.load(</span>
<span id="cb53-955"><a href="#cb53-955"></a>    <span class="st">"people.csv"</span>,</span>
<span id="cb53-956"><a href="#cb53-956"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-957"><a href="#cb53-957"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-958"><a href="#cb53-958"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-959"><a href="#cb53-959"></a>)</span>
<span id="cb53-960"><a href="#cb53-960"></a></span>
<span id="cb53-961"><a href="#cb53-961"></a><span class="co">## Save it</span></span>
<span id="cb53-962"><a href="#cb53-962"></a>df.write.csv(outputPath, header<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb53-963"><a href="#cb53-963"></a><span class="in">```</span></span>
<span id="cb53-964"><a href="#cb53-964"></a></span>
<span id="cb53-965"><a href="#cb53-965"></a>:::</span>
<span id="cb53-966"><a href="#cb53-966"></a></span>
<span id="cb53-967"><a href="#cb53-967"></a><span class="fu">## UDFs: User Defines Functions</span></span>
<span id="cb53-968"><a href="#cb53-968"></a>Spark SQL provides a set of system predefined functions, which can be used in some transformations (e.g., <span class="in">`selectExpr()`</span>, <span class="in">`sort()`</span>) but also in the SQL queries. Some examples are</span>
<span id="cb53-969"><a href="#cb53-969"></a></span>
<span id="cb53-970"><a href="#cb53-970"></a><span class="ss">- </span><span class="in">`hour(Timestamp)`</span></span>
<span id="cb53-971"><a href="#cb53-971"></a><span class="ss">- </span><span class="in">`abs(Integer)`</span></span>
<span id="cb53-972"><a href="#cb53-972"></a><span class="ss">- </span>...</span>
<span id="cb53-973"><a href="#cb53-973"></a></span>
<span id="cb53-974"><a href="#cb53-974"></a>However, users can also define custom functions, which are called **User Defined Functions** (**UDFs**).</span>
<span id="cb53-975"><a href="#cb53-975"></a></span>
<span id="cb53-976"><a href="#cb53-976"></a>UDFs are defined/registered by invoking the <span class="in">`udf().register(name, function, datatype)`</span> on the <span class="in">`SparkSession`</span>, where</span>
<span id="cb53-977"><a href="#cb53-977"></a></span>
<span id="cb53-978"><a href="#cb53-978"></a><span class="ss">- </span><span class="in">`name`</span> is the name of the defined UDF</span>
<span id="cb53-979"><a href="#cb53-979"></a><span class="ss">- </span><span class="in">`function`</span> is a lambda function used to specify how the parameters of the function are used to generate the returned value</span>
<span id="cb53-980"><a href="#cb53-980"></a><span class="ss">    - </span>One of more input parameters are accepted</span>
<span id="cb53-981"><a href="#cb53-981"></a><span class="ss">    - </span>One single returned value is accepted</span>
<span id="cb53-982"><a href="#cb53-982"></a><span class="ss">- </span><span class="in">`datatype`</span> is the SQL data type of the returned value</span>
<span id="cb53-983"><a href="#cb53-983"></a></span>
<span id="cb53-984"><a href="#cb53-984"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-985"><a href="#cb53-985"></a><span class="fu">### Example</span></span>
<span id="cb53-986"><a href="#cb53-986"></a>Define a UDFs that, given a string, returns the length of the string.</span>
<span id="cb53-987"><a href="#cb53-987"></a></span>
<span id="cb53-988"><a href="#cb53-988"></a><span class="in">```python</span></span>
<span id="cb53-989"><a href="#cb53-989"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-990"><a href="#cb53-990"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-991"><a href="#cb53-991"></a></span>
<span id="cb53-992"><a href="#cb53-992"></a><span class="co">## Define the UDF</span></span>
<span id="cb53-993"><a href="#cb53-993"></a><span class="co">## name: length</span></span>
<span id="cb53-994"><a href="#cb53-994"></a><span class="co">## output: integer value</span></span>
<span id="cb53-995"><a href="#cb53-995"></a>spark.udf.register(<span class="st">"length"</span>, <span class="kw">lambda</span> x: <span class="bu">len</span>(x))</span>
<span id="cb53-996"><a href="#cb53-996"></a><span class="in">```</span></span>
<span id="cb53-997"><a href="#cb53-997"></a></span>
<span id="cb53-998"><a href="#cb53-998"></a>Use of the defined UDF in a selectExpr transformation.</span>
<span id="cb53-999"><a href="#cb53-999"></a></span>
<span id="cb53-1000"><a href="#cb53-1000"></a><span class="in">```python</span></span>
<span id="cb53-1001"><a href="#cb53-1001"></a>result <span class="op">=</span> inputDF.selectExpr(<span class="st">"length(name) as size"</span>)</span>
<span id="cb53-1002"><a href="#cb53-1002"></a><span class="in">```</span></span>
<span id="cb53-1003"><a href="#cb53-1003"></a></span>
<span id="cb53-1004"><a href="#cb53-1004"></a>Use of the defined UDF in a SQL query.</span>
<span id="cb53-1005"><a href="#cb53-1005"></a><span class="in">```python</span></span>
<span id="cb53-1006"><a href="#cb53-1006"></a>result <span class="op">=</span> spark.sql(<span class="st">"SELECT length(name) FROM profiles"</span>)</span>
<span id="cb53-1007"><a href="#cb53-1007"></a><span class="in">```</span></span>
<span id="cb53-1008"><a href="#cb53-1008"></a></span>
<span id="cb53-1009"><a href="#cb53-1009"></a>:::</span>
<span id="cb53-1010"><a href="#cb53-1010"></a></span>
<span id="cb53-1011"><a href="#cb53-1011"></a><span class="fu">## Other notes</span></span>
<span id="cb53-1012"><a href="#cb53-1012"></a><span class="fu">### Data warehouse methods: cube and rollup</span></span>
<span id="cb53-1013"><a href="#cb53-1013"></a>The method <span class="in">`cube(col1, ..., coln)`</span> of the <span class="in">`DataFrame`</span> class can be used to create a multi-dimensional cube for the input DataFrame, on top of which aggregate functions can be computed for each group.</span>
<span id="cb53-1014"><a href="#cb53-1014"></a></span>
<span id="cb53-1015"><a href="#cb53-1015"></a>The method <span class="in">`rollup(col1, ..., coln)`</span> of the <span class="in">`DataFrame`</span> class can be used to create a multi-dimensional rollup for the input DataFrame, on top of which aggregate functions can be computed for each group.</span>
<span id="cb53-1016"><a href="#cb53-1016"></a></span>
<span id="cb53-1017"><a href="#cb53-1017"></a>Specify which attributes are used to split the input data in groups by using <span class="in">`cube(col1, ..., coln)`</span> or <span class="in">`rollup(col1, ..., coln)`</span>, respectively, then, apply the aggregate functions to compute for each group of the cube/rollup. The result is a DataFrame. The same aggregate functions/methods already discussed for groupBy can be used also for cube and rollup.</span>
<span id="cb53-1018"><a href="#cb53-1018"></a></span>
<span id="cb53-1019"><a href="#cb53-1019"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-1020"><a href="#cb53-1020"></a><span class="fu">### Example</span></span>
<span id="cb53-1021"><a href="#cb53-1021"></a><span class="ss">1. </span>Create a DataFrame from the "purchases.csv" file</span>
<span id="cb53-1022"><a href="#cb53-1022"></a><span class="ss">    - </span>The first line contains the header;</span>
<span id="cb53-1023"><a href="#cb53-1023"></a><span class="ss">    - </span>The others lines contain the quantities of purchased products by users: each line contains userid, productid, quantity.</span>
<span id="cb53-1024"><a href="#cb53-1024"></a><span class="ss">2. </span>Create a first DataFrame containing the result of the cube method. Define one group for each pair userid, productid and compute the sum of quantity in each group;</span>
<span id="cb53-1025"><a href="#cb53-1025"></a>3.Create a second DataFrame containing the result of the rollup method. Define one group for each pair userid, productid and compute the sum of quantity in each group.</span>
<span id="cb53-1026"><a href="#cb53-1026"></a></span>
<span id="cb53-1027"><a href="#cb53-1027"></a>Input file</span>
<span id="cb53-1028"><a href="#cb53-1028"></a></span>
<span id="cb53-1029"><a href="#cb53-1029"></a><span class="in">```</span></span>
<span id="cb53-1030"><a href="#cb53-1030"></a><span class="in">userid,productid,quantity</span></span>
<span id="cb53-1031"><a href="#cb53-1031"></a><span class="in">u1,p1,10</span></span>
<span id="cb53-1032"><a href="#cb53-1032"></a><span class="in">u1,p1,20</span></span>
<span id="cb53-1033"><a href="#cb53-1033"></a><span class="in">u1,p2,20</span></span>
<span id="cb53-1034"><a href="#cb53-1034"></a><span class="in">u1,p3,10</span></span>
<span id="cb53-1035"><a href="#cb53-1035"></a><span class="in">u2,p1,20</span></span>
<span id="cb53-1036"><a href="#cb53-1036"></a><span class="in">u2,p3,40</span></span>
<span id="cb53-1037"><a href="#cb53-1037"></a><span class="in">u2,p3,30</span></span>
<span id="cb53-1038"><a href="#cb53-1038"></a><span class="in">```</span></span>
<span id="cb53-1039"><a href="#cb53-1039"></a></span>
<span id="cb53-1040"><a href="#cb53-1040"></a>Expected output - cube</span>
<span id="cb53-1041"><a href="#cb53-1041"></a></span>
<span id="cb53-1042"><a href="#cb53-1042"></a><span class="in">```</span></span>
<span id="cb53-1043"><a href="#cb53-1043"></a><span class="in">userid,productid,sum(quantity)</span></span>
<span id="cb53-1044"><a href="#cb53-1044"></a><span class="in">null    null    150</span></span>
<span id="cb53-1045"><a href="#cb53-1045"></a><span class="in">null    p1      50</span></span>
<span id="cb53-1046"><a href="#cb53-1046"></a><span class="in">null    p2      20</span></span>
<span id="cb53-1047"><a href="#cb53-1047"></a><span class="in">null    p3      80</span></span>
<span id="cb53-1048"><a href="#cb53-1048"></a><span class="in">u1      null    60</span></span>
<span id="cb53-1049"><a href="#cb53-1049"></a><span class="in">u1      p1      30</span></span>
<span id="cb53-1050"><a href="#cb53-1050"></a><span class="in">u1      p2      20</span></span>
<span id="cb53-1051"><a href="#cb53-1051"></a><span class="in">u1      p3      10</span></span>
<span id="cb53-1052"><a href="#cb53-1052"></a><span class="in">u2      null    90</span></span>
<span id="cb53-1053"><a href="#cb53-1053"></a><span class="in">u2      p1      20</span></span>
<span id="cb53-1054"><a href="#cb53-1054"></a><span class="in">u2      p3      70</span></span>
<span id="cb53-1055"><a href="#cb53-1055"></a><span class="in">```</span></span>
<span id="cb53-1056"><a href="#cb53-1056"></a></span>
<span id="cb53-1057"><a href="#cb53-1057"></a>Expected output - rollup</span>
<span id="cb53-1058"><a href="#cb53-1058"></a></span>
<span id="cb53-1059"><a href="#cb53-1059"></a><span class="in">```</span></span>
<span id="cb53-1060"><a href="#cb53-1060"></a><span class="in">userid,productid,sum(quantity)</span></span>
<span id="cb53-1061"><a href="#cb53-1061"></a><span class="in">null    null    150</span></span>
<span id="cb53-1062"><a href="#cb53-1062"></a><span class="in">u1      null    60</span></span>
<span id="cb53-1063"><a href="#cb53-1063"></a><span class="in">u1      p1      30</span></span>
<span id="cb53-1064"><a href="#cb53-1064"></a><span class="in">u1      p2      20</span></span>
<span id="cb53-1065"><a href="#cb53-1065"></a><span class="in">u1      p3      10</span></span>
<span id="cb53-1066"><a href="#cb53-1066"></a><span class="in">u2      null    90</span></span>
<span id="cb53-1067"><a href="#cb53-1067"></a><span class="in">u2      p1      20</span></span>
<span id="cb53-1068"><a href="#cb53-1068"></a><span class="in">u2      p3      70</span></span>
<span id="cb53-1069"><a href="#cb53-1069"></a><span class="in">```</span></span>
<span id="cb53-1070"><a href="#cb53-1070"></a></span>
<span id="cb53-1071"><a href="#cb53-1071"></a><span class="in">```python</span></span>
<span id="cb53-1072"><a href="#cb53-1072"></a><span class="co">## Create a Spark Session object</span></span>
<span id="cb53-1073"><a href="#cb53-1073"></a>spark <span class="op">=</span> SparkSession.builder.getOrCreate()</span>
<span id="cb53-1074"><a href="#cb53-1074"></a></span>
<span id="cb53-1075"><a href="#cb53-1075"></a><span class="co">## Read purchases.csv and store it in a DataFrame</span></span>
<span id="cb53-1076"><a href="#cb53-1076"></a>dfPurchases <span class="op">=</span> spark.read.load(</span>
<span id="cb53-1077"><a href="#cb53-1077"></a>    <span class="st">"purchases.csv"</span>,</span>
<span id="cb53-1078"><a href="#cb53-1078"></a>    <span class="bu">format</span><span class="op">=</span><span class="st">"csv"</span>,</span>
<span id="cb53-1079"><a href="#cb53-1079"></a>    header<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb53-1080"><a href="#cb53-1080"></a>    inferSchema<span class="op">=</span><span class="va">True</span></span>
<span id="cb53-1081"><a href="#cb53-1081"></a>)</span>
<span id="cb53-1082"><a href="#cb53-1082"></a></span>
<span id="cb53-1083"><a href="#cb53-1083"></a>dfCube<span class="op">=</span>dfPurchases <span class="op">\</span></span>
<span id="cb53-1084"><a href="#cb53-1084"></a>    .cube(<span class="st">"userid"</span>,<span class="st">"productid"</span>) <span class="op">\</span></span>
<span id="cb53-1085"><a href="#cb53-1085"></a>    .agg({<span class="st">"quantity"</span>: <span class="st">"sum"</span>})</span>
<span id="cb53-1086"><a href="#cb53-1086"></a></span>
<span id="cb53-1087"><a href="#cb53-1087"></a>dfRollup<span class="op">=</span>dfPurchases <span class="op">\</span></span>
<span id="cb53-1088"><a href="#cb53-1088"></a>    .rollup(<span class="st">"userid"</span>,<span class="st">"productid"</span>)<span class="op">\</span></span>
<span id="cb53-1089"><a href="#cb53-1089"></a>    .agg({<span class="st">"quantity"</span>: <span class="st">"sum"</span>})</span>
<span id="cb53-1090"><a href="#cb53-1090"></a><span class="in">```</span></span>
<span id="cb53-1091"><a href="#cb53-1091"></a></span>
<span id="cb53-1092"><a href="#cb53-1092"></a>:::</span>
<span id="cb53-1093"><a href="#cb53-1093"></a></span>
<span id="cb53-1094"><a href="#cb53-1094"></a><span class="fu">### Set methods</span></span>
<span id="cb53-1095"><a href="#cb53-1095"></a>Similarly to RDDs also DataFrames can be combined by using set transformations</span>
<span id="cb53-1096"><a href="#cb53-1096"></a></span>
<span id="cb53-1097"><a href="#cb53-1097"></a><span class="ss">- </span><span class="in">`df1.union(df2)`</span></span>
<span id="cb53-1098"><a href="#cb53-1098"></a><span class="ss">- </span><span class="in">`df1.intersect(df2)`</span></span>
<span id="cb53-1099"><a href="#cb53-1099"></a><span class="ss">- </span><span class="in">`df1.subtract(df2)`</span></span>
<span id="cb53-1100"><a href="#cb53-1100"></a></span>
<span id="cb53-1101"><a href="#cb53-1101"></a><span class="fu">### Broadcast join</span></span>
<span id="cb53-1102"><a href="#cb53-1102"></a>Spark SQL automatically implements a broadcast version of the join operation if one of the two input DataFrames is small enough to be stored in the main memory of each executor.</span>
<span id="cb53-1103"><a href="#cb53-1103"></a></span>
<span id="cb53-1104"><a href="#cb53-1104"></a>It is possible to suggest/force it by creating a broadcast version of a DataFrame.</span>
<span id="cb53-1105"><a href="#cb53-1105"></a></span>
<span id="cb53-1106"><a href="#cb53-1106"></a>:::{.callout-note collapse="true"}</span>
<span id="cb53-1107"><a href="#cb53-1107"></a><span class="fu">### Example</span></span>
<span id="cb53-1108"><a href="#cb53-1108"></a></span>
<span id="cb53-1109"><a href="#cb53-1109"></a><span class="in">```python</span></span>
<span id="cb53-1110"><a href="#cb53-1110"></a>dfPersonLikesBroadcast <span class="op">=</span> dfUidSports<span class="op">\</span></span>
<span id="cb53-1111"><a href="#cb53-1111"></a>    .join(</span>
<span id="cb53-1112"><a href="#cb53-1112"></a>        broadcast(dfPersons),</span>
<span id="cb53-1113"><a href="#cb53-1113"></a>        dfPersons.uid <span class="op">==</span> dfUidSports.uid</span>
<span id="cb53-1114"><a href="#cb53-1114"></a>    )</span>
<span id="cb53-1115"><a href="#cb53-1115"></a><span class="in">```</span></span>
<span id="cb53-1116"><a href="#cb53-1116"></a></span>
<span id="cb53-1117"><a href="#cb53-1117"></a>|||</span>
<span id="cb53-1118"><a href="#cb53-1118"></a>|-|--|</span>
<span id="cb53-1119"><a href="#cb53-1119"></a>| <span class="in">`broadcast(dfPersons)`</span> | In this case we specify that <span class="in">`dfPersons`</span> must be broadcasted and hence Spark will execute the join operation by using a broadcast join. |</span>
<span id="cb53-1120"><a href="#cb53-1120"></a></span>
<span id="cb53-1121"><a href="#cb53-1121"></a>:::</span>
<span id="cb53-1122"><a href="#cb53-1122"></a></span>
<span id="cb53-1123"><a href="#cb53-1123"></a><span class="fu">### Execution plan</span></span>
<span id="cb53-1124"><a href="#cb53-1124"></a>The method <span class="in">`explain()`</span> can be invoked on a DataFrame to print on the standard output the execution plan of the part of the code that is used to compute the content of the DataFrame on which <span class="in">`explain()`</span> is invoked.</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>