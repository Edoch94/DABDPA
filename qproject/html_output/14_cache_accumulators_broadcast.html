<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.335">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Distributed architectures for big data processing and analytics - 16&nbsp; Cache, Accumulators, Broadcast Variables</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./15b_pagerank.html" rel="next">
<link href="./13_rdd_numbers.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Cache, Accumulators, Broadcast Variables</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Distributed architectures for big data processing and analytics</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Index</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./00_01_intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to Big data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./02_architectures.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Big data architectures</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03b_HDFS_clc.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">HDFS and Hadoop: command line commands</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./03_intro_hadoop.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Introduction to Hadoop and MapReduce</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./04_hadoop_implementation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">How to write MapReduce programs in Hadoop</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./05_mapreduce_patterns_1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">MapReduce patterns - 1</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./06_mapreduce_advanced_topics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">MapReduce and Hadoop Advanced Topics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./07_mapreduce_patterns_2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">MapReduce patterns - 2</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./08_sql_operators_mapreduce.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Relational Algebra Operations and MapReduce</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10b_spark_submit_execute.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">How to submit/execute a Spark application</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./10_intro_spark.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Introduction to Spark</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./11_rdd_based_programming.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">RDD based programming</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./12_rdd_keyvalue_pairs.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">RDDs and key-value pairs</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./13_rdd_numbers.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">RDD of numbers</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./14_cache_accumulators_broadcast.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Cache, Accumulators, Broadcast Variables</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./15b_pagerank.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Introduction to PageRank</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./16_sparksql_dataframes.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Spark SQL and DataFrames</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18a_spark_mllib.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Spark MLlib</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18b_classification.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Classification algorithms</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18c_clustering.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Clustering algorithms</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18d_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Regression algorithms</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./18e_mining.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Itemset and Association rule mining</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./19_graph_analytics_1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Graph analytics in Spark</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./20_graph_analytics_2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Graph Analytics in Spark</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./21_streaming_analytics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Streaming data analytics frameworks</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./22_structured_streaming.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Spark structured streaming</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./23_streaming_frameworks.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Streaming data analytics frameworks</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#persistence-and-cache" id="toc-persistence-and-cache" class="nav-link active" data-scroll-target="#persistence-and-cache">Persistence and Cache</a></li>
  <li><a href="#accumulators" id="toc-accumulators" class="nav-link" data-scroll-target="#accumulators">Accumulators</a></li>
  <li><a href="#broadcast-variables" id="toc-broadcast-variables" class="nav-link" data-scroll-target="#broadcast-variables">Broadcast variables</a></li>
  <li><a href="#rdds-and-partitions" id="toc-rdds-and-partitions" class="nav-link" data-scroll-target="#rdds-and-partitions">RDDs and Partitions</a></li>
  <li><a href="#broadcast-join" id="toc-broadcast-join" class="nav-link" data-scroll-target="#broadcast-join">Broadcast join</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Cache, Accumulators, Broadcast Variables</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="persistence-and-cache" class="level3">
<h3 class="anchored" data-anchor-id="persistence-and-cache">Persistence and Cache</h3>
<p>Spark computes the content of an RDD each time an action is invoked on it. If the same RDD is used multiple times in an application, Spark recomputes its content every time an action is invoked on the RDD, or on one of its descendants, but this is expensive, especially for iterative applications.</p>
<p>So, it is possible to ask Spark to persist/cache RDDs: in this way, each node stores the content of its partitions in memory and reuses them in other actions on that RDD/dataset (or RDDs derived from it).</p>
<ul>
<li>The first time the content of a persistent/cached RDD is computed in an action, it will be kept in the main memory of the nodes;</li>
<li>The next actions on the same RDD will read its content from memory (i.e., Spark persists/caches the content of the RDD across operations). This allows future actions to be much faster, often by more than ten times faster.</li>
</ul>
<p>Spark supports several storage levels, which are used to specify if the content of the RDD is stored</p>
<ul>
<li>In the main memory of the nodes</li>
<li>On the local disks of the nodes</li>
<li>Partially in the main memory and partially on disk</li>
</ul>
<table class="table">
<caption>Storage levels</caption>
<colgroup>
<col style="width: 40%">
<col style="width: 50%">
</colgroup>
<thead>
<tr class="header">
<th>Storage Level</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>MEMORY_ONLY</code></td>
<td>Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, some partitions will not be cached and will be recomputed on the fly each time they’re needed. This is the default level.</td>
</tr>
<tr class="even">
<td><code>MEMORY_AND_DISK</code></td>
<td>Store RDD as deserialized Java objects in the JVM. If the RDD does not fit in memory, store the partitions that don’t fit on (local) disk, and read them from there when they’re needed.</td>
</tr>
<tr class="odd">
<td><code>DISK_ONLY</code></td>
<td>Store the RDD partitions only on disk.</td>
</tr>
<tr class="even">
<td><code>MEMORY_ONLY_2</code>, <code>MEMORY_AND_DISK_2</code>, etc.</td>
<td>Same as the levels above, but replicate each partition on two cluster nodes.</td>
</tr>
<tr class="odd">
<td><code>OFF_HEAP</code> (experimental)</td>
<td>Similar to <code>MEMORY_ONLY</code>, but store the data in off-heap memory. This requires off-heap memory to be enabled.</td>
</tr>
</tbody>
</table>
<p>See <a href="https://spark.apache.org/docs/2.4.0/rdd-programming-guide.html#rdd-persistence">here</a> for more details.</p>
<p>It is possible to mark an RDD to be persisted by using the <code>persist(storageLevel)</code> method of the <code>RDD</code> class. The parameter of persist can assume the following values</p>
<ul>
<li><code>pyspark.StorageLevel.MEMORY_ONLY</code></li>
<li><code>pyspark.StorageLevel.MEMORY_AND_DISK</code></li>
<li><code>pyspark.StorageLevel.DISK_ONLY</code></li>
<li><code>pyspark.StorageLevel.NONE</code></li>
<li><code>pyspark.StorageLevel.OFF_HEAP</code></li>
<li><code>pyspark.StorageLevel.MEMORY_ONLY_2</code></li>
<li><code>pyspark.StorageLevel.MEMORY_AND_DISK_2</code></li>
</ul>
<p>The storage level <code>*_2</code> replicate each partition on two cluster nodes, so that, ff one node fails, the other one can be used to perform the actions on the RDD without recomputing the content of the RDD.</p>
<p>It is possible to cache an RDD by using the <code>cache()</code> method of the <code>RDD</code> class: it corresponds to persist the RDD with the storage level <code>'MEMORY_ONLY'</code> (i.e., it is equivalent to <code>inRDD.persist(pyspark.StorageLevel.MEMORY_ONLY)</code>)</p>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Notice that both persist and cache return a new RDD, since RDDs are immutable.</p>
</div>
</div>
<p>The use of the persist/cache mechanism on an RDD provides an advantage if the same RDD is used multiple times (i.e., multiples actions are applied on it or on its descendants).</p>
<p>The storage levels that store RDDs on disk are useful if and only if</p>
<ul>
<li>the size of the RDD is significantly smaller than the size of the input dataset;</li>
<li>the functions that are used to compute the content of the RDD are expensive.</li>
</ul>
<p>Otherwise, recomputing a partition may be as fast as reading it from disk.</p>
<section id="remove-data-from-cache" class="level4">
<h4 class="anchored" data-anchor-id="remove-data-from-cache">Remove data from cache</h4>
<p>Spark automatically monitors cache usage on each node and drops out old data partitions in a least-recently-used (LRU) fashion. It is also possible to manually remove an RDD from the cache by using the <code>unpersist()</code> method of the <code>RDD</code> class.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create an RDD from a textual file containing a list of words (one word for each line);</li>
<li>Print on the standard output
<ul>
<li>The number of lines of the input file</li>
<li>The number of distinct words</li>
</ul></li>
</ol>
<div class="sourceCode" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="co">## Read the content of a textual file</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="co">## and cache the associated RDD</span></span>
<span id="cb1-3"><a href="#cb1-3"></a>inputRDD <span class="op">=</span> sc.textFile(<span class="st">"words.txt"</span>).cache()</span>
<span id="cb1-4"><a href="#cb1-4"></a></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="bu">print</span>(<span class="st">"Number of words: "</span>,inputRDD.count())</span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="bu">print</span>(<span class="st">"Number of distinct words: "</span>, inputRDD.distinct().count())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 25%">
<col style="width: 75%">
</colgroup>
<tbody>
<tr class="odd">
<td><code>.cache()</code></td>
<td>The cache method is invoked, hence <code>inputRDD</code> is a cached RDD</td>
</tr>
<tr class="even">
<td><code>inputRDD.count()</code></td>
<td>This is the first time an action is invoked on the <code>inputRDD</code> RDD. The content of the RDD is computed by reading the lines of the words.txt file and the result of the count action is returned. The content of <code>inputRDD</code> is also stored in the main memory of the nodes of the cluster.</td>
</tr>
<tr class="odd">
<td><code>inputRDD.distinct().count()</code></td>
<td>The content of <code>inputRDD</code> is in the main memory if the nodes of the cluster. Hence the computation of <code>distinct()</code> and <code>count()</code> is performed by reading the data from the main memory and not from the input (HDFS) file <code>words.txt</code>.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="accumulators" class="level3">
<h3 class="anchored" data-anchor-id="accumulators">Accumulators</h3>
<p>When a function passed to a Spark operation is executed on a remote cluster node, it works on separate copies of all the variables used in the function. These variables are copied to each node of the cluster, and no updates to the variables on the nodes are propagated back to the driver program.</p>
<p>Spark provides a type of shared variables called <strong>accumulators</strong>: accumulators are shared variables that are only “added” to through an associative operation and can therefore be efficiently supported in parallel, and they can be used to implement counters or sums.</p>
<p>Accumulators are usually used to compute simple statistics while performing some other actions on the input RDD, avoiding to use actions like <code>reduce()</code> to compute simple statistics (e.g., count the number of lines with some characteristics).</p>
<section id="how-to-use-accumulators" class="level4">
<h4 class="anchored" data-anchor-id="how-to-use-accumulators">How to use accumulators</h4>
<ol type="1">
<li>The driver defines and initializes the accumulator</li>
<li>The code executed in the worker nodes increases the value of the accumulator (i.e., the code in the functions associated with the transformations)</li>
<li>The final value of the accumulator is returned to the driver node
<ul>
<li>Only the driver node can access the final value of the accumulator</li>
<li>The worker nodes cannot access the value of the accumulator: they can only add values to it</li>
</ul></li>
</ol>
<div class="callout-important callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Pay attention that the value of the accumulator is increased in the functions associated with transformations, and, since transformations are lazily evaluated, the value of the accumulator is computed only when an action is executed on the RDD on which the transformations increasing the accumulator are applied.</p>
</div>
</div>
<p>Spark natively supports numerical accumulators (integers and floats), but programmers can add support for new data types: accumulators are <code>pyspark.accumulators.Accumulator</code> objects.</p>
<p>Accumulators are defined and initialized by using the <code>accumulator(value)</code> method of the <code>SparkContext</code> class: the value of an accumulator can be increased by using the <code>add(value)</code> method of the <code>Accumulator</code> class, that adds <code>value</code> to the current value of the accumulator. The final value of an accumulator can be retrieved in the driver program by using <code>value</code> of the <code>Accumulator</code> class.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create an RDD from a textual file containing a list of email addresses (one email for each line);</li>
<li>Select the lines containing a valid email and store them in an HDFS file (in this example, an email is considered a valid email if it contains the @ symbol);</li>
<li>Print also, on the standard output, the number of invalid emails.</li>
</ol>
<div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="co">## Define an accumulator. Initialize it to 0</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>invalidEmails <span class="op">=</span> sc.accumulator(<span class="dv">0</span>)</span>
<span id="cb2-3"><a href="#cb2-3"></a></span>
<span id="cb2-4"><a href="#cb2-4"></a><span class="co">## Read the content of the input textual file</span></span>
<span id="cb2-5"><a href="#cb2-5"></a>emailsRDD <span class="op">=</span> sc.textFile(<span class="st">"emails.txt"</span>)</span>
<span id="cb2-6"><a href="#cb2-6"></a></span>
<span id="cb2-7"><a href="#cb2-7"></a><span class="co">#Define the filtering function</span></span>
<span id="cb2-8"><a href="#cb2-8"></a><span class="kw">def</span> validEmailFunc(line):</span>
<span id="cb2-9"><a href="#cb2-9"></a>    <span class="cf">if</span> (line.find(<span class="st">'@'</span>)<span class="op">&lt;</span><span class="dv">0</span>):</span>
<span id="cb2-10"><a href="#cb2-10"></a>        invalidEmails.add(<span class="dv">1</span>)</span>
<span id="cb2-11"><a href="#cb2-11"></a>        <span class="cf">return</span> <span class="va">False</span></span>
<span id="cb2-12"><a href="#cb2-12"></a>    <span class="cf">else</span>:</span>
<span id="cb2-13"><a href="#cb2-13"></a>        <span class="cf">return</span> <span class="va">True</span></span>
<span id="cb2-14"><a href="#cb2-14"></a></span>
<span id="cb2-15"><a href="#cb2-15"></a><span class="co">## Select only valid emails</span></span>
<span id="cb2-16"><a href="#cb2-16"></a><span class="co">## Count also the number of invalid emails</span></span>
<span id="cb2-17"><a href="#cb2-17"></a>validEmailsRDD <span class="op">=</span> emailsRDD.<span class="bu">filter</span>(validEmailFunc)</span>
<span id="cb2-18"><a href="#cb2-18"></a></span>
<span id="cb2-19"><a href="#cb2-19"></a><span class="co">## Store valid emails in the output file</span></span>
<span id="cb2-20"><a href="#cb2-20"></a>validEmailsRDD.saveAsTextFile(outputPath)</span>
<span id="cb2-21"><a href="#cb2-21"></a></span>
<span id="cb2-22"><a href="#cb2-22"></a><span class="co">## Print the number of invalid emails</span></span>
<span id="cb2-23"><a href="#cb2-23"></a><span class="bu">print</span>(<span class="st">"Invalid email addresses: "</span>, invalidEmails.value)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 66%">
</colgroup>
<tbody>
<tr class="odd">
<td><code>invalidEmails = sc.accumulator(0)</code></td>
<td>Definition of an accumulator of type integer.</td>
</tr>
<tr class="even">
<td><code>invalidEmails.add(1)</code></td>
<td>This function increments the value of the <code>invalidEmails</code> accumulator if the email is invalid.</td>
</tr>
<tr class="odd">
<td><code>invalidEmails.value</code></td>
<td>Read the final value of the accumulator. Pay attention that the value of the accumulator is correct only because an action (<code>saveAsTextFile</code>) has been executed on the <code>validEmailsRDD</code> and its content has been computed (the function <code>validEmailFunc</code> has been executed on each element of <code>emailsRDD</code>)</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="personalized-accumulators" class="level4">
<h4 class="anchored" data-anchor-id="personalized-accumulators">Personalized accumulators</h4>
<p>Programmers can define accumulators based on new data types (different from integers and floats): to define a new accumulator data type of type <span class="math inline">\(T\)</span>, the programmer must define a class subclassing the <code>AccumulatorParam</code> interface. The <code>AccumulatorParam</code> interface has two methods</p>
<ul>
<li><code>zero</code> for providing a zero value for your data type</li>
<li><code>addInPlace</code> for adding two values together</li>
</ul>
</section>
</section>
<section id="broadcast-variables" class="level3">
<h3 class="anchored" data-anchor-id="broadcast-variables">Broadcast variables</h3>
<p>Spark supports broadcast variables. A broadcast variable is a read-only (small/medium) shared variable</p>
<ul>
<li>It is instantiated in the driver: the broadcast variable is stored in the main memory of the driver in a local variable;</li>
<li>It is sent to all worker nodes that use it in one or more Spark operations: the broadcast variable is also stored in the main memory of the executors (which are instantiated in the used worker nodes).</li>
</ul>
<p>A copy each broadcast variable is sent to all executors that are used to run a task executing a Spark operation based on that variable (i.e., the variable is sent <code>num.executors</code> times). A broadcast variable is sent only one time to each executor that uses that variable in at least one Spark operation (i.e., in at least one of its tasks). Each executor can run multiples tasks associated with the same broadcast variable, but the broadcast variable is sent only one time for each executor, hence the amount of data sent on the network is limited by using broadcast variables instead of standard variables.</p>
<p>Broadcast variables are usually used to share (small/medium) lookup-tables, and, since they are stored in local variables, they must the small enough to be stored in the main memory of the driver and also in the main memory of the executors.</p>
<p>Broadcast variables are objects of type <code>Broadcast</code>: a broadcast variable (of type <span class="math inline">\(T\)</span>) is defined in the driver by using the <code>broadcast(value)</code> method of the <code>SparkContext</code> class. The value of a broadcast variable (of type <span class="math inline">\(T\)</span>) is retrieved (usually in transformations) by using <code>value</code> of the <code>Broadcast</code> class.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create an RDD from a textual file containing a dictionary of pairs (word, integer value), one pair for each line. Suppose the content of this first file is large but can be stored in main-memory;</li>
<li>Create an RDD from a textual file containing a set of words, in particular a sentence (set of words) for each line; Transform the content of the second file mapping each word to an integer based on the dictionary contained in the first file; then, store the result in an HDFS file.</li>
</ol>
<ul>
<li>First file (dictionary)</li>
</ul>
<pre><code>java 1
spark 2
test 3</code></pre>
<ul>
<li>Second file (the text to transform)</li>
</ul>
<pre><code>java spark
spark test java</code></pre>
<ul>
<li>Output file</li>
</ul>
<pre><code>12
231</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a><span class="co">## Read the content of the dictionary from the first file and</span></span>
<span id="cb6-2"><a href="#cb6-2"></a><span class="co">## map each line to a pair (word, integer value)</span></span>
<span id="cb6-3"><a href="#cb6-3"></a>dictionaryRDD <span class="op">=</span> sc <span class="op">\</span></span>
<span id="cb6-4"><a href="#cb6-4"></a>    .textFile(<span class="st">"dictionary.txt"</span>) <span class="op">\</span></span>
<span id="cb6-5"><a href="#cb6-5"></a>    .<span class="bu">map</span>(<span class="kw">lambda</span> line: (</span>
<span id="cb6-6"><a href="#cb6-6"></a>        line.split(<span class="st">" "</span>)[<span class="dv">0</span>], </span>
<span id="cb6-7"><a href="#cb6-7"></a>        line.split(<span class="st">" "</span>)[<span class="dv">1</span>]</span>
<span id="cb6-8"><a href="#cb6-8"></a>    ))</span>
<span id="cb6-9"><a href="#cb6-9"></a></span>
<span id="cb6-10"><a href="#cb6-10"></a><span class="co">## Create a broadcast variable based on the content of dictionaryRDD.</span></span>
<span id="cb6-11"><a href="#cb6-11"></a><span class="co">## Pay attention that a broadcast variable can be instantiated only</span></span>
<span id="cb6-12"><a href="#cb6-12"></a><span class="co">## by passing as parameter a local variable and not an RDD.</span></span>
<span id="cb6-13"><a href="#cb6-13"></a><span class="co">## Hence, the collectAsMap method is used to retrieve the content of the</span></span>
<span id="cb6-14"><a href="#cb6-14"></a><span class="co">## RDD and store it in the dictionary variable</span></span>
<span id="cb6-15"><a href="#cb6-15"></a>dictionary <span class="op">=</span> dictionaryRDD.collectAsMap()</span>
<span id="cb6-16"><a href="#cb6-16"></a></span>
<span id="cb6-17"><a href="#cb6-17"></a><span class="co">## Broadcast dictionary</span></span>
<span id="cb6-18"><a href="#cb6-18"></a>dictionaryBroadcast <span class="op">=</span> sc.broadcast(dictionary)</span>
<span id="cb6-19"><a href="#cb6-19"></a></span>
<span id="cb6-20"><a href="#cb6-20"></a><span class="co">## Read the content of the second file</span></span>
<span id="cb6-21"><a href="#cb6-21"></a>textRDD <span class="op">=</span> sc.textFile(<span class="st">"document.txt"</span>)</span>
<span id="cb6-22"><a href="#cb6-22"></a></span>
<span id="cb6-23"><a href="#cb6-23"></a><span class="co">## Define the function that is used to map strings to integers</span></span>
<span id="cb6-24"><a href="#cb6-24"></a><span class="kw">def</span> myMapFunc(line):</span>
<span id="cb6-25"><a href="#cb6-25"></a>    transformedLine<span class="op">=</span><span class="st">''</span></span>
<span id="cb6-26"><a href="#cb6-26"></a>    <span class="cf">for</span> word <span class="kw">in</span> line.split(<span class="st">' '</span>):</span>
<span id="cb6-27"><a href="#cb6-27"></a>        intValue <span class="op">=</span> dictionaryBroadcast.value[word]</span>
<span id="cb6-28"><a href="#cb6-28"></a>        transformedLine <span class="op">=</span> transformedLine<span class="op">+</span>intValue<span class="op">+</span><span class="st">' '</span></span>
<span id="cb6-29"><a href="#cb6-29"></a>    <span class="cf">return</span> transformedLine.strip()</span>
<span id="cb6-30"><a href="#cb6-30"></a></span>
<span id="cb6-31"><a href="#cb6-31"></a><span class="co">## Map words in textRDD to the corresponding integers and concatenate</span></span>
<span id="cb6-32"><a href="#cb6-32"></a><span class="co">## them</span></span>
<span id="cb6-33"><a href="#cb6-33"></a>mappedTextRDD<span class="op">=</span> textRDD.<span class="bu">map</span>(myMapFunc)</span>
<span id="cb6-34"><a href="#cb6-34"></a></span>
<span id="cb6-35"><a href="#cb6-35"></a><span class="co">## Store the result in an HDFS file</span></span>
<span id="cb6-36"><a href="#cb6-36"></a>mappedTextRDD.saveAsTextFile(outputPath)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 66%">
</colgroup>
<tbody>
<tr class="odd">
<td><code>sc.broadcast(dictionary)</code></td>
<td>Define a broadcast variable.</td>
</tr>
<tr class="even">
<td><code>dictionaryBroadcast.value[word]</code></td>
<td>Retrieve the content of the broadcast variable and use it.</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
<section id="rdds-and-partitions" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="rdds-and-partitions">RDDs and Partitions</h3>
<p>The content of each RDD is split in partitions: the number of partitions and the content of each partition depend on how RDDs are defined/created. The number of partitions impacts on the maximum parallelization degree of the Spark application, but pay attention that the amount of resources is limited (there is a maximum number of executors and parallel tasks).</p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
How many partitions are good?
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Disadvantages of too few partitions</strong></p>
<ul>
<li>Less concurrency/parallelism: there could be worker nodes that are idle and could be used to speed up the execution of your application;</li>
<li>Data skewing and improper resource utilization: data might be skewed on one partition (i.e., one partition with many data, many partitions with few data). The worker node that processes the largest partition needs more time than the other workers, becoming the bottleneck of your application.</li>
</ul>
<p><strong>Disadvantages of too many partitions</strong></p>
<ul>
<li>Task scheduling may take more time than actual execution time if the amount of data in some partitions is too small</li>
</ul>
</div>
</div>
<p>Only some specific transformations set the number of partitions of the returned RDD: <code>parallelize()</code>, <code>textFile()</code>, <code>repartition()</code>, <code>coalesce()</code>. The majority of the Spark transformations do not change the number of partitions, preserving the number of partitions of the input RDD (i.e., the returned RDD has the same number of partitions of the input RDD).</p>
<table class="table">
<colgroup>
<col style="width: 35%">
<col style="width: 65%">
</colgroup>
<thead>
<tr class="header">
<th>Transformation</th>
<th>Effect</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>parallelize(collection)</code></td>
<td><p>The number of partitions of the returned RDD is equal to <code>sc.defaultParallelism</code>.</p>
<p>Sparks tries to balance the number of elements per partition in the returned RDD; notice that elements are not assigned to partitions based on their value.</p></td>
</tr>
<tr class="even">
<td><code>parallelize(collection, numSlices)</code></td>
<td><p>The number of partitions of the returned RDD is equal to <code>numSlices</code>.</p>
<p>Sparks tries to balance the number of elements per partition in the returned RDD; notice that elements are not assigned to partitions based on their value.</p></td>
</tr>
<tr class="odd">
<td><code>textFile(pathInputData)</code></td>
<td><p>The number of partitions of the returned RDD is equal to the number of input chunks/blocks of the input HDFS data.</p>
<p>Each partition contains the content of one of the input blocks.</p></td>
</tr>
<tr class="even">
<td><code>textFile(pathInputData, minPartitions)</code></td>
<td><p>The user specified number of partitions must be greater than the number of input blocks.</p>
<p>The number of partitions of the returned RDD is greater than or equal to the specified value <code>minPartitions</code>, and each partition contains a part of one input blocks.</p></td>
</tr>
<tr class="odd">
<td><code>repartition(numPartitions)</code></td>
<td><p><code>numPartitions</code> can be greater or smaller than the number of partitions of the input RDD, and the number of partitions of the returned RDD is equal to <code>numPartitions</code>.</p>
<p>Sparks tries to balance the number of elements per partition in the returned RDD; notice that elements are not assigned to partitions based on their value.</p>
<p>A shuffle operation is executed to assign input elements to the partitions of the returned RDD.</p></td>
</tr>
<tr class="even">
<td><code>coalesce(numPartitions)</code></td>
<td><p><code>numPartitions</code> is smaller than the number of partitions of the input RDD, and the number of partitions of the returned RDD is equal to <code>numPartitions</code>.</p>
<p>Sparks tries to balance the number of elements per partition in the returned RDD; notice that elements are not assigned to partitions based on their value.</p>
<p>Usually no shuffle operation is executed to assign input elements to the partitions of the returned RDD, so coalesce is more efficient than repartition to reduce the number of partitions.</p></td>
</tr>
</tbody>
</table>
<p>Spark allows specifying how to partition the content of RDDs of key-value pairs: he input tpairs are grouped in partitions based on the integer value returned by a function applied on the key of each input pair. This operation can be useful to improve the efficiency of the next transformations by reducing the amount of shuffle operations and the amount of data sent on the network in the next steps of the application (Spark can optimize the execution of the transformations if the input RDDs of pairs are properly partitioned).</p>
<section id="partitionbynumpartitions" class="level4">
<h4 class="anchored" data-anchor-id="partitionbynumpartitions"><code>partitionBy(numPartitions)</code></h4>
<p>Partitioning is based on the <code>partitionBy()</code> transformation. The input pairs are grouped in partitions based on the integer value returned by a default hash function applied on the key of each input pair. A shuffle operation is executed to assign input elements to the partitions of the returned RDD.</p>
<p>Suppose that the number of partition of the returned Pair RDD is <span class="math inline">\(\textbf{numPart}\)</span>. The default partition function is <code>portable_hash</code>: given an input pair <span class="math inline">\((key, value)\)</span> a copy of that pair will be stored in the partition number <span class="math inline">\(n\)</span> of the returned RDD, where</p>
<p><span class="math display">\[
n = portable\_hash(key) \% numPart
\]</span></p>
<p>Notice that <span class="math inline">\(portable\_hash(key)\)</span> returns and integer.</p>
<section id="partitionbynumpartitions-partitionfunc" class="level5">
<h5 class="anchored" data-anchor-id="partitionbynumpartitions-partitionfunc"><code>partitionBy(numPartitions, partitionFunc)</code></h5>
<p>The input pairs are grouped in partitions based on the integer value returned by the user provided <code>partitionFunc</code> function. A shuffle operation is executed to assign input elements to the partitions of the returned RDD.</p>
<p>Suppose that the number of partition of the returned Pair RDD is <span class="math inline">\(\textbf{numPart}\)</span>. The custom partition function is <code>partitionFunc</code>: given an input pair <span class="math inline">\((key, value)\)</span> a copy of that pair will be stored in the partition number <span class="math inline">\(n\)</span> of the returned RDD, where</p>
<p><span class="math display">\[
n = partitionFunc(key) \% numPart
\]</span></p>
<div class="callout-tip callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Use case scenario
</div>
</div>
<div class="callout-body-container callout-body">
<p>Partitioning Pair RDDs by using <code>partitionBy()</code> is useful only when the same partitioned RDD is cached and reused multiple times in the application in time and network consuming key-oriented transformations.</p>
<p>For example, the same partitioned RDD is used in many <code>join()</code>, <code>cogroup()</code>, <code>groupyByKey()</code>, … transformations in different paths/branches of the application (different paths/branches of the DAG).</p>
<p>Pay attention to the amount of data that is actually sent on the network: <code>partitionBy()</code> can slow down the application instead of speeding it up.</p>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create an RDD from a textual file containing a list of pairs (pageID, list of linked pages);</li>
<li>Implement the (simplified) PageRank algorithm and compute the pageRank of each input page;</li>
<li>Print the result on the standard output.</li>
</ol>
<div class="sourceCode" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a><span class="co">## Read the input file with the structure of the web graph</span></span>
<span id="cb7-2"><a href="#cb7-2"></a>inputData <span class="op">=</span> sc.textFile(<span class="st">"links.txt"</span>)</span>
<span id="cb7-3"><a href="#cb7-3"></a></span>
<span id="cb7-4"><a href="#cb7-4"></a><span class="co">## Format of each input line</span></span>
<span id="cb7-5"><a href="#cb7-5"></a><span class="co">## PageId,LinksToOtherPages - e.g., P3 [P1,P2,P4,P5]</span></span>
<span id="cb7-6"><a href="#cb7-6"></a><span class="kw">def</span> mapToPairPageIDLinks(line):</span>
<span id="cb7-7"><a href="#cb7-7"></a>    fields <span class="op">=</span> line.split(<span class="st">' '</span>)</span>
<span id="cb7-8"><a href="#cb7-8"></a>    pageID <span class="op">=</span> fields[<span class="dv">0</span>]</span>
<span id="cb7-9"><a href="#cb7-9"></a>    links <span class="op">=</span> fields[<span class="dv">1</span>].split(<span class="st">','</span>)</span>
<span id="cb7-10"><a href="#cb7-10"></a>    <span class="cf">return</span> (pageID, links)</span>
<span id="cb7-11"><a href="#cb7-11"></a></span>
<span id="cb7-12"><a href="#cb7-12"></a>links <span class="op">=</span> inputData.<span class="bu">map</span>(mapToPairPageIDLinks) <span class="op">\</span></span>
<span id="cb7-13"><a href="#cb7-13"></a>    .partitionBy(inputData.getNumPartitions()) <span class="op">\</span></span>
<span id="cb7-14"><a href="#cb7-14"></a>    .cache()</span>
<span id="cb7-15"><a href="#cb7-15"></a></span>
<span id="cb7-16"><a href="#cb7-16"></a><span class="co">## Initialize each page's rank to 1.0; since we use mapValues,</span></span>
<span id="cb7-17"><a href="#cb7-17"></a><span class="co">## the resulting RDD will have the same partitioner as links</span></span>
<span id="cb7-18"><a href="#cb7-18"></a>ranks <span class="op">=</span> links.mapValues(<span class="kw">lambda</span> v: <span class="fl">1.0</span>)</span>
<span id="cb7-19"><a href="#cb7-19"></a></span>
<span id="cb7-20"><a href="#cb7-20"></a><span class="co">## Function that returns a set of pairs from each input pair</span></span>
<span id="cb7-21"><a href="#cb7-21"></a><span class="co">## input pair: (pageid, (linked pages, current page rank of pageid) )</span></span>
<span id="cb7-22"><a href="#cb7-22"></a><span class="co">## one output pair for each linked page. Output pairs:</span></span>
<span id="cb7-23"><a href="#cb7-23"></a><span class="co">## (pageid linked page,</span></span>
<span id="cb7-24"><a href="#cb7-24"></a><span class="co">## current page rank of the linking page pageid / number of linked pages)</span></span>
<span id="cb7-25"><a href="#cb7-25"></a><span class="kw">def</span> computeContributions(pageIDLinksPageRank):</span>
<span id="cb7-26"><a href="#cb7-26"></a>    pagesContributions <span class="op">=</span> []</span>
<span id="cb7-27"><a href="#cb7-27"></a>    currentPageRank <span class="op">=</span> pageIDLinksPageRank[<span class="dv">1</span>][<span class="dv">1</span>]</span>
<span id="cb7-28"><a href="#cb7-28"></a>    linkedPages <span class="op">=</span> pageIDLinksPageRank[<span class="dv">1</span>][<span class="dv">0</span>]</span>
<span id="cb7-29"><a href="#cb7-29"></a>    numLinkedPages <span class="op">=</span> <span class="bu">len</span>(linkedPages)</span>
<span id="cb7-30"><a href="#cb7-30"></a>    contribution <span class="op">=</span> currentPageRank<span class="op">/</span>numLinkedPages</span>
<span id="cb7-31"><a href="#cb7-31"></a></span>
<span id="cb7-32"><a href="#cb7-32"></a>    <span class="cf">for</span> pageidLinkedPage <span class="kw">in</span> linkedPages:</span>
<span id="cb7-33"><a href="#cb7-33"></a>        pagesContributions.append((pageidLinkedPage, contribution))</span>
<span id="cb7-34"><a href="#cb7-34"></a>    </span>
<span id="cb7-35"><a href="#cb7-35"></a>    <span class="cf">return</span> pagesContributions</span>
<span id="cb7-36"><a href="#cb7-36"></a></span>
<span id="cb7-37"><a href="#cb7-37"></a><span class="co">## Run 30 iterations of PageRank</span></span>
<span id="cb7-38"><a href="#cb7-38"></a><span class="cf">for</span> x <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">30</span>):</span>
<span id="cb7-39"><a href="#cb7-39"></a>    <span class="co">## Retrieve for each page its current pagerank and</span></span>
<span id="cb7-40"><a href="#cb7-40"></a>    <span class="co">## the list of linked pages by using the join transformation</span></span>
<span id="cb7-41"><a href="#cb7-41"></a></span>
<span id="cb7-42"><a href="#cb7-42"></a>    pageRankLinks <span class="op">=</span> links.join(ranks)</span>
<span id="cb7-43"><a href="#cb7-43"></a>    <span class="co">## Compute contributions from linking pages to linked pages</span></span>
<span id="cb7-44"><a href="#cb7-44"></a>    <span class="co">## for this iteration</span></span>
<span id="cb7-45"><a href="#cb7-45"></a>    </span>
<span id="cb7-46"><a href="#cb7-46"></a>    contributions <span class="op">=</span> pageRankLinks.flatMap(computeContributions)</span>
<span id="cb7-47"><a href="#cb7-47"></a>    <span class="co">## Update current pagerank of all pages for this iteration</span></span>
<span id="cb7-48"><a href="#cb7-48"></a>    ranks <span class="op">=</span> contributions<span class="op">\</span></span>
<span id="cb7-49"><a href="#cb7-49"></a>        .reduceByKey(<span class="kw">lambda</span> contrib1, contrib2: contrib1<span class="op">+</span>contrib2)</span>
<span id="cb7-50"><a href="#cb7-50"></a></span>
<span id="cb7-51"><a href="#cb7-51"></a><span class="co">## Print the result</span></span>
<span id="cb7-52"><a href="#cb7-52"></a>ranks.collect()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<table class="table">
<colgroup>
<col style="width: 33%">
<col style="width: 66%">
</colgroup>
<tbody>
<tr class="odd">
<td><code>.partitionBy()...cache()</code></td>
<td>Notice that the returned Pair RDD is partitioned and cached.</td>
</tr>
<tr class="even">
<td><code>links</code></td>
<td>The join transformation is invoked many times on the links Pair RDD. The content of links is constant (it does not change during the loop iterations). Hence, caching it and also partitioning its content by key is useful: its content is computed one time and cached in the main memory of the executors, and it is shuffled and sent on the network only one time because <code>partitionBy</code> was applied on it</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="default-partitioning-behavior-of-the-main-transformations" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="default-partitioning-behavior-of-the-main-transformations">Default partitioning behavior of the main transformations</h4>
<div class="page-columns page-full">
<div class="column-page">
<table class="table">
<colgroup>
<col style="width: 40%">
<col style="width: 30%">
<col style="width: 30%">
</colgroup>
<thead>
<tr class="header">
<th>Transformation</th>
<th>Number of partitions</th>
<th>Partitioner</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>sc.parallelize()</code></td>
<td><code>sc.defaultParallelism</code></td>
<td>NONE</td>
</tr>
<tr class="even">
<td><code>sc.textFile()</code></td>
<td>the maximum between <code>sc.defaultParallelism</code> and the number of file blocks</td>
<td>NONE</td>
</tr>
<tr class="odd">
<td><code>filter()</code>, <code>map()</code>, <code>flatMap()</code>, <code>distinct()</code></td>
<td>same as parent RDD</td>
<td>NONE except filter preserve parent RDD’s partitioner</td>
</tr>
<tr class="even">
<td><code>rdd.union(otherRDD)</code></td>
<td><code>rdd.partitions.size + otherRDD.partitions.size</code></td>
<td>NONE except filter preserve parent RDD’s partitioner</td>
</tr>
<tr class="odd">
<td><code>rdd.intersection(otherRDD)</code></td>
<td><code>max(rdd.partitions.size, otherRDD.partitions.size)</code></td>
<td>NONE except filter preserve parent RDD’s partitioner</td>
</tr>
<tr class="even">
<td><code>rdd.subtract(otherRDD)</code></td>
<td><code>rdd.partitions.size</code></td>
<td>NONE except filter preserve parent RDD’s partitioner</td>
</tr>
<tr class="odd">
<td><code>rdd.cartesian(otherRDD)</code></td>
<td><code>rdd.partitions.size * otherRDD. partitions.size</code></td>
<td>NONE except filter preserve parent RDD’s partitioner</td>
</tr>
<tr class="even">
<td><code>reduceByKey()</code>, <code>foldByKey()</code>, <code>combineByKey()</code>, <code>groupByKey()</code></td>
<td>same as parent RDD</td>
<td>HashPartitioner</td>
</tr>
<tr class="odd">
<td><code>sortByKey()</code></td>
<td>same as parent RDD</td>
<td>RangePartitioner</td>
</tr>
<tr class="even">
<td><code>mapValues()</code>, <code>flatMapValues()</code></td>
<td>same as parent RDD</td>
<td>parent RDD’s partitioner</td>
</tr>
<tr class="odd">
<td><code>cogroup()</code>, <code>join()</code>,<code>leftOuterJoin()</code>, <code>rightOuterJoin()</code></td>
<td>depends upon input properties of two involved RDDs</td>
<td>HashPartitioner</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
</section>
<section id="broadcast-join" class="level3">
<h3 class="anchored" data-anchor-id="broadcast-join">Broadcast join</h3>
<p>The join transformation is expensive in terms of execution time and amount of data sent on the network. If one of the two input RDDs of key-value pairs is small enough to be stored in the main memory, then it is possible to use a more efficient solution based on a broadcast variable.</p>
<ul>
<li>Broadcast hash join (or map-side join)</li>
<li>The smaller the small RDD, the higher the speed up</li>
</ul>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ol type="1">
<li>Create a large RDD from a textual file containing a list of pairs <code>(userID, post)</code>; notice that each user can be associated to several posts;</li>
<li>Create a small RDD from a textual file containing a list of pairs <code>(userID, (name, surname, age))</code>; notice that each user can be associated to one single line in this second file;</li>
<li>Compute the join between these two files.</li>
</ol>
<div class="sourceCode" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="co">## Read the first input file</span></span>
<span id="cb8-2"><a href="#cb8-2"></a>largeRDD <span class="op">=</span> sc <span class="op">\</span></span>
<span id="cb8-3"><a href="#cb8-3"></a>    .textFile(<span class="st">"post.txt"</span>) <span class="op">\</span></span>
<span id="cb8-4"><a href="#cb8-4"></a>    .<span class="bu">map</span>(<span class="kw">lambda</span> line: (</span>
<span id="cb8-5"><a href="#cb8-5"></a>        <span class="bu">int</span>(line.split(<span class="st">','</span>)[<span class="dv">0</span>]), </span>
<span id="cb8-6"><a href="#cb8-6"></a>        line.split(<span class="st">','</span>)[<span class="dv">1</span>]</span>
<span id="cb8-7"><a href="#cb8-7"></a>    ))</span>
<span id="cb8-8"><a href="#cb8-8"></a></span>
<span id="cb8-9"><a href="#cb8-9"></a><span class="co">## Read the second input file</span></span>
<span id="cb8-10"><a href="#cb8-10"></a>smallRDD <span class="op">=</span> sc <span class="op">\</span></span>
<span id="cb8-11"><a href="#cb8-11"></a>    .textFile(<span class="st">"profiles.txt"</span>) <span class="op">\</span></span>
<span id="cb8-12"><a href="#cb8-12"></a>    .<span class="bu">map</span>(<span class="kw">lambda</span> line: (</span>
<span id="cb8-13"><a href="#cb8-13"></a>        <span class="bu">int</span>(line.split(<span class="st">','</span>)[<span class="dv">0</span>]), </span>
<span id="cb8-14"><a href="#cb8-14"></a>        line.split(<span class="st">','</span>)[<span class="dv">1</span>]</span>
<span id="cb8-15"><a href="#cb8-15"></a>    ))</span>
<span id="cb8-16"><a href="#cb8-16"></a></span>
<span id="cb8-17"><a href="#cb8-17"></a><span class="co">## Broadcast join version</span></span>
<span id="cb8-18"><a href="#cb8-18"></a><span class="co">## Store the "small" RDD in a local python variable in the driver</span></span>
<span id="cb8-19"><a href="#cb8-19"></a><span class="co">## and broadcast it</span></span>
<span id="cb8-20"><a href="#cb8-20"></a>localSmallTable <span class="op">=</span> smallRDD.collectAsMap()</span>
<span id="cb8-21"><a href="#cb8-21"></a>localSmallTableBroadcast <span class="op">=</span> sc.broadcast(localSmallTable)</span>
<span id="cb8-22"><a href="#cb8-22"></a></span>
<span id="cb8-23"><a href="#cb8-23"></a><span class="co">## Function for joining a record of the large RDD with the matching</span></span>
<span id="cb8-24"><a href="#cb8-24"></a><span class="co">## record of the small one</span></span>
<span id="cb8-25"><a href="#cb8-25"></a><span class="kw">def</span> joinRecords(largeTableRecord):</span>
<span id="cb8-26"><a href="#cb8-26"></a>    returnedRecords <span class="op">=</span> []</span>
<span id="cb8-27"><a href="#cb8-27"></a>    key <span class="op">=</span> largeTableRecord[<span class="dv">0</span>]</span>
<span id="cb8-28"><a href="#cb8-28"></a>    valueLargeRecord <span class="op">=</span> largeTableRecord[<span class="dv">1</span>]</span>
<span id="cb8-29"><a href="#cb8-29"></a></span>
<span id="cb8-30"><a href="#cb8-30"></a>    <span class="cf">if</span> key <span class="kw">in</span> localSmallTableBroadcast.value:</span>
<span id="cb8-31"><a href="#cb8-31"></a>        returnedRecords.append((</span>
<span id="cb8-32"><a href="#cb8-32"></a>            key,</span>
<span id="cb8-33"><a href="#cb8-33"></a>            (valueLargeRecord,localSmallTableBroadcast.value[key])</span>
<span id="cb8-34"><a href="#cb8-34"></a>        ))</span>
<span id="cb8-35"><a href="#cb8-35"></a></span>
<span id="cb8-36"><a href="#cb8-36"></a>    <span class="cf">return</span> returnedRecords</span>
<span id="cb8-37"><a href="#cb8-37"></a></span>
<span id="cb8-38"><a href="#cb8-38"></a><span class="co">## Execute the broadcast join operation by using a flatMap</span></span>
<span id="cb8-39"><a href="#cb8-39"></a><span class="co">## transformation on the "large" RDD</span></span>
<span id="cb8-40"><a href="#cb8-40"></a>userPostProfileRDDBroadcatJoin <span class="op">=</span> largeRDD.flatMap(joinRecords)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./13_rdd_numbers.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">RDD of numbers</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./15b_pagerank.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Introduction to PageRank</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>